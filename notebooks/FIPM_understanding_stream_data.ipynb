{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import websocket\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone\n",
    "import time\n",
    "import joblib\n",
    "import os\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Thalassa_Regime_Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_json(json_message):\n",
    "    size = len(np.array(json_message['bids'])[:,0])    \n",
    "    return {\n",
    "        **{'ts':[time.mktime(datetime.now().timetuple())]},\n",
    "        **{'bp'+str(key):[float(value)] for key,value in zip(np.arange(0,size)+1,np.array(json_message['bids'])[:,0])},\n",
    "        **{'bs'+str(key):[float(value)] for key,value in zip(np.arange(0,size)+1,np.array(json_message['bids'])[:,1])},\n",
    "        **{'ap'+str(key):[float(value)] for key,value in zip(np.arange(0,size)+1,np.array(json_message['asks'])[:,0])},\n",
    "        **{'as'+str(key):[float(value)] for key,value in zip(np.arange(0,size)+1,np.array(json_message['asks'])[:,1])}}\n",
    "    \n",
    "def my_json_0(size):    \n",
    "    return {\n",
    "        **{'ts':[time.mktime(datetime.now().timetuple())]},\n",
    "        **{'bp'+str(key):[value] for key,value in zip(np.arange(0,size)+1,(np.arange(0,size)+1)*np.nan)},\n",
    "        **{'bs'+str(key):[value] for key,value in zip(np.arange(0,size)+1,(np.arange(0,size)+1)*np.nan)},\n",
    "        **{'ap'+str(key):[value] for key,value in zip(np.arange(0,size)+1,(np.arange(0,size)+1)*np.nan)},\n",
    "        **{'as'+str(key):[value] for key,value in zip(np.arange(0,size)+1,(np.arange(0,size)+1)*np.nan)}}\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_json(json_message):\n",
    "    size = len(np.array(json_message['bids'])[:,0])    \n",
    "    return {\n",
    "        **{'primary_key':[datetime.now()]},\n",
    "        **{'bp'+str(key):[float(value)] for key,value in zip(np.arange(0,size)+1,np.array(json_message['bids'])[:,0])},\n",
    "        **{'bs'+str(key):[float(value)] for key,value in zip(np.arange(0,size)+1,np.array(json_message['bids'])[:,1])},\n",
    "        **{'ap'+str(key):[float(value)] for key,value in zip(np.arange(0,size)+1,np.array(json_message['asks'])[:,0])},\n",
    "        **{'as'+str(key):[float(value)] for key,value in zip(np.arange(0,size)+1,np.array(json_message['asks'])[:,1])}}\n",
    "    \n",
    "def my_json_0(size):    \n",
    "    return {\n",
    "        **{'primary_key':[datetime.now()]},\n",
    "        **{'bp'+str(key):[value] for key,value in zip(np.arange(0,size)+1,(np.arange(0,size)+1)*np.nan)},\n",
    "        **{'bs'+str(key):[value] for key,value in zip(np.arange(0,size)+1,(np.arange(0,size)+1)*np.nan)},\n",
    "        **{'ap'+str(key):[value] for key,value in zip(np.arange(0,size)+1,(np.arange(0,size)+1)*np.nan)},\n",
    "        **{'as'+str(key):[value] for key,value in zip(np.arange(0,size)+1,(np.arange(0,size)+1)*np.nan)}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_0 = pd.DataFrame.from_dict(my_json_0(5))\n",
    "\n",
    "def ws_trades(df_0): \n",
    "    symbol = 'BTCUSDT'\n",
    "    depth = 5\n",
    "    socket = 'wss://stream.binance.com:9443/ws/{}@depth{}'.format(symbol.lower(),\n",
    "                                                                depth)\n",
    "    \n",
    "    \n",
    "    def on_message(wsapp,message):  \n",
    "        json_message = json.loads(message)\n",
    "        handle_trades(json_message)\n",
    "\n",
    "    def on_error(wsapp,error):\n",
    "        print(error)\n",
    "\n",
    "    wsapp = websocket.WebSocketApp(socket, on_message=on_message, on_error=on_error)\n",
    "    wsapp.run_forever()\n",
    "    \n",
    "def handle_trades(json_message):    \n",
    "    df = pd.DataFrame.from_dict(my_json(json_message))\n",
    "    df_0 = df_0.append(df, ignore_index = True)\n",
    "    \n",
    "    print(df_0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StreamingData():\n",
    "    def __init__(self):\n",
    "        self.depth = 5     \n",
    "        self.df_0 = None       \n",
    "        self.model = joblib.load('/Users/fipm/code/abefarkas/Thalassa_Regime_Classifier/model.joblib')    \n",
    "        self.symbol = 'BTCUSDT'        \n",
    "        self.socket = 'wss://stream.binance.com:9443/ws/{}@depth{}'.format(self.symbol.lower(),self.depth)\n",
    "        \n",
    "    def handle_trades(self,json_message):    \n",
    "        df = pd.DataFrame.from_dict(self.my_json(json_message))\n",
    "        self.df_0 = pd.concat([self.df_0, df], axis=0)   \n",
    "        df_clean = self.my_return()\n",
    "        # if len(df_clean)>=1:\n",
    "        #     print(self.model.predict(df_clean))\n",
    "        #     send to database \n",
    "        return self.model.predict(df_clean)\n",
    "        \n",
    "    def my_return(self):\n",
    "        return self.preprocessing_streamed_data(self.df_0, rolling_window=2)\n",
    "\n",
    "    def on_message(self,wsapp,message):  \n",
    "        json_message = json.loads(message)\n",
    "        self.handle_trades(json_message)\n",
    "\n",
    "    def on_error(self,wsapp,error):\n",
    "        print(error)\n",
    "\n",
    "    def start(self):        \n",
    "        self.df_0 = pd.DataFrame.from_dict(self.my_json_0(self.depth))\n",
    "        wsapp = websocket.WebSocketApp(self.socket, on_message=self.on_message, on_error=self.on_error)\n",
    "        wsapp.run_forever()\n",
    "        \n",
    "    def preprocessing_streamed_data(self,df_ob, rolling_window=2):\n",
    "        '''preprocessing of data for streamed data'''                \n",
    "        \n",
    "        # aggregating by seconds     \n",
    "        df_agg = df_ob.groupby(pd.Grouper(key='primary_key', axis=0, freq='S')).mean()\n",
    "        # applying rolling window of rolling_window lenght\n",
    "        df_agg = df_agg.rolling(str(rolling_window)+'S').mean()\n",
    "        # moving the index as a column\n",
    "        df_agg.reset_index(inplace=True)\n",
    "        df_agg = df_agg.dropna().tail(50)\n",
    "        \n",
    "        return df_agg\n",
    "        \n",
    "    def my_json(self, json_message):\n",
    "        size = len(np.array(json_message['bids'])[:,0])    \n",
    "        return {\n",
    "            **{'primary_key':[datetime.now()]},\n",
    "            **{'bp'+str(key):[float(value)] for key,value in zip(np.arange(0,size)+1,np.array(json_message['bids'])[:,0])},\n",
    "            **{'bs'+str(key):[float(value)] for key,value in zip(np.arange(0,size)+1,np.array(json_message['bids'])[:,1])},\n",
    "            **{'ap'+str(key):[float(value)] for key,value in zip(np.arange(0,size)+1,np.array(json_message['asks'])[:,0])},\n",
    "            **{'as'+str(key):[float(value)] for key,value in zip(np.arange(0,size)+1,np.array(json_message['asks'])[:,1])}}\n",
    "    \n",
    "    def my_json_0(self, size):    \n",
    "        return {\n",
    "            **{'primary_key':[datetime.now()]},\n",
    "            **{'bp'+str(key):[value] for key,value in zip(np.arange(0,size)+1,(np.arange(0,size)+1)*np.nan)},\n",
    "            **{'bs'+str(key):[value] for key,value in zip(np.arange(0,size)+1,(np.arange(0,size)+1)*np.nan)},\n",
    "            **{'ap'+str(key):[value] for key,value in zip(np.arange(0,size)+1,(np.arange(0,size)+1)*np.nan)},\n",
    "            **{'as'+str(key):[value] for key,value in zip(np.arange(0,size)+1,(np.arange(0,size)+1)*np.nan)}}\n",
    "\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from websocket import create_connection\n",
    "import json\n",
    "\n",
    "class StreamingData2():\n",
    "    def __init__(self):\n",
    "        self.depth = 5     \n",
    "        self.df_0 = None       \n",
    "        # self.model = joblib.load('/Users/fipm/code/abefarkas/Thalassa_Regime_Classifier/model.joblib')    \n",
    "        self.symbol = 'BTCUSDT'        \n",
    "        self.socket = 'wss://stream.binance.com:9443/ws/{}@depth{}'.format(self.symbol.lower(),self.depth)\n",
    "        self.ws = None\n",
    "        \n",
    "    # def handle_trades(self):    \n",
    "                \n",
    "        \n",
    "        # df_clean = self.my_return()\n",
    "        # if len(df_clean)>=1:\n",
    "        #     print(self.model.predict(df_clean))\n",
    "        #     send to database \n",
    "        # return self.model.predict(df_clean)\n",
    "        \n",
    "    def get_data(self, rolling_window=2):\n",
    "        df = pd.DataFrame.from_dict(self.my_json(json.loads(self.ws.recv())))\n",
    "        self.df_0 = pd.concat([self.df_0, df], axis=0)        \n",
    "        return self.preprocessing_streamed_data(self.df_0, rolling_window)\n",
    "\n",
    "    def start(self):        \n",
    "        self.df_0 = pd.DataFrame.from_dict(self.my_json_0(self.depth))\n",
    "        self.ws = create_connection(self.socket)\n",
    "        \n",
    "        \n",
    "    def preprocessing_streamed_data(self,df_ob, rolling_window):\n",
    "        '''preprocessing of data for streamed data'''                \n",
    "        \n",
    "        # aggregating by seconds     \n",
    "        df_agg = df_ob.groupby(pd.Grouper(key='primary_key', axis=0, freq='S')).mean()\n",
    "        # applying rolling window of rolling_window lenght\n",
    "        df_agg = df_agg.rolling(str(rolling_window)+'S').mean()\n",
    "        # moving the index as a column\n",
    "        df_agg.reset_index(inplace=True)\n",
    "        df_agg.reset_index(inplace=True)\n",
    "        df_agg = df_agg.dropna().tail(50)\n",
    "\n",
    "        return df_agg\n",
    "        \n",
    "    def my_json(self, json_message):\n",
    "        \n",
    "        size = len(np.array(json_message['bids'])[:,0])    \n",
    "        return {\n",
    "            **{'primary_key':[datetime.now()]},\n",
    "            **{'bp'+str(key):[float(value)] for key,value in zip(np.arange(0,size)+1,np.array(json_message['bids'])[:,0])},\n",
    "            **{'bs'+str(key):[float(value)] for key,value in zip(np.arange(0,size)+1,np.array(json_message['bids'])[:,1])},\n",
    "            **{'ap'+str(key):[float(value)] for key,value in zip(np.arange(0,size)+1,np.array(json_message['asks'])[:,0])},\n",
    "            **{'as'+str(key):[float(value)] for key,value in zip(np.arange(0,size)+1,np.array(json_message['asks'])[:,1])}}\n",
    "    \n",
    "    def my_json_0(self, size):    \n",
    "        return {\n",
    "            **{'primary_key':[datetime.now()]},\n",
    "            **{'bp'+str(key):[value] for key,value in zip(np.arange(0,size)+1,(np.arange(0,size)+1)*np.nan)},\n",
    "            **{'bs'+str(key):[value] for key,value in zip(np.arange(0,size)+1,(np.arange(0,size)+1)*np.nan)},\n",
    "            **{'ap'+str(key):[value] for key,value in zip(np.arange(0,size)+1,(np.arange(0,size)+1)*np.nan)},\n",
    "            **{'as'+str(key):[value] for key,value in zip(np.arange(0,size)+1,(np.arange(0,size)+1)*np.nan)}}\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = StreamingData2()\n",
    "w.start()\n",
    "while True:\n",
    "    print(w.get_data(rolling_window=2))\n",
    "    to_csv('name')\n",
    "    append\n",
    "    \n",
    "    nohup python app.py &    \n",
    "    ps aux | grep python\n",
    "    kill ID_of_process\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import WebSocket client library (and others)\n",
    "import websocket\n",
    "import _thread\n",
    "import time\n",
    "\n",
    "# Define WebSocket callback functions\n",
    "def ws_message(ws, message):\n",
    "    # print(\"WebSocket thread: %s\" % message)\n",
    "    print('di')\n",
    "\n",
    "def ws_open(ws):\n",
    "    ws.send('{\"event\":\"subscribe\", \"subscription\":{\"name\":\"trade\"}, \"pair\":[\"XBT/USD\",\"XRP/USD\"]}')\n",
    "\n",
    "def ws_thread(*args):\n",
    "    ws = websocket.WebSocketApp(\"wss://ws.kraken.com/\", on_open = ws_open, on_message = ws_message)\n",
    "    ws.run_forever()\n",
    "\n",
    "# Start a new thread for the WebSocket interface\n",
    "_thread.start_new_thread(ws_thread, ())\n",
    "\n",
    "# Continue other (non WebSocket) tasks in the main thread\n",
    "while True:\n",
    "    time.sleep(5)\n",
    "    print(\"Main thread: %d\" % time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import WebSocket client library\n",
    "from websocket import create_connection\n",
    "\n",
    "# Connect to WebSocket API and subscribe to trade feed for XBT/USD and XRP/USD\n",
    "\n",
    "ws = create_connection(\"wss://ws.kraken.com/\")\n",
    "ws.send('{\"event\":\"subscribe\", \"subscription\":{\"name\":\"trade\"}, \"pair\":[\"XBT/USD\",\"XRP/USD\"]}')\n",
    "\n",
    "# Infinite loop waiting for WebSocket data\n",
    "while True:\n",
    "    print(ws.recv())\n",
    "    \n",
    "    #     // URL connection\n",
    "    # const accountAndOrderAndTransfers = new WebSocket(\"wss://dex.binance.org/api/ws/bnb1m4m9etgf3ca5wpgkqe5nr6r33a4ynxfln3yz4v\");\n",
    "\n",
    "    # // Or Subscribe method\n",
    "    # const conn = new WebSocket(\"wss://dex.binance.org/api/ws\");\n",
    "    # conn.onopen = function(evt) {\n",
    "    #     conn.send(JSON.stringify({ method: \"subscribe\", topic: \"orders\", address: \"bnb1m4m9etgf3ca5wpgkqe5nr6r33a4ynxfln3yz4v\" }));\n",
    "    # }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import WebSocket client library\n",
    "from websocket import create_connection\n",
    "\n",
    "depth = 5     \n",
    "symbol = 'BTCUSDT'        \n",
    "socket = 'wss://stream.binance.com:9443/ws/{}@depth{}'.format(symbol.lower(),depth)\n",
    "# Connect to WebSocket API and subscribe to trade feed for XBT/USD and XRP/USD\n",
    "ws = create_connection(socket)\n",
    "# Infinite loop waiting for WebSocket data\n",
    "while True:\n",
    "    print(ws.recv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "# initialising dictionaries\n",
    "ini_dictionary1 = {'nikhil': 1, 'akash' : 5,\n",
    "                     'manjeet' : 10, 'akshat' : 15}\n",
    "ini_dictionary2 = {'akash' : 7, 'akshat' : 5,\n",
    "                                          'm' : 15}\n",
    "\n",
    "ini_dictionary1.update(ini_dictionary2)\n",
    "ini_dictionary1  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_message ={'lastUpdateId': 19493390097, \n",
    "               'bids': [['29724.70000000', '8.90412000'], ['29747.650000', '0.00429000'], ['29724.62000000', '0.08293000'], ['29724.61000000', '0.01998000'], ['29724.57000000', '0.16835000']], \n",
    "               'asks': [['29724.71000000', '0.00001000'], ['29724.72000000', '0.00075000'], ['29724.73000000', '0.01237000'], ['29724.75000000', '0.01237000'], ['29724.77000000', '0.01000000']]}\n",
    "\n",
    "\n",
    "{'bp'+str(key):value for key,value in zip(np.arange(0,5),np.array(json_message['bids'])[:,0]) }\n",
    "{'bs'+str(key):value for key,value in zip(np.arange(0,5),np.array(json_message['bids'])[:,1]) }\n",
    "{'bp'+str(key):value for key,value in zip(np.arange(0,5),np.array(json_message['bids'])[:,0]) }\n",
    "{'bp'+str(key):value for key,value in zip(np.arange(0,5),np.array(json_message['bids'])[:,0]) }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_message ={'lastUpdateId': 19493390097, \n",
    "               'bids': [['29724.70000000', '8.90412000'], ['nan', '0.00429000'], ['29724.62000000', '0.08293000'], ['29724.61000000', '0.01998000'], ['29724.57000000', '0.16835000']], \n",
    "               'asks': [['29724.71000000', '0.00001000'], ['29724.72000000', '0.00075000'], ['29724.73000000', '0.01237000'], ['29724.75000000', '0.01237000'], ['29724.77000000', '0.01000000']]}\n",
    "aaa(bp1) bid price 1 = 29724.70000000\n",
    "(bs1) bid size 1 = 8.90412000\n",
    "\n",
    "(ap1) asd price 1 = 29724.71000000\n",
    "(as1) ask size 1 = 0000100\n",
    "\n",
    "{'ts':json_message['lastUpdateId'],\n",
    "  'bp1':json_message['bids'][0][0],\n",
    "  'bp1':json_message['bids'][0][0],\n",
    "  'bp1':json_message['bids'][0][0],\n",
    "  'bp1':json_message['bids'][0][0],\n",
    "  'bp1':json_message['bids'][0][0],\n",
    "  'bp1':json_message['bids'][0][0],\n",
    "  'bp1':json_message['bids'][0][0],\n",
    "  'bp1':json_message['bids'][0][0],\n",
    "  'bp1':json_message['bids'][0][0],\n",
    "  'bp1':json_message['bids'][0][0],  \n",
    "  'bp1':json_message['bids'][0][0],\n",
    "  }\n",
    "\n",
    "symbol,ts,last_update_id,bp1,bs1,bp2,bs2,bp3,bs3,bp4,bs4,bp5,bs5,bp6,bs6,bp7,bs7,bp8,bs8,bp9,bs9,bp10,bs10,bp11,bs11,bp12,bs12,bp13,bs13,bp14,bs14,bp15,bs15,bp16,bs16,bp17,bs17,bp18,bs18,bp19,bs19,bp20,bs20,ap1,as1,ap2,as2,ap3,as3,ap4,as4,ap5,as5,ap6,as6,ap7,as7,ap8,as8,ap9,as9,ap10,as10,ap11,as11,ap12,as12,ap13,as13,ap14,as14,ap15,as15,ap16,as16,ap17,as17,ap18,as18,ap19,as19,ap20,as20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.streaming import StreamingContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment the next line to run the code block on jupyter. Keep it commented if copy-pasting into the pyspark shell\n",
    "sc = pyspark.SparkContext()\n",
    "\n",
    "# This tells Spark Streaming to bacth-up the contents of a data stream and \"ingest\" them every 10 seconds.\n",
    "ssc = StreamingContext(sc,10)\n",
    "\n",
    "# Tell spark to listen on port 9999 of our localhost.\n",
    "lines = ssc.socketTextStream('wss://stream.binance.com/ws/BTCUSDT@depth5', 9443)\n",
    "lines = ssc.socketTextStream('localhost', 9999)    \n",
    "\n",
    "words = lines.flatMap(lambda line : line.split(\" \"))\n",
    "\n",
    "pairs = words.map(lambda word: (word, 1))\n",
    "wordCount = pairs.reduceByKey(lambda a, b: a + b)\n",
    "\n",
    "wordCount.pprint()\n",
    "\n",
    "ssc.start()\n",
    "ssc.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment the next line to run the code block on jupyter. Keep it commented if copy-pasting into the pyspark shell\n",
    "sc = pyspark.SparkContext()\n",
    "\n",
    "# This tells Spark Streaming to bacth-up the contents of a data stream and \"ingest\" them every 10 seconds.\n",
    "ssc = StreamingContext(sc,10)\n",
    "\n",
    "# Tell spark to listen on port 9999 of our localhost.\n",
    "lines = ssc.socketTextStream('wss://stream.binance.com/ws/BTCUSDT@depth5', 9443)\n",
    "\n",
    "\n",
    "\n",
    "lines.pprint()\n",
    "\n",
    "ssc.start()\n",
    "ssc.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/fipm/code/abefarkas/Thalassa_Regime_Classifier/predicted_values.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(1)\n",
    "\n",
    "y = list(df[df.columns[pd.Series(df.columns).str.startswith('bp')]].tail(1).values[0])\n",
    "y = list([np.nan]*len(y))+y\n",
    "x = np.arange(1,len(y)+1)\n",
    "len(y)\n",
    "\n",
    "\n",
    "asks:[[number, number],[number, number],[number, number]]\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1f53de40d125f7884f636dff8497593e6e6ea391da6f1e4c596278056577faa2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('thalassa')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
