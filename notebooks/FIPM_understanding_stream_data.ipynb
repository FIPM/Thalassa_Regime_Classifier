{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import websocket\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_json(json_message):\n",
    "    size = len(np.array(json_message['bids'])[:,0])    \n",
    "    return {\n",
    "        **{'last_update_id':json_message['lastUpdateId']},\n",
    "        **{'bp'+str(key):[value] for key,value in zip(np.arange(0,size)+1,np.array(json_message['bids'])[:,0])},\n",
    "        **{'bs'+str(key):[value] for key,value in zip(np.arange(0,size)+1,np.array(json_message['bids'])[:,1])},\n",
    "        **{'ap'+str(key):[value] for key,value in zip(np.arange(0,size)+1,np.array(json_message['asks'])[:,0])},\n",
    "        **{'as'+str(key):[value] for key,value in zip(np.arange(0,size)+1,np.array(json_message['asks'])[:,1])}}\n",
    "    \n",
    "def my_json_0(size):    \n",
    "    return {\n",
    "        **{'last_update_id':np.nan},\n",
    "        **{'bp'+str(key):[value] for key,value in zip(np.arange(0,size)+1,(np.arange(0,size)+1)*np.nan)},\n",
    "        **{'bs'+str(key):[value] for key,value in zip(np.arange(0,size)+1,(np.arange(0,size)+1)*np.nan)},\n",
    "        **{'ap'+str(key):[value] for key,value in zip(np.arange(0,size)+1,(np.arange(0,size)+1)*np.nan)},\n",
    "        **{'as'+str(key):[value] for key,value in zip(np.arange(0,size)+1,(np.arange(0,size)+1)*np.nan)}}\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_0 = pd.DataFrame.from_dict(my_json_0(5))\n",
    "\n",
    "def ws_trades(df_0): \n",
    "    symbol = 'BTCUSDT'\n",
    "    depth = 5\n",
    "    socket = 'wss://stream.binance.com:9443/ws/{}@depth{}'.format(symbol.lower(),\n",
    "                                                                depth)\n",
    "    \n",
    "    \n",
    "    def on_message(wsapp,message):  \n",
    "        json_message = json.loads(message)\n",
    "        handle_trades(json_message)\n",
    "\n",
    "    def on_error(wsapp,error):\n",
    "        print(error)\n",
    "\n",
    "    wsapp = websocket.WebSocketApp(socket, on_message=on_message, on_error=on_error)\n",
    "    wsapp.run_forever()\n",
    "    \n",
    "def handle_trades(json_message):    \n",
    "    df = pd.DataFrame.from_dict(my_json(json_message))\n",
    "    df_0 = df_0.append(df, ignore_index = True)\n",
    "    \n",
    "    print(df_0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StreamingData():\n",
    "    def __init__(self,df_0):\n",
    "        self.df_0=df_0\n",
    "        self.symbol = 'BTCUSDT'\n",
    "        self.depth = 5        \n",
    "        self.socket = 'wss://stream.binance.com:9443/ws/{}@depth{}'.format(self.symbol.lower(),self.depth)\n",
    "        \n",
    "    def handle_trades(self,json_message):    \n",
    "        df = pd.DataFrame.from_dict(my_json(json_message))\n",
    "        self.df_0 = self.df_0.append(df, ignore_index = True)        \n",
    "                \n",
    "    def my_return(self):\n",
    "        return self.df_0\n",
    "\n",
    "    def on_message(self,wsapp,message):  \n",
    "        json_message = json.loads(message)\n",
    "        self.handle_trades(json_message)\n",
    "\n",
    "    def on_error(self,wsapp,error):\n",
    "        print(error)\n",
    "\n",
    "    def start(self):\n",
    "        wsapp = websocket.WebSocketApp(self.socket, on_message=self.on_message, on_error=self.on_error)\n",
    "        wsapp.run_forever()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   last_update_id  bp1  bp2  bp3  bp4  bp5  bs1  bs2  bs3  bs4  ...  ap1  ap2  \\\n",
      "0             NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN   \n",
      "\n",
      "   ap3  ap4  ap5  as1  as2  as3  as4  as5  \n",
      "0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "\n",
      "[1 rows x 21 columns]\n",
      "   last_update_id             bp1             bp2             bp3  \\\n",
      "0             NaN             NaN             NaN             NaN   \n",
      "1    1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "\n",
      "              bp4             bp5         bs1         bs2         bs3  \\\n",
      "0             NaN             NaN         NaN         NaN         NaN   \n",
      "1  29819.48000000  29819.39000000  0.60625000  0.24868000  0.23807000   \n",
      "\n",
      "          bs4  ...             ap1             ap2             ap3  \\\n",
      "0         NaN  ...             NaN             NaN             NaN   \n",
      "1  0.02032000  ...  29820.00000000  29820.02000000  29820.04000000   \n",
      "\n",
      "              ap4             ap5         as1         as2         as3  \\\n",
      "0             NaN             NaN         NaN         NaN         NaN   \n",
      "1  29820.09000000  29820.11000000  1.92227000  0.02688000  0.02689000   \n",
      "\n",
      "          as4         as5  \n",
      "0         NaN         NaN  \n",
      "1  0.00222000  0.08000000  \n",
      "\n",
      "[2 rows x 21 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/91/6wbfy1kd3c54vx64tq8sck_00000gn/T/ipykernel_6976/3022916258.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.df_0 = self.df_0.append(df, ignore_index = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   last_update_id             bp1             bp2             bp3  \\\n",
      "0             NaN             NaN             NaN             NaN   \n",
      "1    1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "\n",
      "              bp4             bp5         bs1         bs2         bs3  \\\n",
      "0             NaN             NaN         NaN         NaN         NaN   \n",
      "1  29819.48000000  29819.39000000  0.60625000  0.24868000  0.23807000   \n",
      "\n",
      "          bs4  ...             ap1             ap2             ap3  \\\n",
      "0         NaN  ...             NaN             NaN             NaN   \n",
      "1  0.02032000  ...  29820.00000000  29820.02000000  29820.04000000   \n",
      "\n",
      "              ap4             ap5         as1         as2         as3  \\\n",
      "0             NaN             NaN         NaN         NaN         NaN   \n",
      "1  29820.09000000  29820.11000000  1.92227000  0.02688000  0.02689000   \n",
      "\n",
      "          as4         as5  \n",
      "0         NaN         NaN  \n",
      "1  0.00222000  0.08000000  \n",
      "\n",
      "[2 rows x 21 columns]\n",
      "   last_update_id             bp1             bp2             bp3  \\\n",
      "0             NaN             NaN             NaN             NaN   \n",
      "1    1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "2    1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "\n",
      "              bp4             bp5         bs1         bs2         bs3  \\\n",
      "0             NaN             NaN         NaN         NaN         NaN   \n",
      "1  29819.48000000  29819.39000000  0.60625000  0.24868000  0.23807000   \n",
      "2  29819.39000000  29819.32000000  0.68641000  0.24868000  0.23807000   \n",
      "\n",
      "          bs4  ...             ap1             ap2             ap3  \\\n",
      "0         NaN  ...             NaN             NaN             NaN   \n",
      "1  0.02032000  ...  29820.00000000  29820.02000000  29820.04000000   \n",
      "2  0.00373000  ...  29820.00000000  29820.02000000  29820.09000000   \n",
      "\n",
      "              ap4             ap5         as1         as2         as3  \\\n",
      "0             NaN             NaN         NaN         NaN         NaN   \n",
      "1  29820.09000000  29820.11000000  1.92227000  0.02688000  0.02689000   \n",
      "2  29820.11000000  29820.20000000  2.48119000  0.02688000  0.00222000   \n",
      "\n",
      "          as4         as5  \n",
      "0         NaN         NaN  \n",
      "1  0.00222000  0.08000000  \n",
      "2  0.08000000  0.00108000  \n",
      "\n",
      "[3 rows x 21 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/91/6wbfy1kd3c54vx64tq8sck_00000gn/T/ipykernel_6976/3022916258.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.df_0 = self.df_0.append(df, ignore_index = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   last_update_id             bp1             bp2             bp3  \\\n",
      "0             NaN             NaN             NaN             NaN   \n",
      "1    1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "2    1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "\n",
      "              bp4             bp5         bs1         bs2         bs3  \\\n",
      "0             NaN             NaN         NaN         NaN         NaN   \n",
      "1  29819.48000000  29819.39000000  0.60625000  0.24868000  0.23807000   \n",
      "2  29819.39000000  29819.32000000  0.68641000  0.24868000  0.23807000   \n",
      "\n",
      "          bs4  ...             ap1             ap2             ap3  \\\n",
      "0         NaN  ...             NaN             NaN             NaN   \n",
      "1  0.02032000  ...  29820.00000000  29820.02000000  29820.04000000   \n",
      "2  0.00373000  ...  29820.00000000  29820.02000000  29820.09000000   \n",
      "\n",
      "              ap4             ap5         as1         as2         as3  \\\n",
      "0             NaN             NaN         NaN         NaN         NaN   \n",
      "1  29820.09000000  29820.11000000  1.92227000  0.02688000  0.02689000   \n",
      "2  29820.11000000  29820.20000000  2.48119000  0.02688000  0.00222000   \n",
      "\n",
      "          as4         as5  \n",
      "0         NaN         NaN  \n",
      "1  0.00222000  0.08000000  \n",
      "2  0.08000000  0.00108000  \n",
      "\n",
      "[3 rows x 21 columns]\n",
      "   last_update_id             bp1             bp2             bp3  \\\n",
      "0             NaN             NaN             NaN             NaN   \n",
      "1    1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "2    1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "3    1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "\n",
      "              bp4             bp5         bs1         bs2         bs3  \\\n",
      "0             NaN             NaN         NaN         NaN         NaN   \n",
      "1  29819.48000000  29819.39000000  0.60625000  0.24868000  0.23807000   \n",
      "2  29819.39000000  29819.32000000  0.68641000  0.24868000  0.23807000   \n",
      "3  29819.32000000  29819.10000000  0.30421000  0.23807000  0.00373000   \n",
      "\n",
      "          bs4  ...             ap1             ap2             ap3  \\\n",
      "0         NaN  ...             NaN             NaN             NaN   \n",
      "1  0.02032000  ...  29820.00000000  29820.02000000  29820.04000000   \n",
      "2  0.00373000  ...  29820.00000000  29820.02000000  29820.09000000   \n",
      "3  0.00545000  ...  29819.59000000  29819.64000000  29819.65000000   \n",
      "\n",
      "              ap4             ap5         as1         as2         as3  \\\n",
      "0             NaN             NaN         NaN         NaN         NaN   \n",
      "1  29820.09000000  29820.11000000  1.92227000  0.02688000  0.02689000   \n",
      "2  29820.11000000  29820.20000000  2.48119000  0.02688000  0.00222000   \n",
      "3  29819.70000000  29819.75000000  3.90382000  0.03046000  0.00074000   \n",
      "\n",
      "          as4         as5  \n",
      "0         NaN         NaN  \n",
      "1  0.00222000  0.08000000  \n",
      "2  0.08000000  0.00108000  \n",
      "3  0.00036000  0.08293000  \n",
      "\n",
      "[4 rows x 21 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/91/6wbfy1kd3c54vx64tq8sck_00000gn/T/ipykernel_6976/3022916258.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.df_0 = self.df_0.append(df, ignore_index = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   last_update_id             bp1             bp2             bp3  \\\n",
      "0             NaN             NaN             NaN             NaN   \n",
      "1    1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "2    1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "3    1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "\n",
      "              bp4             bp5         bs1         bs2         bs3  \\\n",
      "0             NaN             NaN         NaN         NaN         NaN   \n",
      "1  29819.48000000  29819.39000000  0.60625000  0.24868000  0.23807000   \n",
      "2  29819.39000000  29819.32000000  0.68641000  0.24868000  0.23807000   \n",
      "3  29819.32000000  29819.10000000  0.30421000  0.23807000  0.00373000   \n",
      "\n",
      "          bs4  ...             ap1             ap2             ap3  \\\n",
      "0         NaN  ...             NaN             NaN             NaN   \n",
      "1  0.02032000  ...  29820.00000000  29820.02000000  29820.04000000   \n",
      "2  0.00373000  ...  29820.00000000  29820.02000000  29820.09000000   \n",
      "3  0.00545000  ...  29819.59000000  29819.64000000  29819.65000000   \n",
      "\n",
      "              ap4             ap5         as1         as2         as3  \\\n",
      "0             NaN             NaN         NaN         NaN         NaN   \n",
      "1  29820.09000000  29820.11000000  1.92227000  0.02688000  0.02689000   \n",
      "2  29820.11000000  29820.20000000  2.48119000  0.02688000  0.00222000   \n",
      "3  29819.70000000  29819.75000000  3.90382000  0.03046000  0.00074000   \n",
      "\n",
      "          as4         as5  \n",
      "0         NaN         NaN  \n",
      "1  0.00222000  0.08000000  \n",
      "2  0.08000000  0.00108000  \n",
      "3  0.00036000  0.08293000  \n",
      "\n",
      "[4 rows x 21 columns]\n",
      "   last_update_id             bp1             bp2             bp3  \\\n",
      "0             NaN             NaN             NaN             NaN   \n",
      "1    1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "2    1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "3    1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "4    1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "\n",
      "              bp4             bp5         bs1         bs2         bs3  \\\n",
      "0             NaN             NaN         NaN         NaN         NaN   \n",
      "1  29819.48000000  29819.39000000  0.60625000  0.24868000  0.23807000   \n",
      "2  29819.39000000  29819.32000000  0.68641000  0.24868000  0.23807000   \n",
      "3  29819.32000000  29819.10000000  0.30421000  0.23807000  0.00373000   \n",
      "4  29819.32000000  29819.10000000  0.91948000  0.23807000  0.00373000   \n",
      "\n",
      "          bs4  ...             ap1             ap2             ap3  \\\n",
      "0         NaN  ...             NaN             NaN             NaN   \n",
      "1  0.02032000  ...  29820.00000000  29820.02000000  29820.04000000   \n",
      "2  0.00373000  ...  29820.00000000  29820.02000000  29820.09000000   \n",
      "3  0.00545000  ...  29819.59000000  29819.64000000  29819.65000000   \n",
      "4  0.00042000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "\n",
      "              ap4             ap5         as1         as2         as3  \\\n",
      "0             NaN             NaN         NaN         NaN         NaN   \n",
      "1  29820.09000000  29820.11000000  1.92227000  0.02688000  0.02689000   \n",
      "2  29820.11000000  29820.20000000  2.48119000  0.02688000  0.00222000   \n",
      "3  29819.70000000  29819.75000000  3.90382000  0.03046000  0.00074000   \n",
      "4  29819.75000000  29820.00000000  1.98067000  0.00074000  0.00036000   \n",
      "\n",
      "          as4         as5  \n",
      "0         NaN         NaN  \n",
      "1  0.00222000  0.08000000  \n",
      "2  0.08000000  0.00108000  \n",
      "3  0.00036000  0.08293000  \n",
      "4  0.08293000  1.00447000  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/91/6wbfy1kd3c54vx64tq8sck_00000gn/T/ipykernel_6976/3022916258.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.df_0 = self.df_0.append(df, ignore_index = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   last_update_id             bp1             bp2             bp3  \\\n",
      "0             NaN             NaN             NaN             NaN   \n",
      "1    1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "2    1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "3    1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "4    1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "\n",
      "              bp4             bp5         bs1         bs2         bs3  \\\n",
      "0             NaN             NaN         NaN         NaN         NaN   \n",
      "1  29819.48000000  29819.39000000  0.60625000  0.24868000  0.23807000   \n",
      "2  29819.39000000  29819.32000000  0.68641000  0.24868000  0.23807000   \n",
      "3  29819.32000000  29819.10000000  0.30421000  0.23807000  0.00373000   \n",
      "4  29819.32000000  29819.10000000  0.91948000  0.23807000  0.00373000   \n",
      "\n",
      "          bs4  ...             ap1             ap2             ap3  \\\n",
      "0         NaN  ...             NaN             NaN             NaN   \n",
      "1  0.02032000  ...  29820.00000000  29820.02000000  29820.04000000   \n",
      "2  0.00373000  ...  29820.00000000  29820.02000000  29820.09000000   \n",
      "3  0.00545000  ...  29819.59000000  29819.64000000  29819.65000000   \n",
      "4  0.00042000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "\n",
      "              ap4             ap5         as1         as2         as3  \\\n",
      "0             NaN             NaN         NaN         NaN         NaN   \n",
      "1  29820.09000000  29820.11000000  1.92227000  0.02688000  0.02689000   \n",
      "2  29820.11000000  29820.20000000  2.48119000  0.02688000  0.00222000   \n",
      "3  29819.70000000  29819.75000000  3.90382000  0.03046000  0.00074000   \n",
      "4  29819.75000000  29820.00000000  1.98067000  0.00074000  0.00036000   \n",
      "\n",
      "          as4         as5  \n",
      "0         NaN         NaN  \n",
      "1  0.00222000  0.08000000  \n",
      "2  0.08000000  0.00108000  \n",
      "3  0.00036000  0.08293000  \n",
      "4  0.08293000  1.00447000  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "   last_update_id             bp1             bp2             bp3  \\\n",
      "0             NaN             NaN             NaN             NaN   \n",
      "1    1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "2    1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "3    1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "4    1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "5    1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "\n",
      "              bp4             bp5         bs1         bs2         bs3  \\\n",
      "0             NaN             NaN         NaN         NaN         NaN   \n",
      "1  29819.48000000  29819.39000000  0.60625000  0.24868000  0.23807000   \n",
      "2  29819.39000000  29819.32000000  0.68641000  0.24868000  0.23807000   \n",
      "3  29819.32000000  29819.10000000  0.30421000  0.23807000  0.00373000   \n",
      "4  29819.32000000  29819.10000000  0.91948000  0.23807000  0.00373000   \n",
      "5  29819.32000000  29819.10000000  0.39849000  0.23807000  0.01755000   \n",
      "\n",
      "          bs4  ...             ap1             ap2             ap3  \\\n",
      "0         NaN  ...             NaN             NaN             NaN   \n",
      "1  0.02032000  ...  29820.00000000  29820.02000000  29820.04000000   \n",
      "2  0.00373000  ...  29820.00000000  29820.02000000  29820.09000000   \n",
      "3  0.00545000  ...  29819.59000000  29819.64000000  29819.65000000   \n",
      "4  0.00042000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "5  0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "\n",
      "              ap4             ap5         as1         as2         as3  \\\n",
      "0             NaN             NaN         NaN         NaN         NaN   \n",
      "1  29820.09000000  29820.11000000  1.92227000  0.02688000  0.02689000   \n",
      "2  29820.11000000  29820.20000000  2.48119000  0.02688000  0.00222000   \n",
      "3  29819.70000000  29819.75000000  3.90382000  0.03046000  0.00074000   \n",
      "4  29819.75000000  29820.00000000  1.98067000  0.00074000  0.00036000   \n",
      "5  29819.70000000  29820.00000000  1.90625000  0.01450000  0.00074000   \n",
      "\n",
      "          as4         as5  \n",
      "0         NaN         NaN  \n",
      "1  0.00222000  0.08000000  \n",
      "2  0.08000000  0.00108000  \n",
      "3  0.00036000  0.08293000  \n",
      "4  0.08293000  1.00447000  \n",
      "5  0.00036000  1.11033000  \n",
      "\n",
      "[6 rows x 21 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/91/6wbfy1kd3c54vx64tq8sck_00000gn/T/ipykernel_6976/3022916258.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.df_0 = self.df_0.append(df, ignore_index = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   last_update_id             bp1             bp2             bp3  \\\n",
      "0             NaN             NaN             NaN             NaN   \n",
      "1    1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "2    1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "3    1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "4    1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "5    1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "\n",
      "              bp4             bp5         bs1         bs2         bs3  \\\n",
      "0             NaN             NaN         NaN         NaN         NaN   \n",
      "1  29819.48000000  29819.39000000  0.60625000  0.24868000  0.23807000   \n",
      "2  29819.39000000  29819.32000000  0.68641000  0.24868000  0.23807000   \n",
      "3  29819.32000000  29819.10000000  0.30421000  0.23807000  0.00373000   \n",
      "4  29819.32000000  29819.10000000  0.91948000  0.23807000  0.00373000   \n",
      "5  29819.32000000  29819.10000000  0.39849000  0.23807000  0.01755000   \n",
      "\n",
      "          bs4  ...             ap1             ap2             ap3  \\\n",
      "0         NaN  ...             NaN             NaN             NaN   \n",
      "1  0.02032000  ...  29820.00000000  29820.02000000  29820.04000000   \n",
      "2  0.00373000  ...  29820.00000000  29820.02000000  29820.09000000   \n",
      "3  0.00545000  ...  29819.59000000  29819.64000000  29819.65000000   \n",
      "4  0.00042000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "5  0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "\n",
      "              ap4             ap5         as1         as2         as3  \\\n",
      "0             NaN             NaN         NaN         NaN         NaN   \n",
      "1  29820.09000000  29820.11000000  1.92227000  0.02688000  0.02689000   \n",
      "2  29820.11000000  29820.20000000  2.48119000  0.02688000  0.00222000   \n",
      "3  29819.70000000  29819.75000000  3.90382000  0.03046000  0.00074000   \n",
      "4  29819.75000000  29820.00000000  1.98067000  0.00074000  0.00036000   \n",
      "5  29819.70000000  29820.00000000  1.90625000  0.01450000  0.00074000   \n",
      "\n",
      "          as4         as5  \n",
      "0         NaN         NaN  \n",
      "1  0.00222000  0.08000000  \n",
      "2  0.08000000  0.00108000  \n",
      "3  0.00036000  0.08293000  \n",
      "4  0.08293000  1.00447000  \n",
      "5  0.00036000  1.11033000  \n",
      "\n",
      "[6 rows x 21 columns]\n",
      "   last_update_id             bp1             bp2             bp3  \\\n",
      "0             NaN             NaN             NaN             NaN   \n",
      "1    1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "2    1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "3    1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "4    1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "5    1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "6    1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "\n",
      "              bp4             bp5         bs1         bs2         bs3  \\\n",
      "0             NaN             NaN         NaN         NaN         NaN   \n",
      "1  29819.48000000  29819.39000000  0.60625000  0.24868000  0.23807000   \n",
      "2  29819.39000000  29819.32000000  0.68641000  0.24868000  0.23807000   \n",
      "3  29819.32000000  29819.10000000  0.30421000  0.23807000  0.00373000   \n",
      "4  29819.32000000  29819.10000000  0.91948000  0.23807000  0.00373000   \n",
      "5  29819.32000000  29819.10000000  0.39849000  0.23807000  0.01755000   \n",
      "6  29819.32000000  29819.10000000  0.40640000  0.23807000  0.01755000   \n",
      "\n",
      "          bs4  ...             ap1             ap2             ap3  \\\n",
      "0         NaN  ...             NaN             NaN             NaN   \n",
      "1  0.02032000  ...  29820.00000000  29820.02000000  29820.04000000   \n",
      "2  0.00373000  ...  29820.00000000  29820.02000000  29820.09000000   \n",
      "3  0.00545000  ...  29819.59000000  29819.64000000  29819.65000000   \n",
      "4  0.00042000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "5  0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "6  0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "\n",
      "              ap4             ap5         as1         as2         as3  \\\n",
      "0             NaN             NaN         NaN         NaN         NaN   \n",
      "1  29820.09000000  29820.11000000  1.92227000  0.02688000  0.02689000   \n",
      "2  29820.11000000  29820.20000000  2.48119000  0.02688000  0.00222000   \n",
      "3  29819.70000000  29819.75000000  3.90382000  0.03046000  0.00074000   \n",
      "4  29819.75000000  29820.00000000  1.98067000  0.00074000  0.00036000   \n",
      "5  29819.70000000  29820.00000000  1.90625000  0.01450000  0.00074000   \n",
      "6  29819.70000000  29820.00000000  1.90545000  0.01450000  0.00074000   \n",
      "\n",
      "          as4         as5  \n",
      "0         NaN         NaN  \n",
      "1  0.00222000  0.08000000  \n",
      "2  0.08000000  0.00108000  \n",
      "3  0.00036000  0.08293000  \n",
      "4  0.08293000  1.00447000  \n",
      "5  0.00036000  1.11033000  \n",
      "6  0.00036000  1.11033000  \n",
      "\n",
      "[7 rows x 21 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/91/6wbfy1kd3c54vx64tq8sck_00000gn/T/ipykernel_6976/3022916258.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.df_0 = self.df_0.append(df, ignore_index = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   last_update_id             bp1             bp2             bp3  \\\n",
      "0             NaN             NaN             NaN             NaN   \n",
      "1    1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "2    1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "3    1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "4    1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "5    1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "6    1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "\n",
      "              bp4             bp5         bs1         bs2         bs3  \\\n",
      "0             NaN             NaN         NaN         NaN         NaN   \n",
      "1  29819.48000000  29819.39000000  0.60625000  0.24868000  0.23807000   \n",
      "2  29819.39000000  29819.32000000  0.68641000  0.24868000  0.23807000   \n",
      "3  29819.32000000  29819.10000000  0.30421000  0.23807000  0.00373000   \n",
      "4  29819.32000000  29819.10000000  0.91948000  0.23807000  0.00373000   \n",
      "5  29819.32000000  29819.10000000  0.39849000  0.23807000  0.01755000   \n",
      "6  29819.32000000  29819.10000000  0.40640000  0.23807000  0.01755000   \n",
      "\n",
      "          bs4  ...             ap1             ap2             ap3  \\\n",
      "0         NaN  ...             NaN             NaN             NaN   \n",
      "1  0.02032000  ...  29820.00000000  29820.02000000  29820.04000000   \n",
      "2  0.00373000  ...  29820.00000000  29820.02000000  29820.09000000   \n",
      "3  0.00545000  ...  29819.59000000  29819.64000000  29819.65000000   \n",
      "4  0.00042000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "5  0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "6  0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "\n",
      "              ap4             ap5         as1         as2         as3  \\\n",
      "0             NaN             NaN         NaN         NaN         NaN   \n",
      "1  29820.09000000  29820.11000000  1.92227000  0.02688000  0.02689000   \n",
      "2  29820.11000000  29820.20000000  2.48119000  0.02688000  0.00222000   \n",
      "3  29819.70000000  29819.75000000  3.90382000  0.03046000  0.00074000   \n",
      "4  29819.75000000  29820.00000000  1.98067000  0.00074000  0.00036000   \n",
      "5  29819.70000000  29820.00000000  1.90625000  0.01450000  0.00074000   \n",
      "6  29819.70000000  29820.00000000  1.90545000  0.01450000  0.00074000   \n",
      "\n",
      "          as4         as5  \n",
      "0         NaN         NaN  \n",
      "1  0.00222000  0.08000000  \n",
      "2  0.08000000  0.00108000  \n",
      "3  0.00036000  0.08293000  \n",
      "4  0.08293000  1.00447000  \n",
      "5  0.00036000  1.11033000  \n",
      "6  0.00036000  1.11033000  \n",
      "\n",
      "[7 rows x 21 columns]\n",
      "   last_update_id             bp1             bp2             bp3  \\\n",
      "0             NaN             NaN             NaN             NaN   \n",
      "1    1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "2    1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "3    1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "4    1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "5    1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "6    1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "7    1.950054e+10  29819.58000000  29819.57000000  29819.32000000   \n",
      "\n",
      "              bp4             bp5         bs1         bs2         bs3  \\\n",
      "0             NaN             NaN         NaN         NaN         NaN   \n",
      "1  29819.48000000  29819.39000000  0.60625000  0.24868000  0.23807000   \n",
      "2  29819.39000000  29819.32000000  0.68641000  0.24868000  0.23807000   \n",
      "3  29819.32000000  29819.10000000  0.30421000  0.23807000  0.00373000   \n",
      "4  29819.32000000  29819.10000000  0.91948000  0.23807000  0.00373000   \n",
      "5  29819.32000000  29819.10000000  0.39849000  0.23807000  0.01755000   \n",
      "6  29819.32000000  29819.10000000  0.40640000  0.23807000  0.01755000   \n",
      "7  29819.10000000  29816.96000000  0.55670000  0.23807000  0.00042000   \n",
      "\n",
      "          bs4  ...             ap1             ap2             ap3  \\\n",
      "0         NaN  ...             NaN             NaN             NaN   \n",
      "1  0.02032000  ...  29820.00000000  29820.02000000  29820.04000000   \n",
      "2  0.00373000  ...  29820.00000000  29820.02000000  29820.09000000   \n",
      "3  0.00545000  ...  29819.59000000  29819.64000000  29819.65000000   \n",
      "4  0.00042000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "5  0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "6  0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "7  0.01000000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "\n",
      "              ap4             ap5         as1         as2         as3  \\\n",
      "0             NaN             NaN         NaN         NaN         NaN   \n",
      "1  29820.09000000  29820.11000000  1.92227000  0.02688000  0.02689000   \n",
      "2  29820.11000000  29820.20000000  2.48119000  0.02688000  0.00222000   \n",
      "3  29819.70000000  29819.75000000  3.90382000  0.03046000  0.00074000   \n",
      "4  29819.75000000  29820.00000000  1.98067000  0.00074000  0.00036000   \n",
      "5  29819.70000000  29820.00000000  1.90625000  0.01450000  0.00074000   \n",
      "6  29819.70000000  29820.00000000  1.90545000  0.01450000  0.00074000   \n",
      "7  29820.00000000  29820.09000000  1.88693000  0.00074000  0.00036000   \n",
      "\n",
      "          as4         as5  \n",
      "0         NaN         NaN  \n",
      "1  0.00222000  0.08000000  \n",
      "2  0.08000000  0.00108000  \n",
      "3  0.00036000  0.08293000  \n",
      "4  0.08293000  1.00447000  \n",
      "5  0.00036000  1.11033000  \n",
      "6  0.00036000  1.11033000  \n",
      "7  1.08021000  0.07605000  \n",
      "\n",
      "[8 rows x 21 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/91/6wbfy1kd3c54vx64tq8sck_00000gn/T/ipykernel_6976/3022916258.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.df_0 = self.df_0.append(df, ignore_index = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   last_update_id             bp1             bp2             bp3  \\\n",
      "0             NaN             NaN             NaN             NaN   \n",
      "1    1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "2    1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "3    1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "4    1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "5    1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "6    1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "7    1.950054e+10  29819.58000000  29819.57000000  29819.32000000   \n",
      "\n",
      "              bp4             bp5         bs1         bs2         bs3  \\\n",
      "0             NaN             NaN         NaN         NaN         NaN   \n",
      "1  29819.48000000  29819.39000000  0.60625000  0.24868000  0.23807000   \n",
      "2  29819.39000000  29819.32000000  0.68641000  0.24868000  0.23807000   \n",
      "3  29819.32000000  29819.10000000  0.30421000  0.23807000  0.00373000   \n",
      "4  29819.32000000  29819.10000000  0.91948000  0.23807000  0.00373000   \n",
      "5  29819.32000000  29819.10000000  0.39849000  0.23807000  0.01755000   \n",
      "6  29819.32000000  29819.10000000  0.40640000  0.23807000  0.01755000   \n",
      "7  29819.10000000  29816.96000000  0.55670000  0.23807000  0.00042000   \n",
      "\n",
      "          bs4  ...             ap1             ap2             ap3  \\\n",
      "0         NaN  ...             NaN             NaN             NaN   \n",
      "1  0.02032000  ...  29820.00000000  29820.02000000  29820.04000000   \n",
      "2  0.00373000  ...  29820.00000000  29820.02000000  29820.09000000   \n",
      "3  0.00545000  ...  29819.59000000  29819.64000000  29819.65000000   \n",
      "4  0.00042000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "5  0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "6  0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "7  0.01000000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "\n",
      "              ap4             ap5         as1         as2         as3  \\\n",
      "0             NaN             NaN         NaN         NaN         NaN   \n",
      "1  29820.09000000  29820.11000000  1.92227000  0.02688000  0.02689000   \n",
      "2  29820.11000000  29820.20000000  2.48119000  0.02688000  0.00222000   \n",
      "3  29819.70000000  29819.75000000  3.90382000  0.03046000  0.00074000   \n",
      "4  29819.75000000  29820.00000000  1.98067000  0.00074000  0.00036000   \n",
      "5  29819.70000000  29820.00000000  1.90625000  0.01450000  0.00074000   \n",
      "6  29819.70000000  29820.00000000  1.90545000  0.01450000  0.00074000   \n",
      "7  29820.00000000  29820.09000000  1.88693000  0.00074000  0.00036000   \n",
      "\n",
      "          as4         as5  \n",
      "0         NaN         NaN  \n",
      "1  0.00222000  0.08000000  \n",
      "2  0.08000000  0.00108000  \n",
      "3  0.00036000  0.08293000  \n",
      "4  0.08293000  1.00447000  \n",
      "5  0.00036000  1.11033000  \n",
      "6  0.00036000  1.11033000  \n",
      "7  1.08021000  0.07605000  \n",
      "\n",
      "[8 rows x 21 columns]\n",
      "   last_update_id             bp1             bp2             bp3  \\\n",
      "0             NaN             NaN             NaN             NaN   \n",
      "1    1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "2    1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "3    1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "4    1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "5    1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "6    1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "7    1.950054e+10  29819.58000000  29819.57000000  29819.32000000   \n",
      "8    1.950054e+10  29819.58000000  29819.57000000  29819.10000000   \n",
      "\n",
      "              bp4             bp5         bs1         bs2         bs3  \\\n",
      "0             NaN             NaN         NaN         NaN         NaN   \n",
      "1  29819.48000000  29819.39000000  0.60625000  0.24868000  0.23807000   \n",
      "2  29819.39000000  29819.32000000  0.68641000  0.24868000  0.23807000   \n",
      "3  29819.32000000  29819.10000000  0.30421000  0.23807000  0.00373000   \n",
      "4  29819.32000000  29819.10000000  0.91948000  0.23807000  0.00373000   \n",
      "5  29819.32000000  29819.10000000  0.39849000  0.23807000  0.01755000   \n",
      "6  29819.32000000  29819.10000000  0.40640000  0.23807000  0.01755000   \n",
      "7  29819.10000000  29816.96000000  0.55670000  0.23807000  0.00042000   \n",
      "8  29817.67000000  29816.77000000  0.17616000  0.23807000  0.01000000   \n",
      "\n",
      "          bs4  ...             ap1             ap2             ap3  \\\n",
      "0         NaN  ...             NaN             NaN             NaN   \n",
      "1  0.02032000  ...  29820.00000000  29820.02000000  29820.04000000   \n",
      "2  0.00373000  ...  29820.00000000  29820.02000000  29820.09000000   \n",
      "3  0.00545000  ...  29819.59000000  29819.64000000  29819.65000000   \n",
      "4  0.00042000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "5  0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "6  0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "7  0.01000000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "8  0.00450000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "\n",
      "              ap4             ap5         as1         as2         as3  \\\n",
      "0             NaN             NaN         NaN         NaN         NaN   \n",
      "1  29820.09000000  29820.11000000  1.92227000  0.02688000  0.02689000   \n",
      "2  29820.11000000  29820.20000000  2.48119000  0.02688000  0.00222000   \n",
      "3  29819.70000000  29819.75000000  3.90382000  0.03046000  0.00074000   \n",
      "4  29819.75000000  29820.00000000  1.98067000  0.00074000  0.00036000   \n",
      "5  29819.70000000  29820.00000000  1.90625000  0.01450000  0.00074000   \n",
      "6  29819.70000000  29820.00000000  1.90545000  0.01450000  0.00074000   \n",
      "7  29820.00000000  29820.09000000  1.88693000  0.00074000  0.00036000   \n",
      "8  29819.71000000  29819.99000000  2.15159000  0.00074000  0.00036000   \n",
      "\n",
      "          as4         as5  \n",
      "0         NaN         NaN  \n",
      "1  0.00222000  0.08000000  \n",
      "2  0.08000000  0.00108000  \n",
      "3  0.00036000  0.08293000  \n",
      "4  0.08293000  1.00447000  \n",
      "5  0.00036000  1.11033000  \n",
      "6  0.00036000  1.11033000  \n",
      "7  1.08021000  0.07605000  \n",
      "8  0.08293000  0.49787000  \n",
      "\n",
      "[9 rows x 21 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/91/6wbfy1kd3c54vx64tq8sck_00000gn/T/ipykernel_6976/3022916258.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.df_0 = self.df_0.append(df, ignore_index = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   last_update_id             bp1             bp2             bp3  \\\n",
      "0             NaN             NaN             NaN             NaN   \n",
      "1    1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "2    1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "3    1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "4    1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "5    1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "6    1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "7    1.950054e+10  29819.58000000  29819.57000000  29819.32000000   \n",
      "8    1.950054e+10  29819.58000000  29819.57000000  29819.10000000   \n",
      "\n",
      "              bp4             bp5         bs1         bs2         bs3  \\\n",
      "0             NaN             NaN         NaN         NaN         NaN   \n",
      "1  29819.48000000  29819.39000000  0.60625000  0.24868000  0.23807000   \n",
      "2  29819.39000000  29819.32000000  0.68641000  0.24868000  0.23807000   \n",
      "3  29819.32000000  29819.10000000  0.30421000  0.23807000  0.00373000   \n",
      "4  29819.32000000  29819.10000000  0.91948000  0.23807000  0.00373000   \n",
      "5  29819.32000000  29819.10000000  0.39849000  0.23807000  0.01755000   \n",
      "6  29819.32000000  29819.10000000  0.40640000  0.23807000  0.01755000   \n",
      "7  29819.10000000  29816.96000000  0.55670000  0.23807000  0.00042000   \n",
      "8  29817.67000000  29816.77000000  0.17616000  0.23807000  0.01000000   \n",
      "\n",
      "          bs4  ...             ap1             ap2             ap3  \\\n",
      "0         NaN  ...             NaN             NaN             NaN   \n",
      "1  0.02032000  ...  29820.00000000  29820.02000000  29820.04000000   \n",
      "2  0.00373000  ...  29820.00000000  29820.02000000  29820.09000000   \n",
      "3  0.00545000  ...  29819.59000000  29819.64000000  29819.65000000   \n",
      "4  0.00042000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "5  0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "6  0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "7  0.01000000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "8  0.00450000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "\n",
      "              ap4             ap5         as1         as2         as3  \\\n",
      "0             NaN             NaN         NaN         NaN         NaN   \n",
      "1  29820.09000000  29820.11000000  1.92227000  0.02688000  0.02689000   \n",
      "2  29820.11000000  29820.20000000  2.48119000  0.02688000  0.00222000   \n",
      "3  29819.70000000  29819.75000000  3.90382000  0.03046000  0.00074000   \n",
      "4  29819.75000000  29820.00000000  1.98067000  0.00074000  0.00036000   \n",
      "5  29819.70000000  29820.00000000  1.90625000  0.01450000  0.00074000   \n",
      "6  29819.70000000  29820.00000000  1.90545000  0.01450000  0.00074000   \n",
      "7  29820.00000000  29820.09000000  1.88693000  0.00074000  0.00036000   \n",
      "8  29819.71000000  29819.99000000  2.15159000  0.00074000  0.00036000   \n",
      "\n",
      "          as4         as5  \n",
      "0         NaN         NaN  \n",
      "1  0.00222000  0.08000000  \n",
      "2  0.08000000  0.00108000  \n",
      "3  0.00036000  0.08293000  \n",
      "4  0.08293000  1.00447000  \n",
      "5  0.00036000  1.11033000  \n",
      "6  0.00036000  1.11033000  \n",
      "7  1.08021000  0.07605000  \n",
      "8  0.08293000  0.49787000  \n",
      "\n",
      "[9 rows x 21 columns]\n",
      "   last_update_id             bp1             bp2             bp3  \\\n",
      "0             NaN             NaN             NaN             NaN   \n",
      "1    1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "2    1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "3    1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "4    1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "5    1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "6    1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "7    1.950054e+10  29819.58000000  29819.57000000  29819.32000000   \n",
      "8    1.950054e+10  29819.58000000  29819.57000000  29819.10000000   \n",
      "9    1.950054e+10  29819.58000000  29819.57000000  29819.10000000   \n",
      "\n",
      "              bp4             bp5         bs1         bs2         bs3  \\\n",
      "0             NaN             NaN         NaN         NaN         NaN   \n",
      "1  29819.48000000  29819.39000000  0.60625000  0.24868000  0.23807000   \n",
      "2  29819.39000000  29819.32000000  0.68641000  0.24868000  0.23807000   \n",
      "3  29819.32000000  29819.10000000  0.30421000  0.23807000  0.00373000   \n",
      "4  29819.32000000  29819.10000000  0.91948000  0.23807000  0.00373000   \n",
      "5  29819.32000000  29819.10000000  0.39849000  0.23807000  0.01755000   \n",
      "6  29819.32000000  29819.10000000  0.40640000  0.23807000  0.01755000   \n",
      "7  29819.10000000  29816.96000000  0.55670000  0.23807000  0.00042000   \n",
      "8  29817.67000000  29816.77000000  0.17616000  0.23807000  0.01000000   \n",
      "9  29818.14000000  29817.67000000  0.34906000  0.23807000  0.01000000   \n",
      "\n",
      "          bs4  ...             ap1             ap2             ap3  \\\n",
      "0         NaN  ...             NaN             NaN             NaN   \n",
      "1  0.02032000  ...  29820.00000000  29820.02000000  29820.04000000   \n",
      "2  0.00373000  ...  29820.00000000  29820.02000000  29820.09000000   \n",
      "3  0.00545000  ...  29819.59000000  29819.64000000  29819.65000000   \n",
      "4  0.00042000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "5  0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "6  0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "7  0.01000000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "8  0.00450000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "9  0.00450000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "\n",
      "              ap4             ap5         as1         as2         as3  \\\n",
      "0             NaN             NaN         NaN         NaN         NaN   \n",
      "1  29820.09000000  29820.11000000  1.92227000  0.02688000  0.02689000   \n",
      "2  29820.11000000  29820.20000000  2.48119000  0.02688000  0.00222000   \n",
      "3  29819.70000000  29819.75000000  3.90382000  0.03046000  0.00074000   \n",
      "4  29819.75000000  29820.00000000  1.98067000  0.00074000  0.00036000   \n",
      "5  29819.70000000  29820.00000000  1.90625000  0.01450000  0.00074000   \n",
      "6  29819.70000000  29820.00000000  1.90545000  0.01450000  0.00074000   \n",
      "7  29820.00000000  29820.09000000  1.88693000  0.00074000  0.00036000   \n",
      "8  29819.71000000  29819.99000000  2.15159000  0.00074000  0.00036000   \n",
      "9  29819.71000000  29819.99000000  2.15159000  0.00074000  0.00036000   \n",
      "\n",
      "          as4         as5  \n",
      "0         NaN         NaN  \n",
      "1  0.00222000  0.08000000  \n",
      "2  0.08000000  0.00108000  \n",
      "3  0.00036000  0.08293000  \n",
      "4  0.08293000  1.00447000  \n",
      "5  0.00036000  1.11033000  \n",
      "6  0.00036000  1.11033000  \n",
      "7  1.08021000  0.07605000  \n",
      "8  0.08293000  0.49787000  \n",
      "9  0.08293000  0.49787000  \n",
      "\n",
      "[10 rows x 21 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/91/6wbfy1kd3c54vx64tq8sck_00000gn/T/ipykernel_6976/3022916258.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.df_0 = self.df_0.append(df, ignore_index = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   last_update_id             bp1             bp2             bp3  \\\n",
      "0             NaN             NaN             NaN             NaN   \n",
      "1    1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "2    1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "3    1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "4    1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "5    1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "6    1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "7    1.950054e+10  29819.58000000  29819.57000000  29819.32000000   \n",
      "8    1.950054e+10  29819.58000000  29819.57000000  29819.10000000   \n",
      "9    1.950054e+10  29819.58000000  29819.57000000  29819.10000000   \n",
      "\n",
      "              bp4             bp5         bs1         bs2         bs3  \\\n",
      "0             NaN             NaN         NaN         NaN         NaN   \n",
      "1  29819.48000000  29819.39000000  0.60625000  0.24868000  0.23807000   \n",
      "2  29819.39000000  29819.32000000  0.68641000  0.24868000  0.23807000   \n",
      "3  29819.32000000  29819.10000000  0.30421000  0.23807000  0.00373000   \n",
      "4  29819.32000000  29819.10000000  0.91948000  0.23807000  0.00373000   \n",
      "5  29819.32000000  29819.10000000  0.39849000  0.23807000  0.01755000   \n",
      "6  29819.32000000  29819.10000000  0.40640000  0.23807000  0.01755000   \n",
      "7  29819.10000000  29816.96000000  0.55670000  0.23807000  0.00042000   \n",
      "8  29817.67000000  29816.77000000  0.17616000  0.23807000  0.01000000   \n",
      "9  29818.14000000  29817.67000000  0.34906000  0.23807000  0.01000000   \n",
      "\n",
      "          bs4  ...             ap1             ap2             ap3  \\\n",
      "0         NaN  ...             NaN             NaN             NaN   \n",
      "1  0.02032000  ...  29820.00000000  29820.02000000  29820.04000000   \n",
      "2  0.00373000  ...  29820.00000000  29820.02000000  29820.09000000   \n",
      "3  0.00545000  ...  29819.59000000  29819.64000000  29819.65000000   \n",
      "4  0.00042000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "5  0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "6  0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "7  0.01000000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "8  0.00450000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "9  0.00450000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "\n",
      "              ap4             ap5         as1         as2         as3  \\\n",
      "0             NaN             NaN         NaN         NaN         NaN   \n",
      "1  29820.09000000  29820.11000000  1.92227000  0.02688000  0.02689000   \n",
      "2  29820.11000000  29820.20000000  2.48119000  0.02688000  0.00222000   \n",
      "3  29819.70000000  29819.75000000  3.90382000  0.03046000  0.00074000   \n",
      "4  29819.75000000  29820.00000000  1.98067000  0.00074000  0.00036000   \n",
      "5  29819.70000000  29820.00000000  1.90625000  0.01450000  0.00074000   \n",
      "6  29819.70000000  29820.00000000  1.90545000  0.01450000  0.00074000   \n",
      "7  29820.00000000  29820.09000000  1.88693000  0.00074000  0.00036000   \n",
      "8  29819.71000000  29819.99000000  2.15159000  0.00074000  0.00036000   \n",
      "9  29819.71000000  29819.99000000  2.15159000  0.00074000  0.00036000   \n",
      "\n",
      "          as4         as5  \n",
      "0         NaN         NaN  \n",
      "1  0.00222000  0.08000000  \n",
      "2  0.08000000  0.00108000  \n",
      "3  0.00036000  0.08293000  \n",
      "4  0.08293000  1.00447000  \n",
      "5  0.00036000  1.11033000  \n",
      "6  0.00036000  1.11033000  \n",
      "7  1.08021000  0.07605000  \n",
      "8  0.08293000  0.49787000  \n",
      "9  0.08293000  0.49787000  \n",
      "\n",
      "[10 rows x 21 columns]\n",
      "    last_update_id             bp1             bp2             bp3  \\\n",
      "0              NaN             NaN             NaN             NaN   \n",
      "1     1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "2     1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "3     1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "4     1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "5     1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "6     1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "7     1.950054e+10  29819.58000000  29819.57000000  29819.32000000   \n",
      "8     1.950054e+10  29819.58000000  29819.57000000  29819.10000000   \n",
      "9     1.950054e+10  29819.58000000  29819.57000000  29819.10000000   \n",
      "10    1.950054e+10  29819.57000000  29819.10000000  29818.14000000   \n",
      "\n",
      "               bp4             bp5         bs1         bs2         bs3  \\\n",
      "0              NaN             NaN         NaN         NaN         NaN   \n",
      "1   29819.48000000  29819.39000000  0.60625000  0.24868000  0.23807000   \n",
      "2   29819.39000000  29819.32000000  0.68641000  0.24868000  0.23807000   \n",
      "3   29819.32000000  29819.10000000  0.30421000  0.23807000  0.00373000   \n",
      "4   29819.32000000  29819.10000000  0.91948000  0.23807000  0.00373000   \n",
      "5   29819.32000000  29819.10000000  0.39849000  0.23807000  0.01755000   \n",
      "6   29819.32000000  29819.10000000  0.40640000  0.23807000  0.01755000   \n",
      "7   29819.10000000  29816.96000000  0.55670000  0.23807000  0.00042000   \n",
      "8   29817.67000000  29816.77000000  0.17616000  0.23807000  0.01000000   \n",
      "9   29818.14000000  29817.67000000  0.34906000  0.23807000  0.01000000   \n",
      "10  29817.67000000  29816.76000000  0.40690000  0.01000000  0.00450000   \n",
      "\n",
      "           bs4  ...             ap1             ap2             ap3  \\\n",
      "0          NaN  ...             NaN             NaN             NaN   \n",
      "1   0.02032000  ...  29820.00000000  29820.02000000  29820.04000000   \n",
      "2   0.00373000  ...  29820.00000000  29820.02000000  29820.09000000   \n",
      "3   0.00545000  ...  29819.59000000  29819.64000000  29819.65000000   \n",
      "4   0.00042000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "5   0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "6   0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "7   0.01000000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "8   0.00450000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "9   0.00450000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "10  0.00450000  ...  29819.58000000  29819.59000000  29819.65000000   \n",
      "\n",
      "               ap4             ap5         as1         as2         as3  \\\n",
      "0              NaN             NaN         NaN         NaN         NaN   \n",
      "1   29820.09000000  29820.11000000  1.92227000  0.02688000  0.02689000   \n",
      "2   29820.11000000  29820.20000000  2.48119000  0.02688000  0.00222000   \n",
      "3   29819.70000000  29819.75000000  3.90382000  0.03046000  0.00074000   \n",
      "4   29819.75000000  29820.00000000  1.98067000  0.00074000  0.00036000   \n",
      "5   29819.70000000  29820.00000000  1.90625000  0.01450000  0.00074000   \n",
      "6   29819.70000000  29820.00000000  1.90545000  0.01450000  0.00074000   \n",
      "7   29820.00000000  29820.09000000  1.88693000  0.00074000  0.00036000   \n",
      "8   29819.71000000  29819.99000000  2.15159000  0.00074000  0.00036000   \n",
      "9   29819.71000000  29819.99000000  2.15159000  0.00074000  0.00036000   \n",
      "10  29819.70000000  29819.71000000  3.66217000  0.14181000  0.00074000   \n",
      "\n",
      "           as4         as5  \n",
      "0          NaN         NaN  \n",
      "1   0.00222000  0.08000000  \n",
      "2   0.08000000  0.00108000  \n",
      "3   0.00036000  0.08293000  \n",
      "4   0.08293000  1.00447000  \n",
      "5   0.00036000  1.11033000  \n",
      "6   0.00036000  1.11033000  \n",
      "7   1.08021000  0.07605000  \n",
      "8   0.08293000  0.49787000  \n",
      "9   0.08293000  0.49787000  \n",
      "10  0.00036000  0.08293000  \n",
      "\n",
      "[11 rows x 21 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/91/6wbfy1kd3c54vx64tq8sck_00000gn/T/ipykernel_6976/3022916258.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.df_0 = self.df_0.append(df, ignore_index = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    last_update_id             bp1             bp2             bp3  \\\n",
      "0              NaN             NaN             NaN             NaN   \n",
      "1     1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "2     1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "3     1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "4     1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "5     1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "6     1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "7     1.950054e+10  29819.58000000  29819.57000000  29819.32000000   \n",
      "8     1.950054e+10  29819.58000000  29819.57000000  29819.10000000   \n",
      "9     1.950054e+10  29819.58000000  29819.57000000  29819.10000000   \n",
      "10    1.950054e+10  29819.57000000  29819.10000000  29818.14000000   \n",
      "\n",
      "               bp4             bp5         bs1         bs2         bs3  \\\n",
      "0              NaN             NaN         NaN         NaN         NaN   \n",
      "1   29819.48000000  29819.39000000  0.60625000  0.24868000  0.23807000   \n",
      "2   29819.39000000  29819.32000000  0.68641000  0.24868000  0.23807000   \n",
      "3   29819.32000000  29819.10000000  0.30421000  0.23807000  0.00373000   \n",
      "4   29819.32000000  29819.10000000  0.91948000  0.23807000  0.00373000   \n",
      "5   29819.32000000  29819.10000000  0.39849000  0.23807000  0.01755000   \n",
      "6   29819.32000000  29819.10000000  0.40640000  0.23807000  0.01755000   \n",
      "7   29819.10000000  29816.96000000  0.55670000  0.23807000  0.00042000   \n",
      "8   29817.67000000  29816.77000000  0.17616000  0.23807000  0.01000000   \n",
      "9   29818.14000000  29817.67000000  0.34906000  0.23807000  0.01000000   \n",
      "10  29817.67000000  29816.76000000  0.40690000  0.01000000  0.00450000   \n",
      "\n",
      "           bs4  ...             ap1             ap2             ap3  \\\n",
      "0          NaN  ...             NaN             NaN             NaN   \n",
      "1   0.02032000  ...  29820.00000000  29820.02000000  29820.04000000   \n",
      "2   0.00373000  ...  29820.00000000  29820.02000000  29820.09000000   \n",
      "3   0.00545000  ...  29819.59000000  29819.64000000  29819.65000000   \n",
      "4   0.00042000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "5   0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "6   0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "7   0.01000000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "8   0.00450000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "9   0.00450000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "10  0.00450000  ...  29819.58000000  29819.59000000  29819.65000000   \n",
      "\n",
      "               ap4             ap5         as1         as2         as3  \\\n",
      "0              NaN             NaN         NaN         NaN         NaN   \n",
      "1   29820.09000000  29820.11000000  1.92227000  0.02688000  0.02689000   \n",
      "2   29820.11000000  29820.20000000  2.48119000  0.02688000  0.00222000   \n",
      "3   29819.70000000  29819.75000000  3.90382000  0.03046000  0.00074000   \n",
      "4   29819.75000000  29820.00000000  1.98067000  0.00074000  0.00036000   \n",
      "5   29819.70000000  29820.00000000  1.90625000  0.01450000  0.00074000   \n",
      "6   29819.70000000  29820.00000000  1.90545000  0.01450000  0.00074000   \n",
      "7   29820.00000000  29820.09000000  1.88693000  0.00074000  0.00036000   \n",
      "8   29819.71000000  29819.99000000  2.15159000  0.00074000  0.00036000   \n",
      "9   29819.71000000  29819.99000000  2.15159000  0.00074000  0.00036000   \n",
      "10  29819.70000000  29819.71000000  3.66217000  0.14181000  0.00074000   \n",
      "\n",
      "           as4         as5  \n",
      "0          NaN         NaN  \n",
      "1   0.00222000  0.08000000  \n",
      "2   0.08000000  0.00108000  \n",
      "3   0.00036000  0.08293000  \n",
      "4   0.08293000  1.00447000  \n",
      "5   0.00036000  1.11033000  \n",
      "6   0.00036000  1.11033000  \n",
      "7   1.08021000  0.07605000  \n",
      "8   0.08293000  0.49787000  \n",
      "9   0.08293000  0.49787000  \n",
      "10  0.00036000  0.08293000  \n",
      "\n",
      "[11 rows x 21 columns]\n",
      "    last_update_id             bp1             bp2             bp3  \\\n",
      "0              NaN             NaN             NaN             NaN   \n",
      "1     1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "2     1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "3     1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "4     1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "5     1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "6     1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "7     1.950054e+10  29819.58000000  29819.57000000  29819.32000000   \n",
      "8     1.950054e+10  29819.58000000  29819.57000000  29819.10000000   \n",
      "9     1.950054e+10  29819.58000000  29819.57000000  29819.10000000   \n",
      "10    1.950054e+10  29819.57000000  29819.10000000  29818.14000000   \n",
      "11    1.950054e+10  29819.57000000  29819.10000000  29818.14000000   \n",
      "\n",
      "               bp4             bp5         bs1         bs2         bs3  \\\n",
      "0              NaN             NaN         NaN         NaN         NaN   \n",
      "1   29819.48000000  29819.39000000  0.60625000  0.24868000  0.23807000   \n",
      "2   29819.39000000  29819.32000000  0.68641000  0.24868000  0.23807000   \n",
      "3   29819.32000000  29819.10000000  0.30421000  0.23807000  0.00373000   \n",
      "4   29819.32000000  29819.10000000  0.91948000  0.23807000  0.00373000   \n",
      "5   29819.32000000  29819.10000000  0.39849000  0.23807000  0.01755000   \n",
      "6   29819.32000000  29819.10000000  0.40640000  0.23807000  0.01755000   \n",
      "7   29819.10000000  29816.96000000  0.55670000  0.23807000  0.00042000   \n",
      "8   29817.67000000  29816.77000000  0.17616000  0.23807000  0.01000000   \n",
      "9   29818.14000000  29817.67000000  0.34906000  0.23807000  0.01000000   \n",
      "10  29817.67000000  29816.76000000  0.40690000  0.01000000  0.00450000   \n",
      "11  29817.67000000  29816.76000000  0.40690000  0.01000000  0.00450000   \n",
      "\n",
      "           bs4  ...             ap1             ap2             ap3  \\\n",
      "0          NaN  ...             NaN             NaN             NaN   \n",
      "1   0.02032000  ...  29820.00000000  29820.02000000  29820.04000000   \n",
      "2   0.00373000  ...  29820.00000000  29820.02000000  29820.09000000   \n",
      "3   0.00545000  ...  29819.59000000  29819.64000000  29819.65000000   \n",
      "4   0.00042000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "5   0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "6   0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "7   0.01000000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "8   0.00450000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "9   0.00450000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "10  0.00450000  ...  29819.58000000  29819.59000000  29819.65000000   \n",
      "11  0.00450000  ...  29819.58000000  29819.59000000  29819.65000000   \n",
      "\n",
      "               ap4             ap5         as1         as2         as3  \\\n",
      "0              NaN             NaN         NaN         NaN         NaN   \n",
      "1   29820.09000000  29820.11000000  1.92227000  0.02688000  0.02689000   \n",
      "2   29820.11000000  29820.20000000  2.48119000  0.02688000  0.00222000   \n",
      "3   29819.70000000  29819.75000000  3.90382000  0.03046000  0.00074000   \n",
      "4   29819.75000000  29820.00000000  1.98067000  0.00074000  0.00036000   \n",
      "5   29819.70000000  29820.00000000  1.90625000  0.01450000  0.00074000   \n",
      "6   29819.70000000  29820.00000000  1.90545000  0.01450000  0.00074000   \n",
      "7   29820.00000000  29820.09000000  1.88693000  0.00074000  0.00036000   \n",
      "8   29819.71000000  29819.99000000  2.15159000  0.00074000  0.00036000   \n",
      "9   29819.71000000  29819.99000000  2.15159000  0.00074000  0.00036000   \n",
      "10  29819.70000000  29819.71000000  3.66217000  0.14181000  0.00074000   \n",
      "11  29819.70000000  29819.71000000  3.79434000  0.14181000  0.00074000   \n",
      "\n",
      "           as4         as5  \n",
      "0          NaN         NaN  \n",
      "1   0.00222000  0.08000000  \n",
      "2   0.08000000  0.00108000  \n",
      "3   0.00036000  0.08293000  \n",
      "4   0.08293000  1.00447000  \n",
      "5   0.00036000  1.11033000  \n",
      "6   0.00036000  1.11033000  \n",
      "7   1.08021000  0.07605000  \n",
      "8   0.08293000  0.49787000  \n",
      "9   0.08293000  0.49787000  \n",
      "10  0.00036000  0.08293000  \n",
      "11  0.00036000  0.08293000  \n",
      "\n",
      "[12 rows x 21 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/91/6wbfy1kd3c54vx64tq8sck_00000gn/T/ipykernel_6976/3022916258.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.df_0 = self.df_0.append(df, ignore_index = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    last_update_id             bp1             bp2             bp3  \\\n",
      "0              NaN             NaN             NaN             NaN   \n",
      "1     1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "2     1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "3     1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "4     1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "5     1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "6     1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "7     1.950054e+10  29819.58000000  29819.57000000  29819.32000000   \n",
      "8     1.950054e+10  29819.58000000  29819.57000000  29819.10000000   \n",
      "9     1.950054e+10  29819.58000000  29819.57000000  29819.10000000   \n",
      "10    1.950054e+10  29819.57000000  29819.10000000  29818.14000000   \n",
      "11    1.950054e+10  29819.57000000  29819.10000000  29818.14000000   \n",
      "\n",
      "               bp4             bp5         bs1         bs2         bs3  \\\n",
      "0              NaN             NaN         NaN         NaN         NaN   \n",
      "1   29819.48000000  29819.39000000  0.60625000  0.24868000  0.23807000   \n",
      "2   29819.39000000  29819.32000000  0.68641000  0.24868000  0.23807000   \n",
      "3   29819.32000000  29819.10000000  0.30421000  0.23807000  0.00373000   \n",
      "4   29819.32000000  29819.10000000  0.91948000  0.23807000  0.00373000   \n",
      "5   29819.32000000  29819.10000000  0.39849000  0.23807000  0.01755000   \n",
      "6   29819.32000000  29819.10000000  0.40640000  0.23807000  0.01755000   \n",
      "7   29819.10000000  29816.96000000  0.55670000  0.23807000  0.00042000   \n",
      "8   29817.67000000  29816.77000000  0.17616000  0.23807000  0.01000000   \n",
      "9   29818.14000000  29817.67000000  0.34906000  0.23807000  0.01000000   \n",
      "10  29817.67000000  29816.76000000  0.40690000  0.01000000  0.00450000   \n",
      "11  29817.67000000  29816.76000000  0.40690000  0.01000000  0.00450000   \n",
      "\n",
      "           bs4  ...             ap1             ap2             ap3  \\\n",
      "0          NaN  ...             NaN             NaN             NaN   \n",
      "1   0.02032000  ...  29820.00000000  29820.02000000  29820.04000000   \n",
      "2   0.00373000  ...  29820.00000000  29820.02000000  29820.09000000   \n",
      "3   0.00545000  ...  29819.59000000  29819.64000000  29819.65000000   \n",
      "4   0.00042000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "5   0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "6   0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "7   0.01000000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "8   0.00450000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "9   0.00450000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "10  0.00450000  ...  29819.58000000  29819.59000000  29819.65000000   \n",
      "11  0.00450000  ...  29819.58000000  29819.59000000  29819.65000000   \n",
      "\n",
      "               ap4             ap5         as1         as2         as3  \\\n",
      "0              NaN             NaN         NaN         NaN         NaN   \n",
      "1   29820.09000000  29820.11000000  1.92227000  0.02688000  0.02689000   \n",
      "2   29820.11000000  29820.20000000  2.48119000  0.02688000  0.00222000   \n",
      "3   29819.70000000  29819.75000000  3.90382000  0.03046000  0.00074000   \n",
      "4   29819.75000000  29820.00000000  1.98067000  0.00074000  0.00036000   \n",
      "5   29819.70000000  29820.00000000  1.90625000  0.01450000  0.00074000   \n",
      "6   29819.70000000  29820.00000000  1.90545000  0.01450000  0.00074000   \n",
      "7   29820.00000000  29820.09000000  1.88693000  0.00074000  0.00036000   \n",
      "8   29819.71000000  29819.99000000  2.15159000  0.00074000  0.00036000   \n",
      "9   29819.71000000  29819.99000000  2.15159000  0.00074000  0.00036000   \n",
      "10  29819.70000000  29819.71000000  3.66217000  0.14181000  0.00074000   \n",
      "11  29819.70000000  29819.71000000  3.79434000  0.14181000  0.00074000   \n",
      "\n",
      "           as4         as5  \n",
      "0          NaN         NaN  \n",
      "1   0.00222000  0.08000000  \n",
      "2   0.08000000  0.00108000  \n",
      "3   0.00036000  0.08293000  \n",
      "4   0.08293000  1.00447000  \n",
      "5   0.00036000  1.11033000  \n",
      "6   0.00036000  1.11033000  \n",
      "7   1.08021000  0.07605000  \n",
      "8   0.08293000  0.49787000  \n",
      "9   0.08293000  0.49787000  \n",
      "10  0.00036000  0.08293000  \n",
      "11  0.00036000  0.08293000  \n",
      "\n",
      "[12 rows x 21 columns]\n",
      "    last_update_id             bp1             bp2             bp3  \\\n",
      "0              NaN             NaN             NaN             NaN   \n",
      "1     1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "2     1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "3     1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "4     1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "5     1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "6     1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "7     1.950054e+10  29819.58000000  29819.57000000  29819.32000000   \n",
      "8     1.950054e+10  29819.58000000  29819.57000000  29819.10000000   \n",
      "9     1.950054e+10  29819.58000000  29819.57000000  29819.10000000   \n",
      "10    1.950054e+10  29819.57000000  29819.10000000  29818.14000000   \n",
      "11    1.950054e+10  29819.57000000  29819.10000000  29818.14000000   \n",
      "12    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "\n",
      "               bp4             bp5         bs1         bs2         bs3  \\\n",
      "0              NaN             NaN         NaN         NaN         NaN   \n",
      "1   29819.48000000  29819.39000000  0.60625000  0.24868000  0.23807000   \n",
      "2   29819.39000000  29819.32000000  0.68641000  0.24868000  0.23807000   \n",
      "3   29819.32000000  29819.10000000  0.30421000  0.23807000  0.00373000   \n",
      "4   29819.32000000  29819.10000000  0.91948000  0.23807000  0.00373000   \n",
      "5   29819.32000000  29819.10000000  0.39849000  0.23807000  0.01755000   \n",
      "6   29819.32000000  29819.10000000  0.40640000  0.23807000  0.01755000   \n",
      "7   29819.10000000  29816.96000000  0.55670000  0.23807000  0.00042000   \n",
      "8   29817.67000000  29816.77000000  0.17616000  0.23807000  0.01000000   \n",
      "9   29818.14000000  29817.67000000  0.34906000  0.23807000  0.01000000   \n",
      "10  29817.67000000  29816.76000000  0.40690000  0.01000000  0.00450000   \n",
      "11  29817.67000000  29816.76000000  0.40690000  0.01000000  0.00450000   \n",
      "12  29812.74000000  29810.94000000  0.36085000  0.01665000  0.00720000   \n",
      "\n",
      "           bs4  ...             ap1             ap2             ap3  \\\n",
      "0          NaN  ...             NaN             NaN             NaN   \n",
      "1   0.02032000  ...  29820.00000000  29820.02000000  29820.04000000   \n",
      "2   0.00373000  ...  29820.00000000  29820.02000000  29820.09000000   \n",
      "3   0.00545000  ...  29819.59000000  29819.64000000  29819.65000000   \n",
      "4   0.00042000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "5   0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "6   0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "7   0.01000000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "8   0.00450000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "9   0.00450000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "10  0.00450000  ...  29819.58000000  29819.59000000  29819.65000000   \n",
      "11  0.00450000  ...  29819.58000000  29819.59000000  29819.65000000   \n",
      "12  0.00450000  ...  29814.55000000  29815.20000000  29815.44000000   \n",
      "\n",
      "               ap4             ap5         as1         as2         as3  \\\n",
      "0              NaN             NaN         NaN         NaN         NaN   \n",
      "1   29820.09000000  29820.11000000  1.92227000  0.02688000  0.02689000   \n",
      "2   29820.11000000  29820.20000000  2.48119000  0.02688000  0.00222000   \n",
      "3   29819.70000000  29819.75000000  3.90382000  0.03046000  0.00074000   \n",
      "4   29819.75000000  29820.00000000  1.98067000  0.00074000  0.00036000   \n",
      "5   29819.70000000  29820.00000000  1.90625000  0.01450000  0.00074000   \n",
      "6   29819.70000000  29820.00000000  1.90545000  0.01450000  0.00074000   \n",
      "7   29820.00000000  29820.09000000  1.88693000  0.00074000  0.00036000   \n",
      "8   29819.71000000  29819.99000000  2.15159000  0.00074000  0.00036000   \n",
      "9   29819.71000000  29819.99000000  2.15159000  0.00074000  0.00036000   \n",
      "10  29819.70000000  29819.71000000  3.66217000  0.14181000  0.00074000   \n",
      "11  29819.70000000  29819.71000000  3.79434000  0.14181000  0.00074000   \n",
      "12  29816.29000000  29816.30000000  2.06426000  0.01855000  0.25145000   \n",
      "\n",
      "           as4         as5  \n",
      "0          NaN         NaN  \n",
      "1   0.00222000  0.08000000  \n",
      "2   0.08000000  0.00108000  \n",
      "3   0.00036000  0.08293000  \n",
      "4   0.08293000  1.00447000  \n",
      "5   0.00036000  1.11033000  \n",
      "6   0.00036000  1.11033000  \n",
      "7   1.08021000  0.07605000  \n",
      "8   0.08293000  0.49787000  \n",
      "9   0.08293000  0.49787000  \n",
      "10  0.00036000  0.08293000  \n",
      "11  0.00036000  0.08293000  \n",
      "12  0.00067000  0.54868000  \n",
      "\n",
      "[13 rows x 21 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/91/6wbfy1kd3c54vx64tq8sck_00000gn/T/ipykernel_6976/3022916258.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.df_0 = self.df_0.append(df, ignore_index = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    last_update_id             bp1             bp2             bp3  \\\n",
      "0              NaN             NaN             NaN             NaN   \n",
      "1     1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "2     1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "3     1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "4     1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "5     1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "6     1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "7     1.950054e+10  29819.58000000  29819.57000000  29819.32000000   \n",
      "8     1.950054e+10  29819.58000000  29819.57000000  29819.10000000   \n",
      "9     1.950054e+10  29819.58000000  29819.57000000  29819.10000000   \n",
      "10    1.950054e+10  29819.57000000  29819.10000000  29818.14000000   \n",
      "11    1.950054e+10  29819.57000000  29819.10000000  29818.14000000   \n",
      "12    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "\n",
      "               bp4             bp5         bs1         bs2         bs3  \\\n",
      "0              NaN             NaN         NaN         NaN         NaN   \n",
      "1   29819.48000000  29819.39000000  0.60625000  0.24868000  0.23807000   \n",
      "2   29819.39000000  29819.32000000  0.68641000  0.24868000  0.23807000   \n",
      "3   29819.32000000  29819.10000000  0.30421000  0.23807000  0.00373000   \n",
      "4   29819.32000000  29819.10000000  0.91948000  0.23807000  0.00373000   \n",
      "5   29819.32000000  29819.10000000  0.39849000  0.23807000  0.01755000   \n",
      "6   29819.32000000  29819.10000000  0.40640000  0.23807000  0.01755000   \n",
      "7   29819.10000000  29816.96000000  0.55670000  0.23807000  0.00042000   \n",
      "8   29817.67000000  29816.77000000  0.17616000  0.23807000  0.01000000   \n",
      "9   29818.14000000  29817.67000000  0.34906000  0.23807000  0.01000000   \n",
      "10  29817.67000000  29816.76000000  0.40690000  0.01000000  0.00450000   \n",
      "11  29817.67000000  29816.76000000  0.40690000  0.01000000  0.00450000   \n",
      "12  29812.74000000  29810.94000000  0.36085000  0.01665000  0.00720000   \n",
      "\n",
      "           bs4  ...             ap1             ap2             ap3  \\\n",
      "0          NaN  ...             NaN             NaN             NaN   \n",
      "1   0.02032000  ...  29820.00000000  29820.02000000  29820.04000000   \n",
      "2   0.00373000  ...  29820.00000000  29820.02000000  29820.09000000   \n",
      "3   0.00545000  ...  29819.59000000  29819.64000000  29819.65000000   \n",
      "4   0.00042000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "5   0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "6   0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "7   0.01000000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "8   0.00450000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "9   0.00450000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "10  0.00450000  ...  29819.58000000  29819.59000000  29819.65000000   \n",
      "11  0.00450000  ...  29819.58000000  29819.59000000  29819.65000000   \n",
      "12  0.00450000  ...  29814.55000000  29815.20000000  29815.44000000   \n",
      "\n",
      "               ap4             ap5         as1         as2         as3  \\\n",
      "0              NaN             NaN         NaN         NaN         NaN   \n",
      "1   29820.09000000  29820.11000000  1.92227000  0.02688000  0.02689000   \n",
      "2   29820.11000000  29820.20000000  2.48119000  0.02688000  0.00222000   \n",
      "3   29819.70000000  29819.75000000  3.90382000  0.03046000  0.00074000   \n",
      "4   29819.75000000  29820.00000000  1.98067000  0.00074000  0.00036000   \n",
      "5   29819.70000000  29820.00000000  1.90625000  0.01450000  0.00074000   \n",
      "6   29819.70000000  29820.00000000  1.90545000  0.01450000  0.00074000   \n",
      "7   29820.00000000  29820.09000000  1.88693000  0.00074000  0.00036000   \n",
      "8   29819.71000000  29819.99000000  2.15159000  0.00074000  0.00036000   \n",
      "9   29819.71000000  29819.99000000  2.15159000  0.00074000  0.00036000   \n",
      "10  29819.70000000  29819.71000000  3.66217000  0.14181000  0.00074000   \n",
      "11  29819.70000000  29819.71000000  3.79434000  0.14181000  0.00074000   \n",
      "12  29816.29000000  29816.30000000  2.06426000  0.01855000  0.25145000   \n",
      "\n",
      "           as4         as5  \n",
      "0          NaN         NaN  \n",
      "1   0.00222000  0.08000000  \n",
      "2   0.08000000  0.00108000  \n",
      "3   0.00036000  0.08293000  \n",
      "4   0.08293000  1.00447000  \n",
      "5   0.00036000  1.11033000  \n",
      "6   0.00036000  1.11033000  \n",
      "7   1.08021000  0.07605000  \n",
      "8   0.08293000  0.49787000  \n",
      "9   0.08293000  0.49787000  \n",
      "10  0.00036000  0.08293000  \n",
      "11  0.00036000  0.08293000  \n",
      "12  0.00067000  0.54868000  \n",
      "\n",
      "[13 rows x 21 columns]\n",
      "    last_update_id             bp1             bp2             bp3  \\\n",
      "0              NaN             NaN             NaN             NaN   \n",
      "1     1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "2     1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "3     1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "4     1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "5     1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "6     1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "7     1.950054e+10  29819.58000000  29819.57000000  29819.32000000   \n",
      "8     1.950054e+10  29819.58000000  29819.57000000  29819.10000000   \n",
      "9     1.950054e+10  29819.58000000  29819.57000000  29819.10000000   \n",
      "10    1.950054e+10  29819.57000000  29819.10000000  29818.14000000   \n",
      "11    1.950054e+10  29819.57000000  29819.10000000  29818.14000000   \n",
      "12    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "13    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "\n",
      "               bp4             bp5         bs1         bs2         bs3  \\\n",
      "0              NaN             NaN         NaN         NaN         NaN   \n",
      "1   29819.48000000  29819.39000000  0.60625000  0.24868000  0.23807000   \n",
      "2   29819.39000000  29819.32000000  0.68641000  0.24868000  0.23807000   \n",
      "3   29819.32000000  29819.10000000  0.30421000  0.23807000  0.00373000   \n",
      "4   29819.32000000  29819.10000000  0.91948000  0.23807000  0.00373000   \n",
      "5   29819.32000000  29819.10000000  0.39849000  0.23807000  0.01755000   \n",
      "6   29819.32000000  29819.10000000  0.40640000  0.23807000  0.01755000   \n",
      "7   29819.10000000  29816.96000000  0.55670000  0.23807000  0.00042000   \n",
      "8   29817.67000000  29816.77000000  0.17616000  0.23807000  0.01000000   \n",
      "9   29818.14000000  29817.67000000  0.34906000  0.23807000  0.01000000   \n",
      "10  29817.67000000  29816.76000000  0.40690000  0.01000000  0.00450000   \n",
      "11  29817.67000000  29816.76000000  0.40690000  0.01000000  0.00450000   \n",
      "12  29812.74000000  29810.94000000  0.36085000  0.01665000  0.00720000   \n",
      "13  29813.04000000  29811.17000000  0.22782000  0.01665000  0.00720000   \n",
      "\n",
      "           bs4  ...             ap1             ap2             ap3  \\\n",
      "0          NaN  ...             NaN             NaN             NaN   \n",
      "1   0.02032000  ...  29820.00000000  29820.02000000  29820.04000000   \n",
      "2   0.00373000  ...  29820.00000000  29820.02000000  29820.09000000   \n",
      "3   0.00545000  ...  29819.59000000  29819.64000000  29819.65000000   \n",
      "4   0.00042000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "5   0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "6   0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "7   0.01000000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "8   0.00450000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "9   0.00450000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "10  0.00450000  ...  29819.58000000  29819.59000000  29819.65000000   \n",
      "11  0.00450000  ...  29819.58000000  29819.59000000  29819.65000000   \n",
      "12  0.00450000  ...  29814.55000000  29815.20000000  29815.44000000   \n",
      "13  0.00450000  ...  29814.55000000  29815.44000000  29816.05000000   \n",
      "\n",
      "               ap4             ap5         as1         as2         as3  \\\n",
      "0              NaN             NaN         NaN         NaN         NaN   \n",
      "1   29820.09000000  29820.11000000  1.92227000  0.02688000  0.02689000   \n",
      "2   29820.11000000  29820.20000000  2.48119000  0.02688000  0.00222000   \n",
      "3   29819.70000000  29819.75000000  3.90382000  0.03046000  0.00074000   \n",
      "4   29819.75000000  29820.00000000  1.98067000  0.00074000  0.00036000   \n",
      "5   29819.70000000  29820.00000000  1.90625000  0.01450000  0.00074000   \n",
      "6   29819.70000000  29820.00000000  1.90545000  0.01450000  0.00074000   \n",
      "7   29820.00000000  29820.09000000  1.88693000  0.00074000  0.00036000   \n",
      "8   29819.71000000  29819.99000000  2.15159000  0.00074000  0.00036000   \n",
      "9   29819.71000000  29819.99000000  2.15159000  0.00074000  0.00036000   \n",
      "10  29819.70000000  29819.71000000  3.66217000  0.14181000  0.00074000   \n",
      "11  29819.70000000  29819.71000000  3.79434000  0.14181000  0.00074000   \n",
      "12  29816.29000000  29816.30000000  2.06426000  0.01855000  0.25145000   \n",
      "13  29816.29000000  29816.30000000  6.65887000  0.25145000  0.00450000   \n",
      "\n",
      "           as4         as5  \n",
      "0          NaN         NaN  \n",
      "1   0.00222000  0.08000000  \n",
      "2   0.08000000  0.00108000  \n",
      "3   0.00036000  0.08293000  \n",
      "4   0.08293000  1.00447000  \n",
      "5   0.00036000  1.11033000  \n",
      "6   0.00036000  1.11033000  \n",
      "7   1.08021000  0.07605000  \n",
      "8   0.08293000  0.49787000  \n",
      "9   0.08293000  0.49787000  \n",
      "10  0.00036000  0.08293000  \n",
      "11  0.00036000  0.08293000  \n",
      "12  0.00067000  0.54868000  \n",
      "13  0.00067000  0.54868000  \n",
      "\n",
      "[14 rows x 21 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/91/6wbfy1kd3c54vx64tq8sck_00000gn/T/ipykernel_6976/3022916258.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.df_0 = self.df_0.append(df, ignore_index = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    last_update_id             bp1             bp2             bp3  \\\n",
      "0              NaN             NaN             NaN             NaN   \n",
      "1     1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "2     1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "3     1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "4     1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "5     1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "6     1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "7     1.950054e+10  29819.58000000  29819.57000000  29819.32000000   \n",
      "8     1.950054e+10  29819.58000000  29819.57000000  29819.10000000   \n",
      "9     1.950054e+10  29819.58000000  29819.57000000  29819.10000000   \n",
      "10    1.950054e+10  29819.57000000  29819.10000000  29818.14000000   \n",
      "11    1.950054e+10  29819.57000000  29819.10000000  29818.14000000   \n",
      "12    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "13    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "\n",
      "               bp4             bp5         bs1         bs2         bs3  \\\n",
      "0              NaN             NaN         NaN         NaN         NaN   \n",
      "1   29819.48000000  29819.39000000  0.60625000  0.24868000  0.23807000   \n",
      "2   29819.39000000  29819.32000000  0.68641000  0.24868000  0.23807000   \n",
      "3   29819.32000000  29819.10000000  0.30421000  0.23807000  0.00373000   \n",
      "4   29819.32000000  29819.10000000  0.91948000  0.23807000  0.00373000   \n",
      "5   29819.32000000  29819.10000000  0.39849000  0.23807000  0.01755000   \n",
      "6   29819.32000000  29819.10000000  0.40640000  0.23807000  0.01755000   \n",
      "7   29819.10000000  29816.96000000  0.55670000  0.23807000  0.00042000   \n",
      "8   29817.67000000  29816.77000000  0.17616000  0.23807000  0.01000000   \n",
      "9   29818.14000000  29817.67000000  0.34906000  0.23807000  0.01000000   \n",
      "10  29817.67000000  29816.76000000  0.40690000  0.01000000  0.00450000   \n",
      "11  29817.67000000  29816.76000000  0.40690000  0.01000000  0.00450000   \n",
      "12  29812.74000000  29810.94000000  0.36085000  0.01665000  0.00720000   \n",
      "13  29813.04000000  29811.17000000  0.22782000  0.01665000  0.00720000   \n",
      "\n",
      "           bs4  ...             ap1             ap2             ap3  \\\n",
      "0          NaN  ...             NaN             NaN             NaN   \n",
      "1   0.02032000  ...  29820.00000000  29820.02000000  29820.04000000   \n",
      "2   0.00373000  ...  29820.00000000  29820.02000000  29820.09000000   \n",
      "3   0.00545000  ...  29819.59000000  29819.64000000  29819.65000000   \n",
      "4   0.00042000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "5   0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "6   0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "7   0.01000000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "8   0.00450000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "9   0.00450000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "10  0.00450000  ...  29819.58000000  29819.59000000  29819.65000000   \n",
      "11  0.00450000  ...  29819.58000000  29819.59000000  29819.65000000   \n",
      "12  0.00450000  ...  29814.55000000  29815.20000000  29815.44000000   \n",
      "13  0.00450000  ...  29814.55000000  29815.44000000  29816.05000000   \n",
      "\n",
      "               ap4             ap5         as1         as2         as3  \\\n",
      "0              NaN             NaN         NaN         NaN         NaN   \n",
      "1   29820.09000000  29820.11000000  1.92227000  0.02688000  0.02689000   \n",
      "2   29820.11000000  29820.20000000  2.48119000  0.02688000  0.00222000   \n",
      "3   29819.70000000  29819.75000000  3.90382000  0.03046000  0.00074000   \n",
      "4   29819.75000000  29820.00000000  1.98067000  0.00074000  0.00036000   \n",
      "5   29819.70000000  29820.00000000  1.90625000  0.01450000  0.00074000   \n",
      "6   29819.70000000  29820.00000000  1.90545000  0.01450000  0.00074000   \n",
      "7   29820.00000000  29820.09000000  1.88693000  0.00074000  0.00036000   \n",
      "8   29819.71000000  29819.99000000  2.15159000  0.00074000  0.00036000   \n",
      "9   29819.71000000  29819.99000000  2.15159000  0.00074000  0.00036000   \n",
      "10  29819.70000000  29819.71000000  3.66217000  0.14181000  0.00074000   \n",
      "11  29819.70000000  29819.71000000  3.79434000  0.14181000  0.00074000   \n",
      "12  29816.29000000  29816.30000000  2.06426000  0.01855000  0.25145000   \n",
      "13  29816.29000000  29816.30000000  6.65887000  0.25145000  0.00450000   \n",
      "\n",
      "           as4         as5  \n",
      "0          NaN         NaN  \n",
      "1   0.00222000  0.08000000  \n",
      "2   0.08000000  0.00108000  \n",
      "3   0.00036000  0.08293000  \n",
      "4   0.08293000  1.00447000  \n",
      "5   0.00036000  1.11033000  \n",
      "6   0.00036000  1.11033000  \n",
      "7   1.08021000  0.07605000  \n",
      "8   0.08293000  0.49787000  \n",
      "9   0.08293000  0.49787000  \n",
      "10  0.00036000  0.08293000  \n",
      "11  0.00036000  0.08293000  \n",
      "12  0.00067000  0.54868000  \n",
      "13  0.00067000  0.54868000  \n",
      "\n",
      "[14 rows x 21 columns]\n",
      "    last_update_id             bp1             bp2             bp3  \\\n",
      "0              NaN             NaN             NaN             NaN   \n",
      "1     1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "2     1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "3     1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "4     1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "5     1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "6     1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "7     1.950054e+10  29819.58000000  29819.57000000  29819.32000000   \n",
      "8     1.950054e+10  29819.58000000  29819.57000000  29819.10000000   \n",
      "9     1.950054e+10  29819.58000000  29819.57000000  29819.10000000   \n",
      "10    1.950054e+10  29819.57000000  29819.10000000  29818.14000000   \n",
      "11    1.950054e+10  29819.57000000  29819.10000000  29818.14000000   \n",
      "12    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "13    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "14    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "\n",
      "               bp4             bp5         bs1         bs2         bs3  \\\n",
      "0              NaN             NaN         NaN         NaN         NaN   \n",
      "1   29819.48000000  29819.39000000  0.60625000  0.24868000  0.23807000   \n",
      "2   29819.39000000  29819.32000000  0.68641000  0.24868000  0.23807000   \n",
      "3   29819.32000000  29819.10000000  0.30421000  0.23807000  0.00373000   \n",
      "4   29819.32000000  29819.10000000  0.91948000  0.23807000  0.00373000   \n",
      "5   29819.32000000  29819.10000000  0.39849000  0.23807000  0.01755000   \n",
      "6   29819.32000000  29819.10000000  0.40640000  0.23807000  0.01755000   \n",
      "7   29819.10000000  29816.96000000  0.55670000  0.23807000  0.00042000   \n",
      "8   29817.67000000  29816.77000000  0.17616000  0.23807000  0.01000000   \n",
      "9   29818.14000000  29817.67000000  0.34906000  0.23807000  0.01000000   \n",
      "10  29817.67000000  29816.76000000  0.40690000  0.01000000  0.00450000   \n",
      "11  29817.67000000  29816.76000000  0.40690000  0.01000000  0.00450000   \n",
      "12  29812.74000000  29810.94000000  0.36085000  0.01665000  0.00720000   \n",
      "13  29813.04000000  29811.17000000  0.22782000  0.01665000  0.00720000   \n",
      "14  29813.04000000  29811.17000000  0.21910000  0.01665000  0.00720000   \n",
      "\n",
      "           bs4  ...             ap1             ap2             ap3  \\\n",
      "0          NaN  ...             NaN             NaN             NaN   \n",
      "1   0.02032000  ...  29820.00000000  29820.02000000  29820.04000000   \n",
      "2   0.00373000  ...  29820.00000000  29820.02000000  29820.09000000   \n",
      "3   0.00545000  ...  29819.59000000  29819.64000000  29819.65000000   \n",
      "4   0.00042000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "5   0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "6   0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "7   0.01000000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "8   0.00450000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "9   0.00450000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "10  0.00450000  ...  29819.58000000  29819.59000000  29819.65000000   \n",
      "11  0.00450000  ...  29819.58000000  29819.59000000  29819.65000000   \n",
      "12  0.00450000  ...  29814.55000000  29815.20000000  29815.44000000   \n",
      "13  0.00450000  ...  29814.55000000  29815.44000000  29816.05000000   \n",
      "14  0.00450000  ...  29814.55000000  29814.57000000  29814.59000000   \n",
      "\n",
      "               ap4             ap5         as1         as2         as3  \\\n",
      "0              NaN             NaN         NaN         NaN         NaN   \n",
      "1   29820.09000000  29820.11000000  1.92227000  0.02688000  0.02689000   \n",
      "2   29820.11000000  29820.20000000  2.48119000  0.02688000  0.00222000   \n",
      "3   29819.70000000  29819.75000000  3.90382000  0.03046000  0.00074000   \n",
      "4   29819.75000000  29820.00000000  1.98067000  0.00074000  0.00036000   \n",
      "5   29819.70000000  29820.00000000  1.90625000  0.01450000  0.00074000   \n",
      "6   29819.70000000  29820.00000000  1.90545000  0.01450000  0.00074000   \n",
      "7   29820.00000000  29820.09000000  1.88693000  0.00074000  0.00036000   \n",
      "8   29819.71000000  29819.99000000  2.15159000  0.00074000  0.00036000   \n",
      "9   29819.71000000  29819.99000000  2.15159000  0.00074000  0.00036000   \n",
      "10  29819.70000000  29819.71000000  3.66217000  0.14181000  0.00074000   \n",
      "11  29819.70000000  29819.71000000  3.79434000  0.14181000  0.00074000   \n",
      "12  29816.29000000  29816.30000000  2.06426000  0.01855000  0.25145000   \n",
      "13  29816.29000000  29816.30000000  6.65887000  0.25145000  0.00450000   \n",
      "14  29815.44000000  29815.70000000  5.98766000  0.01196000  0.01195000   \n",
      "\n",
      "           as4         as5  \n",
      "0          NaN         NaN  \n",
      "1   0.00222000  0.08000000  \n",
      "2   0.08000000  0.00108000  \n",
      "3   0.00036000  0.08293000  \n",
      "4   0.08293000  1.00447000  \n",
      "5   0.00036000  1.11033000  \n",
      "6   0.00036000  1.11033000  \n",
      "7   1.08021000  0.07605000  \n",
      "8   0.08293000  0.49787000  \n",
      "9   0.08293000  0.49787000  \n",
      "10  0.00036000  0.08293000  \n",
      "11  0.00036000  0.08293000  \n",
      "12  0.00067000  0.54868000  \n",
      "13  0.00067000  0.54868000  \n",
      "14  0.25145000  0.40300000  \n",
      "\n",
      "[15 rows x 21 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/91/6wbfy1kd3c54vx64tq8sck_00000gn/T/ipykernel_6976/3022916258.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.df_0 = self.df_0.append(df, ignore_index = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    last_update_id             bp1             bp2             bp3  \\\n",
      "0              NaN             NaN             NaN             NaN   \n",
      "1     1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "2     1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "3     1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "4     1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "5     1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "6     1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "7     1.950054e+10  29819.58000000  29819.57000000  29819.32000000   \n",
      "8     1.950054e+10  29819.58000000  29819.57000000  29819.10000000   \n",
      "9     1.950054e+10  29819.58000000  29819.57000000  29819.10000000   \n",
      "10    1.950054e+10  29819.57000000  29819.10000000  29818.14000000   \n",
      "11    1.950054e+10  29819.57000000  29819.10000000  29818.14000000   \n",
      "12    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "13    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "14    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "\n",
      "               bp4             bp5         bs1         bs2         bs3  \\\n",
      "0              NaN             NaN         NaN         NaN         NaN   \n",
      "1   29819.48000000  29819.39000000  0.60625000  0.24868000  0.23807000   \n",
      "2   29819.39000000  29819.32000000  0.68641000  0.24868000  0.23807000   \n",
      "3   29819.32000000  29819.10000000  0.30421000  0.23807000  0.00373000   \n",
      "4   29819.32000000  29819.10000000  0.91948000  0.23807000  0.00373000   \n",
      "5   29819.32000000  29819.10000000  0.39849000  0.23807000  0.01755000   \n",
      "6   29819.32000000  29819.10000000  0.40640000  0.23807000  0.01755000   \n",
      "7   29819.10000000  29816.96000000  0.55670000  0.23807000  0.00042000   \n",
      "8   29817.67000000  29816.77000000  0.17616000  0.23807000  0.01000000   \n",
      "9   29818.14000000  29817.67000000  0.34906000  0.23807000  0.01000000   \n",
      "10  29817.67000000  29816.76000000  0.40690000  0.01000000  0.00450000   \n",
      "11  29817.67000000  29816.76000000  0.40690000  0.01000000  0.00450000   \n",
      "12  29812.74000000  29810.94000000  0.36085000  0.01665000  0.00720000   \n",
      "13  29813.04000000  29811.17000000  0.22782000  0.01665000  0.00720000   \n",
      "14  29813.04000000  29811.17000000  0.21910000  0.01665000  0.00720000   \n",
      "\n",
      "           bs4  ...             ap1             ap2             ap3  \\\n",
      "0          NaN  ...             NaN             NaN             NaN   \n",
      "1   0.02032000  ...  29820.00000000  29820.02000000  29820.04000000   \n",
      "2   0.00373000  ...  29820.00000000  29820.02000000  29820.09000000   \n",
      "3   0.00545000  ...  29819.59000000  29819.64000000  29819.65000000   \n",
      "4   0.00042000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "5   0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "6   0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "7   0.01000000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "8   0.00450000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "9   0.00450000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "10  0.00450000  ...  29819.58000000  29819.59000000  29819.65000000   \n",
      "11  0.00450000  ...  29819.58000000  29819.59000000  29819.65000000   \n",
      "12  0.00450000  ...  29814.55000000  29815.20000000  29815.44000000   \n",
      "13  0.00450000  ...  29814.55000000  29815.44000000  29816.05000000   \n",
      "14  0.00450000  ...  29814.55000000  29814.57000000  29814.59000000   \n",
      "\n",
      "               ap4             ap5         as1         as2         as3  \\\n",
      "0              NaN             NaN         NaN         NaN         NaN   \n",
      "1   29820.09000000  29820.11000000  1.92227000  0.02688000  0.02689000   \n",
      "2   29820.11000000  29820.20000000  2.48119000  0.02688000  0.00222000   \n",
      "3   29819.70000000  29819.75000000  3.90382000  0.03046000  0.00074000   \n",
      "4   29819.75000000  29820.00000000  1.98067000  0.00074000  0.00036000   \n",
      "5   29819.70000000  29820.00000000  1.90625000  0.01450000  0.00074000   \n",
      "6   29819.70000000  29820.00000000  1.90545000  0.01450000  0.00074000   \n",
      "7   29820.00000000  29820.09000000  1.88693000  0.00074000  0.00036000   \n",
      "8   29819.71000000  29819.99000000  2.15159000  0.00074000  0.00036000   \n",
      "9   29819.71000000  29819.99000000  2.15159000  0.00074000  0.00036000   \n",
      "10  29819.70000000  29819.71000000  3.66217000  0.14181000  0.00074000   \n",
      "11  29819.70000000  29819.71000000  3.79434000  0.14181000  0.00074000   \n",
      "12  29816.29000000  29816.30000000  2.06426000  0.01855000  0.25145000   \n",
      "13  29816.29000000  29816.30000000  6.65887000  0.25145000  0.00450000   \n",
      "14  29815.44000000  29815.70000000  5.98766000  0.01196000  0.01195000   \n",
      "\n",
      "           as4         as5  \n",
      "0          NaN         NaN  \n",
      "1   0.00222000  0.08000000  \n",
      "2   0.08000000  0.00108000  \n",
      "3   0.00036000  0.08293000  \n",
      "4   0.08293000  1.00447000  \n",
      "5   0.00036000  1.11033000  \n",
      "6   0.00036000  1.11033000  \n",
      "7   1.08021000  0.07605000  \n",
      "8   0.08293000  0.49787000  \n",
      "9   0.08293000  0.49787000  \n",
      "10  0.00036000  0.08293000  \n",
      "11  0.00036000  0.08293000  \n",
      "12  0.00067000  0.54868000  \n",
      "13  0.00067000  0.54868000  \n",
      "14  0.25145000  0.40300000  \n",
      "\n",
      "[15 rows x 21 columns]\n",
      "    last_update_id             bp1             bp2             bp3  \\\n",
      "0              NaN             NaN             NaN             NaN   \n",
      "1     1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "2     1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "3     1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "4     1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "5     1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "6     1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "7     1.950054e+10  29819.58000000  29819.57000000  29819.32000000   \n",
      "8     1.950054e+10  29819.58000000  29819.57000000  29819.10000000   \n",
      "9     1.950054e+10  29819.58000000  29819.57000000  29819.10000000   \n",
      "10    1.950054e+10  29819.57000000  29819.10000000  29818.14000000   \n",
      "11    1.950054e+10  29819.57000000  29819.10000000  29818.14000000   \n",
      "12    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "13    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "14    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "15    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "\n",
      "               bp4             bp5         bs1         bs2         bs3  \\\n",
      "0              NaN             NaN         NaN         NaN         NaN   \n",
      "1   29819.48000000  29819.39000000  0.60625000  0.24868000  0.23807000   \n",
      "2   29819.39000000  29819.32000000  0.68641000  0.24868000  0.23807000   \n",
      "3   29819.32000000  29819.10000000  0.30421000  0.23807000  0.00373000   \n",
      "4   29819.32000000  29819.10000000  0.91948000  0.23807000  0.00373000   \n",
      "5   29819.32000000  29819.10000000  0.39849000  0.23807000  0.01755000   \n",
      "6   29819.32000000  29819.10000000  0.40640000  0.23807000  0.01755000   \n",
      "7   29819.10000000  29816.96000000  0.55670000  0.23807000  0.00042000   \n",
      "8   29817.67000000  29816.77000000  0.17616000  0.23807000  0.01000000   \n",
      "9   29818.14000000  29817.67000000  0.34906000  0.23807000  0.01000000   \n",
      "10  29817.67000000  29816.76000000  0.40690000  0.01000000  0.00450000   \n",
      "11  29817.67000000  29816.76000000  0.40690000  0.01000000  0.00450000   \n",
      "12  29812.74000000  29810.94000000  0.36085000  0.01665000  0.00720000   \n",
      "13  29813.04000000  29811.17000000  0.22782000  0.01665000  0.00720000   \n",
      "14  29813.04000000  29811.17000000  0.21910000  0.01665000  0.00720000   \n",
      "15  29813.04000000  29811.17000000  0.11981000  0.01665000  0.00720000   \n",
      "\n",
      "           bs4  ...             ap1             ap2             ap3  \\\n",
      "0          NaN  ...             NaN             NaN             NaN   \n",
      "1   0.02032000  ...  29820.00000000  29820.02000000  29820.04000000   \n",
      "2   0.00373000  ...  29820.00000000  29820.02000000  29820.09000000   \n",
      "3   0.00545000  ...  29819.59000000  29819.64000000  29819.65000000   \n",
      "4   0.00042000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "5   0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "6   0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "7   0.01000000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "8   0.00450000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "9   0.00450000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "10  0.00450000  ...  29819.58000000  29819.59000000  29819.65000000   \n",
      "11  0.00450000  ...  29819.58000000  29819.59000000  29819.65000000   \n",
      "12  0.00450000  ...  29814.55000000  29815.20000000  29815.44000000   \n",
      "13  0.00450000  ...  29814.55000000  29815.44000000  29816.05000000   \n",
      "14  0.00450000  ...  29814.55000000  29814.57000000  29814.59000000   \n",
      "15  0.00450000  ...  29814.55000000  29814.57000000  29815.44000000   \n",
      "\n",
      "               ap4             ap5         as1         as2         as3  \\\n",
      "0              NaN             NaN         NaN         NaN         NaN   \n",
      "1   29820.09000000  29820.11000000  1.92227000  0.02688000  0.02689000   \n",
      "2   29820.11000000  29820.20000000  2.48119000  0.02688000  0.00222000   \n",
      "3   29819.70000000  29819.75000000  3.90382000  0.03046000  0.00074000   \n",
      "4   29819.75000000  29820.00000000  1.98067000  0.00074000  0.00036000   \n",
      "5   29819.70000000  29820.00000000  1.90625000  0.01450000  0.00074000   \n",
      "6   29819.70000000  29820.00000000  1.90545000  0.01450000  0.00074000   \n",
      "7   29820.00000000  29820.09000000  1.88693000  0.00074000  0.00036000   \n",
      "8   29819.71000000  29819.99000000  2.15159000  0.00074000  0.00036000   \n",
      "9   29819.71000000  29819.99000000  2.15159000  0.00074000  0.00036000   \n",
      "10  29819.70000000  29819.71000000  3.66217000  0.14181000  0.00074000   \n",
      "11  29819.70000000  29819.71000000  3.79434000  0.14181000  0.00074000   \n",
      "12  29816.29000000  29816.30000000  2.06426000  0.01855000  0.25145000   \n",
      "13  29816.29000000  29816.30000000  6.65887000  0.25145000  0.00450000   \n",
      "14  29815.44000000  29815.70000000  5.98766000  0.01196000  0.01195000   \n",
      "15  29815.70000000  29816.05000000  5.98088000  0.01196000  0.25145000   \n",
      "\n",
      "           as4         as5  \n",
      "0          NaN         NaN  \n",
      "1   0.00222000  0.08000000  \n",
      "2   0.08000000  0.00108000  \n",
      "3   0.00036000  0.08293000  \n",
      "4   0.08293000  1.00447000  \n",
      "5   0.00036000  1.11033000  \n",
      "6   0.00036000  1.11033000  \n",
      "7   1.08021000  0.07605000  \n",
      "8   0.08293000  0.49787000  \n",
      "9   0.08293000  0.49787000  \n",
      "10  0.00036000  0.08293000  \n",
      "11  0.00036000  0.08293000  \n",
      "12  0.00067000  0.54868000  \n",
      "13  0.00067000  0.54868000  \n",
      "14  0.25145000  0.40300000  \n",
      "15  0.40300000  0.00450000  \n",
      "\n",
      "[16 rows x 21 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/91/6wbfy1kd3c54vx64tq8sck_00000gn/T/ipykernel_6976/3022916258.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.df_0 = self.df_0.append(df, ignore_index = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    last_update_id             bp1             bp2             bp3  \\\n",
      "0              NaN             NaN             NaN             NaN   \n",
      "1     1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "2     1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "3     1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "4     1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "5     1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "6     1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "7     1.950054e+10  29819.58000000  29819.57000000  29819.32000000   \n",
      "8     1.950054e+10  29819.58000000  29819.57000000  29819.10000000   \n",
      "9     1.950054e+10  29819.58000000  29819.57000000  29819.10000000   \n",
      "10    1.950054e+10  29819.57000000  29819.10000000  29818.14000000   \n",
      "11    1.950054e+10  29819.57000000  29819.10000000  29818.14000000   \n",
      "12    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "13    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "14    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "15    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "\n",
      "               bp4             bp5         bs1         bs2         bs3  \\\n",
      "0              NaN             NaN         NaN         NaN         NaN   \n",
      "1   29819.48000000  29819.39000000  0.60625000  0.24868000  0.23807000   \n",
      "2   29819.39000000  29819.32000000  0.68641000  0.24868000  0.23807000   \n",
      "3   29819.32000000  29819.10000000  0.30421000  0.23807000  0.00373000   \n",
      "4   29819.32000000  29819.10000000  0.91948000  0.23807000  0.00373000   \n",
      "5   29819.32000000  29819.10000000  0.39849000  0.23807000  0.01755000   \n",
      "6   29819.32000000  29819.10000000  0.40640000  0.23807000  0.01755000   \n",
      "7   29819.10000000  29816.96000000  0.55670000  0.23807000  0.00042000   \n",
      "8   29817.67000000  29816.77000000  0.17616000  0.23807000  0.01000000   \n",
      "9   29818.14000000  29817.67000000  0.34906000  0.23807000  0.01000000   \n",
      "10  29817.67000000  29816.76000000  0.40690000  0.01000000  0.00450000   \n",
      "11  29817.67000000  29816.76000000  0.40690000  0.01000000  0.00450000   \n",
      "12  29812.74000000  29810.94000000  0.36085000  0.01665000  0.00720000   \n",
      "13  29813.04000000  29811.17000000  0.22782000  0.01665000  0.00720000   \n",
      "14  29813.04000000  29811.17000000  0.21910000  0.01665000  0.00720000   \n",
      "15  29813.04000000  29811.17000000  0.11981000  0.01665000  0.00720000   \n",
      "\n",
      "           bs4  ...             ap1             ap2             ap3  \\\n",
      "0          NaN  ...             NaN             NaN             NaN   \n",
      "1   0.02032000  ...  29820.00000000  29820.02000000  29820.04000000   \n",
      "2   0.00373000  ...  29820.00000000  29820.02000000  29820.09000000   \n",
      "3   0.00545000  ...  29819.59000000  29819.64000000  29819.65000000   \n",
      "4   0.00042000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "5   0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "6   0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "7   0.01000000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "8   0.00450000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "9   0.00450000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "10  0.00450000  ...  29819.58000000  29819.59000000  29819.65000000   \n",
      "11  0.00450000  ...  29819.58000000  29819.59000000  29819.65000000   \n",
      "12  0.00450000  ...  29814.55000000  29815.20000000  29815.44000000   \n",
      "13  0.00450000  ...  29814.55000000  29815.44000000  29816.05000000   \n",
      "14  0.00450000  ...  29814.55000000  29814.57000000  29814.59000000   \n",
      "15  0.00450000  ...  29814.55000000  29814.57000000  29815.44000000   \n",
      "\n",
      "               ap4             ap5         as1         as2         as3  \\\n",
      "0              NaN             NaN         NaN         NaN         NaN   \n",
      "1   29820.09000000  29820.11000000  1.92227000  0.02688000  0.02689000   \n",
      "2   29820.11000000  29820.20000000  2.48119000  0.02688000  0.00222000   \n",
      "3   29819.70000000  29819.75000000  3.90382000  0.03046000  0.00074000   \n",
      "4   29819.75000000  29820.00000000  1.98067000  0.00074000  0.00036000   \n",
      "5   29819.70000000  29820.00000000  1.90625000  0.01450000  0.00074000   \n",
      "6   29819.70000000  29820.00000000  1.90545000  0.01450000  0.00074000   \n",
      "7   29820.00000000  29820.09000000  1.88693000  0.00074000  0.00036000   \n",
      "8   29819.71000000  29819.99000000  2.15159000  0.00074000  0.00036000   \n",
      "9   29819.71000000  29819.99000000  2.15159000  0.00074000  0.00036000   \n",
      "10  29819.70000000  29819.71000000  3.66217000  0.14181000  0.00074000   \n",
      "11  29819.70000000  29819.71000000  3.79434000  0.14181000  0.00074000   \n",
      "12  29816.29000000  29816.30000000  2.06426000  0.01855000  0.25145000   \n",
      "13  29816.29000000  29816.30000000  6.65887000  0.25145000  0.00450000   \n",
      "14  29815.44000000  29815.70000000  5.98766000  0.01196000  0.01195000   \n",
      "15  29815.70000000  29816.05000000  5.98088000  0.01196000  0.25145000   \n",
      "\n",
      "           as4         as5  \n",
      "0          NaN         NaN  \n",
      "1   0.00222000  0.08000000  \n",
      "2   0.08000000  0.00108000  \n",
      "3   0.00036000  0.08293000  \n",
      "4   0.08293000  1.00447000  \n",
      "5   0.00036000  1.11033000  \n",
      "6   0.00036000  1.11033000  \n",
      "7   1.08021000  0.07605000  \n",
      "8   0.08293000  0.49787000  \n",
      "9   0.08293000  0.49787000  \n",
      "10  0.00036000  0.08293000  \n",
      "11  0.00036000  0.08293000  \n",
      "12  0.00067000  0.54868000  \n",
      "13  0.00067000  0.54868000  \n",
      "14  0.25145000  0.40300000  \n",
      "15  0.40300000  0.00450000  \n",
      "\n",
      "[16 rows x 21 columns]\n",
      "    last_update_id             bp1             bp2             bp3  \\\n",
      "0              NaN             NaN             NaN             NaN   \n",
      "1     1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "2     1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "3     1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "4     1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "5     1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "6     1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "7     1.950054e+10  29819.58000000  29819.57000000  29819.32000000   \n",
      "8     1.950054e+10  29819.58000000  29819.57000000  29819.10000000   \n",
      "9     1.950054e+10  29819.58000000  29819.57000000  29819.10000000   \n",
      "10    1.950054e+10  29819.57000000  29819.10000000  29818.14000000   \n",
      "11    1.950054e+10  29819.57000000  29819.10000000  29818.14000000   \n",
      "12    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "13    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "14    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "15    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "16    1.950054e+10  29814.54000000  29814.53000000  29814.48000000   \n",
      "\n",
      "               bp4             bp5         bs1         bs2         bs3  \\\n",
      "0              NaN             NaN         NaN         NaN         NaN   \n",
      "1   29819.48000000  29819.39000000  0.60625000  0.24868000  0.23807000   \n",
      "2   29819.39000000  29819.32000000  0.68641000  0.24868000  0.23807000   \n",
      "3   29819.32000000  29819.10000000  0.30421000  0.23807000  0.00373000   \n",
      "4   29819.32000000  29819.10000000  0.91948000  0.23807000  0.00373000   \n",
      "5   29819.32000000  29819.10000000  0.39849000  0.23807000  0.01755000   \n",
      "6   29819.32000000  29819.10000000  0.40640000  0.23807000  0.01755000   \n",
      "7   29819.10000000  29816.96000000  0.55670000  0.23807000  0.00042000   \n",
      "8   29817.67000000  29816.77000000  0.17616000  0.23807000  0.01000000   \n",
      "9   29818.14000000  29817.67000000  0.34906000  0.23807000  0.01000000   \n",
      "10  29817.67000000  29816.76000000  0.40690000  0.01000000  0.00450000   \n",
      "11  29817.67000000  29816.76000000  0.40690000  0.01000000  0.00450000   \n",
      "12  29812.74000000  29810.94000000  0.36085000  0.01665000  0.00720000   \n",
      "13  29813.04000000  29811.17000000  0.22782000  0.01665000  0.00720000   \n",
      "14  29813.04000000  29811.17000000  0.21910000  0.01665000  0.00720000   \n",
      "15  29813.04000000  29811.17000000  0.11981000  0.01665000  0.00720000   \n",
      "16  29814.45000000  29813.04000000  0.16352000  0.00114000  0.01665000   \n",
      "\n",
      "           bs4  ...             ap1             ap2             ap3  \\\n",
      "0          NaN  ...             NaN             NaN             NaN   \n",
      "1   0.02032000  ...  29820.00000000  29820.02000000  29820.04000000   \n",
      "2   0.00373000  ...  29820.00000000  29820.02000000  29820.09000000   \n",
      "3   0.00545000  ...  29819.59000000  29819.64000000  29819.65000000   \n",
      "4   0.00042000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "5   0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "6   0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "7   0.01000000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "8   0.00450000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "9   0.00450000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "10  0.00450000  ...  29819.58000000  29819.59000000  29819.65000000   \n",
      "11  0.00450000  ...  29819.58000000  29819.59000000  29819.65000000   \n",
      "12  0.00450000  ...  29814.55000000  29815.20000000  29815.44000000   \n",
      "13  0.00450000  ...  29814.55000000  29815.44000000  29816.05000000   \n",
      "14  0.00450000  ...  29814.55000000  29814.57000000  29814.59000000   \n",
      "15  0.00450000  ...  29814.55000000  29814.57000000  29815.44000000   \n",
      "16  0.00720000  ...  29814.55000000  29814.57000000  29814.94000000   \n",
      "\n",
      "               ap4             ap5         as1         as2         as3  \\\n",
      "0              NaN             NaN         NaN         NaN         NaN   \n",
      "1   29820.09000000  29820.11000000  1.92227000  0.02688000  0.02689000   \n",
      "2   29820.11000000  29820.20000000  2.48119000  0.02688000  0.00222000   \n",
      "3   29819.70000000  29819.75000000  3.90382000  0.03046000  0.00074000   \n",
      "4   29819.75000000  29820.00000000  1.98067000  0.00074000  0.00036000   \n",
      "5   29819.70000000  29820.00000000  1.90625000  0.01450000  0.00074000   \n",
      "6   29819.70000000  29820.00000000  1.90545000  0.01450000  0.00074000   \n",
      "7   29820.00000000  29820.09000000  1.88693000  0.00074000  0.00036000   \n",
      "8   29819.71000000  29819.99000000  2.15159000  0.00074000  0.00036000   \n",
      "9   29819.71000000  29819.99000000  2.15159000  0.00074000  0.00036000   \n",
      "10  29819.70000000  29819.71000000  3.66217000  0.14181000  0.00074000   \n",
      "11  29819.70000000  29819.71000000  3.79434000  0.14181000  0.00074000   \n",
      "12  29816.29000000  29816.30000000  2.06426000  0.01855000  0.25145000   \n",
      "13  29816.29000000  29816.30000000  6.65887000  0.25145000  0.00450000   \n",
      "14  29815.44000000  29815.70000000  5.98766000  0.01196000  0.01195000   \n",
      "15  29815.70000000  29816.05000000  5.98088000  0.01196000  0.25145000   \n",
      "16  29815.44000000  29815.70000000  5.38666000  0.01196000  0.05010000   \n",
      "\n",
      "           as4         as5  \n",
      "0          NaN         NaN  \n",
      "1   0.00222000  0.08000000  \n",
      "2   0.08000000  0.00108000  \n",
      "3   0.00036000  0.08293000  \n",
      "4   0.08293000  1.00447000  \n",
      "5   0.00036000  1.11033000  \n",
      "6   0.00036000  1.11033000  \n",
      "7   1.08021000  0.07605000  \n",
      "8   0.08293000  0.49787000  \n",
      "9   0.08293000  0.49787000  \n",
      "10  0.00036000  0.08293000  \n",
      "11  0.00036000  0.08293000  \n",
      "12  0.00067000  0.54868000  \n",
      "13  0.00067000  0.54868000  \n",
      "14  0.25145000  0.40300000  \n",
      "15  0.40300000  0.00450000  \n",
      "16  0.25139000  0.40300000  \n",
      "\n",
      "[17 rows x 21 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/91/6wbfy1kd3c54vx64tq8sck_00000gn/T/ipykernel_6976/3022916258.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.df_0 = self.df_0.append(df, ignore_index = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    last_update_id             bp1             bp2             bp3  \\\n",
      "0              NaN             NaN             NaN             NaN   \n",
      "1     1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "2     1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "3     1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "4     1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "5     1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "6     1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "7     1.950054e+10  29819.58000000  29819.57000000  29819.32000000   \n",
      "8     1.950054e+10  29819.58000000  29819.57000000  29819.10000000   \n",
      "9     1.950054e+10  29819.58000000  29819.57000000  29819.10000000   \n",
      "10    1.950054e+10  29819.57000000  29819.10000000  29818.14000000   \n",
      "11    1.950054e+10  29819.57000000  29819.10000000  29818.14000000   \n",
      "12    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "13    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "14    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "15    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "16    1.950054e+10  29814.54000000  29814.53000000  29814.48000000   \n",
      "\n",
      "               bp4             bp5         bs1         bs2         bs3  \\\n",
      "0              NaN             NaN         NaN         NaN         NaN   \n",
      "1   29819.48000000  29819.39000000  0.60625000  0.24868000  0.23807000   \n",
      "2   29819.39000000  29819.32000000  0.68641000  0.24868000  0.23807000   \n",
      "3   29819.32000000  29819.10000000  0.30421000  0.23807000  0.00373000   \n",
      "4   29819.32000000  29819.10000000  0.91948000  0.23807000  0.00373000   \n",
      "5   29819.32000000  29819.10000000  0.39849000  0.23807000  0.01755000   \n",
      "6   29819.32000000  29819.10000000  0.40640000  0.23807000  0.01755000   \n",
      "7   29819.10000000  29816.96000000  0.55670000  0.23807000  0.00042000   \n",
      "8   29817.67000000  29816.77000000  0.17616000  0.23807000  0.01000000   \n",
      "9   29818.14000000  29817.67000000  0.34906000  0.23807000  0.01000000   \n",
      "10  29817.67000000  29816.76000000  0.40690000  0.01000000  0.00450000   \n",
      "11  29817.67000000  29816.76000000  0.40690000  0.01000000  0.00450000   \n",
      "12  29812.74000000  29810.94000000  0.36085000  0.01665000  0.00720000   \n",
      "13  29813.04000000  29811.17000000  0.22782000  0.01665000  0.00720000   \n",
      "14  29813.04000000  29811.17000000  0.21910000  0.01665000  0.00720000   \n",
      "15  29813.04000000  29811.17000000  0.11981000  0.01665000  0.00720000   \n",
      "16  29814.45000000  29813.04000000  0.16352000  0.00114000  0.01665000   \n",
      "\n",
      "           bs4  ...             ap1             ap2             ap3  \\\n",
      "0          NaN  ...             NaN             NaN             NaN   \n",
      "1   0.02032000  ...  29820.00000000  29820.02000000  29820.04000000   \n",
      "2   0.00373000  ...  29820.00000000  29820.02000000  29820.09000000   \n",
      "3   0.00545000  ...  29819.59000000  29819.64000000  29819.65000000   \n",
      "4   0.00042000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "5   0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "6   0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "7   0.01000000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "8   0.00450000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "9   0.00450000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "10  0.00450000  ...  29819.58000000  29819.59000000  29819.65000000   \n",
      "11  0.00450000  ...  29819.58000000  29819.59000000  29819.65000000   \n",
      "12  0.00450000  ...  29814.55000000  29815.20000000  29815.44000000   \n",
      "13  0.00450000  ...  29814.55000000  29815.44000000  29816.05000000   \n",
      "14  0.00450000  ...  29814.55000000  29814.57000000  29814.59000000   \n",
      "15  0.00450000  ...  29814.55000000  29814.57000000  29815.44000000   \n",
      "16  0.00720000  ...  29814.55000000  29814.57000000  29814.94000000   \n",
      "\n",
      "               ap4             ap5         as1         as2         as3  \\\n",
      "0              NaN             NaN         NaN         NaN         NaN   \n",
      "1   29820.09000000  29820.11000000  1.92227000  0.02688000  0.02689000   \n",
      "2   29820.11000000  29820.20000000  2.48119000  0.02688000  0.00222000   \n",
      "3   29819.70000000  29819.75000000  3.90382000  0.03046000  0.00074000   \n",
      "4   29819.75000000  29820.00000000  1.98067000  0.00074000  0.00036000   \n",
      "5   29819.70000000  29820.00000000  1.90625000  0.01450000  0.00074000   \n",
      "6   29819.70000000  29820.00000000  1.90545000  0.01450000  0.00074000   \n",
      "7   29820.00000000  29820.09000000  1.88693000  0.00074000  0.00036000   \n",
      "8   29819.71000000  29819.99000000  2.15159000  0.00074000  0.00036000   \n",
      "9   29819.71000000  29819.99000000  2.15159000  0.00074000  0.00036000   \n",
      "10  29819.70000000  29819.71000000  3.66217000  0.14181000  0.00074000   \n",
      "11  29819.70000000  29819.71000000  3.79434000  0.14181000  0.00074000   \n",
      "12  29816.29000000  29816.30000000  2.06426000  0.01855000  0.25145000   \n",
      "13  29816.29000000  29816.30000000  6.65887000  0.25145000  0.00450000   \n",
      "14  29815.44000000  29815.70000000  5.98766000  0.01196000  0.01195000   \n",
      "15  29815.70000000  29816.05000000  5.98088000  0.01196000  0.25145000   \n",
      "16  29815.44000000  29815.70000000  5.38666000  0.01196000  0.05010000   \n",
      "\n",
      "           as4         as5  \n",
      "0          NaN         NaN  \n",
      "1   0.00222000  0.08000000  \n",
      "2   0.08000000  0.00108000  \n",
      "3   0.00036000  0.08293000  \n",
      "4   0.08293000  1.00447000  \n",
      "5   0.00036000  1.11033000  \n",
      "6   0.00036000  1.11033000  \n",
      "7   1.08021000  0.07605000  \n",
      "8   0.08293000  0.49787000  \n",
      "9   0.08293000  0.49787000  \n",
      "10  0.00036000  0.08293000  \n",
      "11  0.00036000  0.08293000  \n",
      "12  0.00067000  0.54868000  \n",
      "13  0.00067000  0.54868000  \n",
      "14  0.25145000  0.40300000  \n",
      "15  0.40300000  0.00450000  \n",
      "16  0.25139000  0.40300000  \n",
      "\n",
      "[17 rows x 21 columns]\n",
      "    last_update_id             bp1             bp2             bp3  \\\n",
      "0              NaN             NaN             NaN             NaN   \n",
      "1     1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "2     1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "3     1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "4     1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "5     1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "6     1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "7     1.950054e+10  29819.58000000  29819.57000000  29819.32000000   \n",
      "8     1.950054e+10  29819.58000000  29819.57000000  29819.10000000   \n",
      "9     1.950054e+10  29819.58000000  29819.57000000  29819.10000000   \n",
      "10    1.950054e+10  29819.57000000  29819.10000000  29818.14000000   \n",
      "11    1.950054e+10  29819.57000000  29819.10000000  29818.14000000   \n",
      "12    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "13    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "14    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "15    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "16    1.950054e+10  29814.54000000  29814.53000000  29814.48000000   \n",
      "17    1.950054e+10  29814.54000000  29814.53000000  29814.48000000   \n",
      "\n",
      "               bp4             bp5         bs1         bs2         bs3  \\\n",
      "0              NaN             NaN         NaN         NaN         NaN   \n",
      "1   29819.48000000  29819.39000000  0.60625000  0.24868000  0.23807000   \n",
      "2   29819.39000000  29819.32000000  0.68641000  0.24868000  0.23807000   \n",
      "3   29819.32000000  29819.10000000  0.30421000  0.23807000  0.00373000   \n",
      "4   29819.32000000  29819.10000000  0.91948000  0.23807000  0.00373000   \n",
      "5   29819.32000000  29819.10000000  0.39849000  0.23807000  0.01755000   \n",
      "6   29819.32000000  29819.10000000  0.40640000  0.23807000  0.01755000   \n",
      "7   29819.10000000  29816.96000000  0.55670000  0.23807000  0.00042000   \n",
      "8   29817.67000000  29816.77000000  0.17616000  0.23807000  0.01000000   \n",
      "9   29818.14000000  29817.67000000  0.34906000  0.23807000  0.01000000   \n",
      "10  29817.67000000  29816.76000000  0.40690000  0.01000000  0.00450000   \n",
      "11  29817.67000000  29816.76000000  0.40690000  0.01000000  0.00450000   \n",
      "12  29812.74000000  29810.94000000  0.36085000  0.01665000  0.00720000   \n",
      "13  29813.04000000  29811.17000000  0.22782000  0.01665000  0.00720000   \n",
      "14  29813.04000000  29811.17000000  0.21910000  0.01665000  0.00720000   \n",
      "15  29813.04000000  29811.17000000  0.11981000  0.01665000  0.00720000   \n",
      "16  29814.45000000  29813.04000000  0.16352000  0.00114000  0.01665000   \n",
      "17  29814.45000000  29814.33000000  0.34986000  0.00114000  0.01665000   \n",
      "\n",
      "           bs4  ...             ap1             ap2             ap3  \\\n",
      "0          NaN  ...             NaN             NaN             NaN   \n",
      "1   0.02032000  ...  29820.00000000  29820.02000000  29820.04000000   \n",
      "2   0.00373000  ...  29820.00000000  29820.02000000  29820.09000000   \n",
      "3   0.00545000  ...  29819.59000000  29819.64000000  29819.65000000   \n",
      "4   0.00042000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "5   0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "6   0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "7   0.01000000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "8   0.00450000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "9   0.00450000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "10  0.00450000  ...  29819.58000000  29819.59000000  29819.65000000   \n",
      "11  0.00450000  ...  29819.58000000  29819.59000000  29819.65000000   \n",
      "12  0.00450000  ...  29814.55000000  29815.20000000  29815.44000000   \n",
      "13  0.00450000  ...  29814.55000000  29815.44000000  29816.05000000   \n",
      "14  0.00450000  ...  29814.55000000  29814.57000000  29814.59000000   \n",
      "15  0.00450000  ...  29814.55000000  29814.57000000  29815.44000000   \n",
      "16  0.00720000  ...  29814.55000000  29814.57000000  29814.94000000   \n",
      "17  0.00720000  ...  29814.55000000  29814.59000000  29814.94000000   \n",
      "\n",
      "               ap4             ap5         as1         as2         as3  \\\n",
      "0              NaN             NaN         NaN         NaN         NaN   \n",
      "1   29820.09000000  29820.11000000  1.92227000  0.02688000  0.02689000   \n",
      "2   29820.11000000  29820.20000000  2.48119000  0.02688000  0.00222000   \n",
      "3   29819.70000000  29819.75000000  3.90382000  0.03046000  0.00074000   \n",
      "4   29819.75000000  29820.00000000  1.98067000  0.00074000  0.00036000   \n",
      "5   29819.70000000  29820.00000000  1.90625000  0.01450000  0.00074000   \n",
      "6   29819.70000000  29820.00000000  1.90545000  0.01450000  0.00074000   \n",
      "7   29820.00000000  29820.09000000  1.88693000  0.00074000  0.00036000   \n",
      "8   29819.71000000  29819.99000000  2.15159000  0.00074000  0.00036000   \n",
      "9   29819.71000000  29819.99000000  2.15159000  0.00074000  0.00036000   \n",
      "10  29819.70000000  29819.71000000  3.66217000  0.14181000  0.00074000   \n",
      "11  29819.70000000  29819.71000000  3.79434000  0.14181000  0.00074000   \n",
      "12  29816.29000000  29816.30000000  2.06426000  0.01855000  0.25145000   \n",
      "13  29816.29000000  29816.30000000  6.65887000  0.25145000  0.00450000   \n",
      "14  29815.44000000  29815.70000000  5.98766000  0.01196000  0.01195000   \n",
      "15  29815.70000000  29816.05000000  5.98088000  0.01196000  0.25145000   \n",
      "16  29815.44000000  29815.70000000  5.38666000  0.01196000  0.05010000   \n",
      "17  29815.44000000  29815.70000000  5.28294000  0.00082000  0.05010000   \n",
      "\n",
      "           as4         as5  \n",
      "0          NaN         NaN  \n",
      "1   0.00222000  0.08000000  \n",
      "2   0.08000000  0.00108000  \n",
      "3   0.00036000  0.08293000  \n",
      "4   0.08293000  1.00447000  \n",
      "5   0.00036000  1.11033000  \n",
      "6   0.00036000  1.11033000  \n",
      "7   1.08021000  0.07605000  \n",
      "8   0.08293000  0.49787000  \n",
      "9   0.08293000  0.49787000  \n",
      "10  0.00036000  0.08293000  \n",
      "11  0.00036000  0.08293000  \n",
      "12  0.00067000  0.54868000  \n",
      "13  0.00067000  0.54868000  \n",
      "14  0.25145000  0.40300000  \n",
      "15  0.40300000  0.00450000  \n",
      "16  0.25139000  0.40300000  \n",
      "17  0.25139000  0.40300000  \n",
      "\n",
      "[18 rows x 21 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/91/6wbfy1kd3c54vx64tq8sck_00000gn/T/ipykernel_6976/3022916258.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.df_0 = self.df_0.append(df, ignore_index = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    last_update_id             bp1             bp2             bp3  \\\n",
      "0              NaN             NaN             NaN             NaN   \n",
      "1     1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "2     1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "3     1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "4     1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "5     1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "6     1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "7     1.950054e+10  29819.58000000  29819.57000000  29819.32000000   \n",
      "8     1.950054e+10  29819.58000000  29819.57000000  29819.10000000   \n",
      "9     1.950054e+10  29819.58000000  29819.57000000  29819.10000000   \n",
      "10    1.950054e+10  29819.57000000  29819.10000000  29818.14000000   \n",
      "11    1.950054e+10  29819.57000000  29819.10000000  29818.14000000   \n",
      "12    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "13    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "14    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "15    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "16    1.950054e+10  29814.54000000  29814.53000000  29814.48000000   \n",
      "17    1.950054e+10  29814.54000000  29814.53000000  29814.48000000   \n",
      "\n",
      "               bp4             bp5         bs1         bs2         bs3  \\\n",
      "0              NaN             NaN         NaN         NaN         NaN   \n",
      "1   29819.48000000  29819.39000000  0.60625000  0.24868000  0.23807000   \n",
      "2   29819.39000000  29819.32000000  0.68641000  0.24868000  0.23807000   \n",
      "3   29819.32000000  29819.10000000  0.30421000  0.23807000  0.00373000   \n",
      "4   29819.32000000  29819.10000000  0.91948000  0.23807000  0.00373000   \n",
      "5   29819.32000000  29819.10000000  0.39849000  0.23807000  0.01755000   \n",
      "6   29819.32000000  29819.10000000  0.40640000  0.23807000  0.01755000   \n",
      "7   29819.10000000  29816.96000000  0.55670000  0.23807000  0.00042000   \n",
      "8   29817.67000000  29816.77000000  0.17616000  0.23807000  0.01000000   \n",
      "9   29818.14000000  29817.67000000  0.34906000  0.23807000  0.01000000   \n",
      "10  29817.67000000  29816.76000000  0.40690000  0.01000000  0.00450000   \n",
      "11  29817.67000000  29816.76000000  0.40690000  0.01000000  0.00450000   \n",
      "12  29812.74000000  29810.94000000  0.36085000  0.01665000  0.00720000   \n",
      "13  29813.04000000  29811.17000000  0.22782000  0.01665000  0.00720000   \n",
      "14  29813.04000000  29811.17000000  0.21910000  0.01665000  0.00720000   \n",
      "15  29813.04000000  29811.17000000  0.11981000  0.01665000  0.00720000   \n",
      "16  29814.45000000  29813.04000000  0.16352000  0.00114000  0.01665000   \n",
      "17  29814.45000000  29814.33000000  0.34986000  0.00114000  0.01665000   \n",
      "\n",
      "           bs4  ...             ap1             ap2             ap3  \\\n",
      "0          NaN  ...             NaN             NaN             NaN   \n",
      "1   0.02032000  ...  29820.00000000  29820.02000000  29820.04000000   \n",
      "2   0.00373000  ...  29820.00000000  29820.02000000  29820.09000000   \n",
      "3   0.00545000  ...  29819.59000000  29819.64000000  29819.65000000   \n",
      "4   0.00042000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "5   0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "6   0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "7   0.01000000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "8   0.00450000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "9   0.00450000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "10  0.00450000  ...  29819.58000000  29819.59000000  29819.65000000   \n",
      "11  0.00450000  ...  29819.58000000  29819.59000000  29819.65000000   \n",
      "12  0.00450000  ...  29814.55000000  29815.20000000  29815.44000000   \n",
      "13  0.00450000  ...  29814.55000000  29815.44000000  29816.05000000   \n",
      "14  0.00450000  ...  29814.55000000  29814.57000000  29814.59000000   \n",
      "15  0.00450000  ...  29814.55000000  29814.57000000  29815.44000000   \n",
      "16  0.00720000  ...  29814.55000000  29814.57000000  29814.94000000   \n",
      "17  0.00720000  ...  29814.55000000  29814.59000000  29814.94000000   \n",
      "\n",
      "               ap4             ap5         as1         as2         as3  \\\n",
      "0              NaN             NaN         NaN         NaN         NaN   \n",
      "1   29820.09000000  29820.11000000  1.92227000  0.02688000  0.02689000   \n",
      "2   29820.11000000  29820.20000000  2.48119000  0.02688000  0.00222000   \n",
      "3   29819.70000000  29819.75000000  3.90382000  0.03046000  0.00074000   \n",
      "4   29819.75000000  29820.00000000  1.98067000  0.00074000  0.00036000   \n",
      "5   29819.70000000  29820.00000000  1.90625000  0.01450000  0.00074000   \n",
      "6   29819.70000000  29820.00000000  1.90545000  0.01450000  0.00074000   \n",
      "7   29820.00000000  29820.09000000  1.88693000  0.00074000  0.00036000   \n",
      "8   29819.71000000  29819.99000000  2.15159000  0.00074000  0.00036000   \n",
      "9   29819.71000000  29819.99000000  2.15159000  0.00074000  0.00036000   \n",
      "10  29819.70000000  29819.71000000  3.66217000  0.14181000  0.00074000   \n",
      "11  29819.70000000  29819.71000000  3.79434000  0.14181000  0.00074000   \n",
      "12  29816.29000000  29816.30000000  2.06426000  0.01855000  0.25145000   \n",
      "13  29816.29000000  29816.30000000  6.65887000  0.25145000  0.00450000   \n",
      "14  29815.44000000  29815.70000000  5.98766000  0.01196000  0.01195000   \n",
      "15  29815.70000000  29816.05000000  5.98088000  0.01196000  0.25145000   \n",
      "16  29815.44000000  29815.70000000  5.38666000  0.01196000  0.05010000   \n",
      "17  29815.44000000  29815.70000000  5.28294000  0.00082000  0.05010000   \n",
      "\n",
      "           as4         as5  \n",
      "0          NaN         NaN  \n",
      "1   0.00222000  0.08000000  \n",
      "2   0.08000000  0.00108000  \n",
      "3   0.00036000  0.08293000  \n",
      "4   0.08293000  1.00447000  \n",
      "5   0.00036000  1.11033000  \n",
      "6   0.00036000  1.11033000  \n",
      "7   1.08021000  0.07605000  \n",
      "8   0.08293000  0.49787000  \n",
      "9   0.08293000  0.49787000  \n",
      "10  0.00036000  0.08293000  \n",
      "11  0.00036000  0.08293000  \n",
      "12  0.00067000  0.54868000  \n",
      "13  0.00067000  0.54868000  \n",
      "14  0.25145000  0.40300000  \n",
      "15  0.40300000  0.00450000  \n",
      "16  0.25139000  0.40300000  \n",
      "17  0.25139000  0.40300000  \n",
      "\n",
      "[18 rows x 21 columns]\n",
      "    last_update_id             bp1             bp2             bp3  \\\n",
      "0              NaN             NaN             NaN             NaN   \n",
      "1     1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "2     1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "3     1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "4     1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "5     1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "6     1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "7     1.950054e+10  29819.58000000  29819.57000000  29819.32000000   \n",
      "8     1.950054e+10  29819.58000000  29819.57000000  29819.10000000   \n",
      "9     1.950054e+10  29819.58000000  29819.57000000  29819.10000000   \n",
      "10    1.950054e+10  29819.57000000  29819.10000000  29818.14000000   \n",
      "11    1.950054e+10  29819.57000000  29819.10000000  29818.14000000   \n",
      "12    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "13    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "14    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "15    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "16    1.950054e+10  29814.54000000  29814.53000000  29814.48000000   \n",
      "17    1.950054e+10  29814.54000000  29814.53000000  29814.48000000   \n",
      "18    1.950054e+10  29808.50000000  29808.45000000  29808.38000000   \n",
      "\n",
      "               bp4             bp5         bs1         bs2         bs3  \\\n",
      "0              NaN             NaN         NaN         NaN         NaN   \n",
      "1   29819.48000000  29819.39000000  0.60625000  0.24868000  0.23807000   \n",
      "2   29819.39000000  29819.32000000  0.68641000  0.24868000  0.23807000   \n",
      "3   29819.32000000  29819.10000000  0.30421000  0.23807000  0.00373000   \n",
      "4   29819.32000000  29819.10000000  0.91948000  0.23807000  0.00373000   \n",
      "5   29819.32000000  29819.10000000  0.39849000  0.23807000  0.01755000   \n",
      "6   29819.32000000  29819.10000000  0.40640000  0.23807000  0.01755000   \n",
      "7   29819.10000000  29816.96000000  0.55670000  0.23807000  0.00042000   \n",
      "8   29817.67000000  29816.77000000  0.17616000  0.23807000  0.01000000   \n",
      "9   29818.14000000  29817.67000000  0.34906000  0.23807000  0.01000000   \n",
      "10  29817.67000000  29816.76000000  0.40690000  0.01000000  0.00450000   \n",
      "11  29817.67000000  29816.76000000  0.40690000  0.01000000  0.00450000   \n",
      "12  29812.74000000  29810.94000000  0.36085000  0.01665000  0.00720000   \n",
      "13  29813.04000000  29811.17000000  0.22782000  0.01665000  0.00720000   \n",
      "14  29813.04000000  29811.17000000  0.21910000  0.01665000  0.00720000   \n",
      "15  29813.04000000  29811.17000000  0.11981000  0.01665000  0.00720000   \n",
      "16  29814.45000000  29813.04000000  0.16352000  0.00114000  0.01665000   \n",
      "17  29814.45000000  29814.33000000  0.34986000  0.00114000  0.01665000   \n",
      "18  29808.16000000  29808.02000000  0.24903000  0.00864000  0.01574000   \n",
      "\n",
      "           bs4  ...             ap1             ap2             ap3  \\\n",
      "0          NaN  ...             NaN             NaN             NaN   \n",
      "1   0.02032000  ...  29820.00000000  29820.02000000  29820.04000000   \n",
      "2   0.00373000  ...  29820.00000000  29820.02000000  29820.09000000   \n",
      "3   0.00545000  ...  29819.59000000  29819.64000000  29819.65000000   \n",
      "4   0.00042000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "5   0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "6   0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "7   0.01000000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "8   0.00450000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "9   0.00450000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "10  0.00450000  ...  29819.58000000  29819.59000000  29819.65000000   \n",
      "11  0.00450000  ...  29819.58000000  29819.59000000  29819.65000000   \n",
      "12  0.00450000  ...  29814.55000000  29815.20000000  29815.44000000   \n",
      "13  0.00450000  ...  29814.55000000  29815.44000000  29816.05000000   \n",
      "14  0.00450000  ...  29814.55000000  29814.57000000  29814.59000000   \n",
      "15  0.00450000  ...  29814.55000000  29814.57000000  29815.44000000   \n",
      "16  0.00720000  ...  29814.55000000  29814.57000000  29814.94000000   \n",
      "17  0.00720000  ...  29814.55000000  29814.59000000  29814.94000000   \n",
      "18  0.00450000  ...  29808.51000000  29808.52000000  29808.53000000   \n",
      "\n",
      "               ap4             ap5         as1         as2         as3  \\\n",
      "0              NaN             NaN         NaN         NaN         NaN   \n",
      "1   29820.09000000  29820.11000000  1.92227000  0.02688000  0.02689000   \n",
      "2   29820.11000000  29820.20000000  2.48119000  0.02688000  0.00222000   \n",
      "3   29819.70000000  29819.75000000  3.90382000  0.03046000  0.00074000   \n",
      "4   29819.75000000  29820.00000000  1.98067000  0.00074000  0.00036000   \n",
      "5   29819.70000000  29820.00000000  1.90625000  0.01450000  0.00074000   \n",
      "6   29819.70000000  29820.00000000  1.90545000  0.01450000  0.00074000   \n",
      "7   29820.00000000  29820.09000000  1.88693000  0.00074000  0.00036000   \n",
      "8   29819.71000000  29819.99000000  2.15159000  0.00074000  0.00036000   \n",
      "9   29819.71000000  29819.99000000  2.15159000  0.00074000  0.00036000   \n",
      "10  29819.70000000  29819.71000000  3.66217000  0.14181000  0.00074000   \n",
      "11  29819.70000000  29819.71000000  3.79434000  0.14181000  0.00074000   \n",
      "12  29816.29000000  29816.30000000  2.06426000  0.01855000  0.25145000   \n",
      "13  29816.29000000  29816.30000000  6.65887000  0.25145000  0.00450000   \n",
      "14  29815.44000000  29815.70000000  5.98766000  0.01196000  0.01195000   \n",
      "15  29815.70000000  29816.05000000  5.98088000  0.01196000  0.25145000   \n",
      "16  29815.44000000  29815.70000000  5.38666000  0.01196000  0.05010000   \n",
      "17  29815.44000000  29815.70000000  5.28294000  0.00082000  0.05010000   \n",
      "18  29808.71000000  29809.49000000  2.62421000  0.69401000  0.54868000   \n",
      "\n",
      "           as4         as5  \n",
      "0          NaN         NaN  \n",
      "1   0.00222000  0.08000000  \n",
      "2   0.08000000  0.00108000  \n",
      "3   0.00036000  0.08293000  \n",
      "4   0.08293000  1.00447000  \n",
      "5   0.00036000  1.11033000  \n",
      "6   0.00036000  1.11033000  \n",
      "7   1.08021000  0.07605000  \n",
      "8   0.08293000  0.49787000  \n",
      "9   0.08293000  0.49787000  \n",
      "10  0.00036000  0.08293000  \n",
      "11  0.00036000  0.08293000  \n",
      "12  0.00067000  0.54868000  \n",
      "13  0.00067000  0.54868000  \n",
      "14  0.25145000  0.40300000  \n",
      "15  0.40300000  0.00450000  \n",
      "16  0.25139000  0.40300000  \n",
      "17  0.25139000  0.40300000  \n",
      "18  0.08293000  0.25144000  \n",
      "\n",
      "[19 rows x 21 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/91/6wbfy1kd3c54vx64tq8sck_00000gn/T/ipykernel_6976/3022916258.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.df_0 = self.df_0.append(df, ignore_index = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    last_update_id             bp1             bp2             bp3  \\\n",
      "0              NaN             NaN             NaN             NaN   \n",
      "1     1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "2     1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "3     1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "4     1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "5     1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "6     1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "7     1.950054e+10  29819.58000000  29819.57000000  29819.32000000   \n",
      "8     1.950054e+10  29819.58000000  29819.57000000  29819.10000000   \n",
      "9     1.950054e+10  29819.58000000  29819.57000000  29819.10000000   \n",
      "10    1.950054e+10  29819.57000000  29819.10000000  29818.14000000   \n",
      "11    1.950054e+10  29819.57000000  29819.10000000  29818.14000000   \n",
      "12    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "13    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "14    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "15    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "16    1.950054e+10  29814.54000000  29814.53000000  29814.48000000   \n",
      "17    1.950054e+10  29814.54000000  29814.53000000  29814.48000000   \n",
      "18    1.950054e+10  29808.50000000  29808.45000000  29808.38000000   \n",
      "\n",
      "               bp4             bp5         bs1         bs2         bs3  \\\n",
      "0              NaN             NaN         NaN         NaN         NaN   \n",
      "1   29819.48000000  29819.39000000  0.60625000  0.24868000  0.23807000   \n",
      "2   29819.39000000  29819.32000000  0.68641000  0.24868000  0.23807000   \n",
      "3   29819.32000000  29819.10000000  0.30421000  0.23807000  0.00373000   \n",
      "4   29819.32000000  29819.10000000  0.91948000  0.23807000  0.00373000   \n",
      "5   29819.32000000  29819.10000000  0.39849000  0.23807000  0.01755000   \n",
      "6   29819.32000000  29819.10000000  0.40640000  0.23807000  0.01755000   \n",
      "7   29819.10000000  29816.96000000  0.55670000  0.23807000  0.00042000   \n",
      "8   29817.67000000  29816.77000000  0.17616000  0.23807000  0.01000000   \n",
      "9   29818.14000000  29817.67000000  0.34906000  0.23807000  0.01000000   \n",
      "10  29817.67000000  29816.76000000  0.40690000  0.01000000  0.00450000   \n",
      "11  29817.67000000  29816.76000000  0.40690000  0.01000000  0.00450000   \n",
      "12  29812.74000000  29810.94000000  0.36085000  0.01665000  0.00720000   \n",
      "13  29813.04000000  29811.17000000  0.22782000  0.01665000  0.00720000   \n",
      "14  29813.04000000  29811.17000000  0.21910000  0.01665000  0.00720000   \n",
      "15  29813.04000000  29811.17000000  0.11981000  0.01665000  0.00720000   \n",
      "16  29814.45000000  29813.04000000  0.16352000  0.00114000  0.01665000   \n",
      "17  29814.45000000  29814.33000000  0.34986000  0.00114000  0.01665000   \n",
      "18  29808.16000000  29808.02000000  0.24903000  0.00864000  0.01574000   \n",
      "\n",
      "           bs4  ...             ap1             ap2             ap3  \\\n",
      "0          NaN  ...             NaN             NaN             NaN   \n",
      "1   0.02032000  ...  29820.00000000  29820.02000000  29820.04000000   \n",
      "2   0.00373000  ...  29820.00000000  29820.02000000  29820.09000000   \n",
      "3   0.00545000  ...  29819.59000000  29819.64000000  29819.65000000   \n",
      "4   0.00042000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "5   0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "6   0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "7   0.01000000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "8   0.00450000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "9   0.00450000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "10  0.00450000  ...  29819.58000000  29819.59000000  29819.65000000   \n",
      "11  0.00450000  ...  29819.58000000  29819.59000000  29819.65000000   \n",
      "12  0.00450000  ...  29814.55000000  29815.20000000  29815.44000000   \n",
      "13  0.00450000  ...  29814.55000000  29815.44000000  29816.05000000   \n",
      "14  0.00450000  ...  29814.55000000  29814.57000000  29814.59000000   \n",
      "15  0.00450000  ...  29814.55000000  29814.57000000  29815.44000000   \n",
      "16  0.00720000  ...  29814.55000000  29814.57000000  29814.94000000   \n",
      "17  0.00720000  ...  29814.55000000  29814.59000000  29814.94000000   \n",
      "18  0.00450000  ...  29808.51000000  29808.52000000  29808.53000000   \n",
      "\n",
      "               ap4             ap5         as1         as2         as3  \\\n",
      "0              NaN             NaN         NaN         NaN         NaN   \n",
      "1   29820.09000000  29820.11000000  1.92227000  0.02688000  0.02689000   \n",
      "2   29820.11000000  29820.20000000  2.48119000  0.02688000  0.00222000   \n",
      "3   29819.70000000  29819.75000000  3.90382000  0.03046000  0.00074000   \n",
      "4   29819.75000000  29820.00000000  1.98067000  0.00074000  0.00036000   \n",
      "5   29819.70000000  29820.00000000  1.90625000  0.01450000  0.00074000   \n",
      "6   29819.70000000  29820.00000000  1.90545000  0.01450000  0.00074000   \n",
      "7   29820.00000000  29820.09000000  1.88693000  0.00074000  0.00036000   \n",
      "8   29819.71000000  29819.99000000  2.15159000  0.00074000  0.00036000   \n",
      "9   29819.71000000  29819.99000000  2.15159000  0.00074000  0.00036000   \n",
      "10  29819.70000000  29819.71000000  3.66217000  0.14181000  0.00074000   \n",
      "11  29819.70000000  29819.71000000  3.79434000  0.14181000  0.00074000   \n",
      "12  29816.29000000  29816.30000000  2.06426000  0.01855000  0.25145000   \n",
      "13  29816.29000000  29816.30000000  6.65887000  0.25145000  0.00450000   \n",
      "14  29815.44000000  29815.70000000  5.98766000  0.01196000  0.01195000   \n",
      "15  29815.70000000  29816.05000000  5.98088000  0.01196000  0.25145000   \n",
      "16  29815.44000000  29815.70000000  5.38666000  0.01196000  0.05010000   \n",
      "17  29815.44000000  29815.70000000  5.28294000  0.00082000  0.05010000   \n",
      "18  29808.71000000  29809.49000000  2.62421000  0.69401000  0.54868000   \n",
      "\n",
      "           as4         as5  \n",
      "0          NaN         NaN  \n",
      "1   0.00222000  0.08000000  \n",
      "2   0.08000000  0.00108000  \n",
      "3   0.00036000  0.08293000  \n",
      "4   0.08293000  1.00447000  \n",
      "5   0.00036000  1.11033000  \n",
      "6   0.00036000  1.11033000  \n",
      "7   1.08021000  0.07605000  \n",
      "8   0.08293000  0.49787000  \n",
      "9   0.08293000  0.49787000  \n",
      "10  0.00036000  0.08293000  \n",
      "11  0.00036000  0.08293000  \n",
      "12  0.00067000  0.54868000  \n",
      "13  0.00067000  0.54868000  \n",
      "14  0.25145000  0.40300000  \n",
      "15  0.40300000  0.00450000  \n",
      "16  0.25139000  0.40300000  \n",
      "17  0.25139000  0.40300000  \n",
      "18  0.08293000  0.25144000  \n",
      "\n",
      "[19 rows x 21 columns]\n",
      "    last_update_id             bp1             bp2             bp3  \\\n",
      "0              NaN             NaN             NaN             NaN   \n",
      "1     1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "2     1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "3     1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "4     1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "5     1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "6     1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "7     1.950054e+10  29819.58000000  29819.57000000  29819.32000000   \n",
      "8     1.950054e+10  29819.58000000  29819.57000000  29819.10000000   \n",
      "9     1.950054e+10  29819.58000000  29819.57000000  29819.10000000   \n",
      "10    1.950054e+10  29819.57000000  29819.10000000  29818.14000000   \n",
      "11    1.950054e+10  29819.57000000  29819.10000000  29818.14000000   \n",
      "12    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "13    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "14    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "15    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "16    1.950054e+10  29814.54000000  29814.53000000  29814.48000000   \n",
      "17    1.950054e+10  29814.54000000  29814.53000000  29814.48000000   \n",
      "18    1.950054e+10  29808.50000000  29808.45000000  29808.38000000   \n",
      "19    1.950054e+10  29806.89000000  29806.70000000  29806.37000000   \n",
      "\n",
      "               bp4             bp5         bs1         bs2         bs3  \\\n",
      "0              NaN             NaN         NaN         NaN         NaN   \n",
      "1   29819.48000000  29819.39000000  0.60625000  0.24868000  0.23807000   \n",
      "2   29819.39000000  29819.32000000  0.68641000  0.24868000  0.23807000   \n",
      "3   29819.32000000  29819.10000000  0.30421000  0.23807000  0.00373000   \n",
      "4   29819.32000000  29819.10000000  0.91948000  0.23807000  0.00373000   \n",
      "5   29819.32000000  29819.10000000  0.39849000  0.23807000  0.01755000   \n",
      "6   29819.32000000  29819.10000000  0.40640000  0.23807000  0.01755000   \n",
      "7   29819.10000000  29816.96000000  0.55670000  0.23807000  0.00042000   \n",
      "8   29817.67000000  29816.77000000  0.17616000  0.23807000  0.01000000   \n",
      "9   29818.14000000  29817.67000000  0.34906000  0.23807000  0.01000000   \n",
      "10  29817.67000000  29816.76000000  0.40690000  0.01000000  0.00450000   \n",
      "11  29817.67000000  29816.76000000  0.40690000  0.01000000  0.00450000   \n",
      "12  29812.74000000  29810.94000000  0.36085000  0.01665000  0.00720000   \n",
      "13  29813.04000000  29811.17000000  0.22782000  0.01665000  0.00720000   \n",
      "14  29813.04000000  29811.17000000  0.21910000  0.01665000  0.00720000   \n",
      "15  29813.04000000  29811.17000000  0.11981000  0.01665000  0.00720000   \n",
      "16  29814.45000000  29813.04000000  0.16352000  0.00114000  0.01665000   \n",
      "17  29814.45000000  29814.33000000  0.34986000  0.00114000  0.01665000   \n",
      "18  29808.16000000  29808.02000000  0.24903000  0.00864000  0.01574000   \n",
      "19  29805.88000000  29805.69000000  0.93639000  0.00252000  0.00450000   \n",
      "\n",
      "           bs4  ...             ap1             ap2             ap3  \\\n",
      "0          NaN  ...             NaN             NaN             NaN   \n",
      "1   0.02032000  ...  29820.00000000  29820.02000000  29820.04000000   \n",
      "2   0.00373000  ...  29820.00000000  29820.02000000  29820.09000000   \n",
      "3   0.00545000  ...  29819.59000000  29819.64000000  29819.65000000   \n",
      "4   0.00042000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "5   0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "6   0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "7   0.01000000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "8   0.00450000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "9   0.00450000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "10  0.00450000  ...  29819.58000000  29819.59000000  29819.65000000   \n",
      "11  0.00450000  ...  29819.58000000  29819.59000000  29819.65000000   \n",
      "12  0.00450000  ...  29814.55000000  29815.20000000  29815.44000000   \n",
      "13  0.00450000  ...  29814.55000000  29815.44000000  29816.05000000   \n",
      "14  0.00450000  ...  29814.55000000  29814.57000000  29814.59000000   \n",
      "15  0.00450000  ...  29814.55000000  29814.57000000  29815.44000000   \n",
      "16  0.00720000  ...  29814.55000000  29814.57000000  29814.94000000   \n",
      "17  0.00720000  ...  29814.55000000  29814.59000000  29814.94000000   \n",
      "18  0.00450000  ...  29808.51000000  29808.52000000  29808.53000000   \n",
      "19  0.00450000  ...  29806.90000000  29807.59000000  29808.02000000   \n",
      "\n",
      "               ap4             ap5         as1         as2         as3  \\\n",
      "0              NaN             NaN         NaN         NaN         NaN   \n",
      "1   29820.09000000  29820.11000000  1.92227000  0.02688000  0.02689000   \n",
      "2   29820.11000000  29820.20000000  2.48119000  0.02688000  0.00222000   \n",
      "3   29819.70000000  29819.75000000  3.90382000  0.03046000  0.00074000   \n",
      "4   29819.75000000  29820.00000000  1.98067000  0.00074000  0.00036000   \n",
      "5   29819.70000000  29820.00000000  1.90625000  0.01450000  0.00074000   \n",
      "6   29819.70000000  29820.00000000  1.90545000  0.01450000  0.00074000   \n",
      "7   29820.00000000  29820.09000000  1.88693000  0.00074000  0.00036000   \n",
      "8   29819.71000000  29819.99000000  2.15159000  0.00074000  0.00036000   \n",
      "9   29819.71000000  29819.99000000  2.15159000  0.00074000  0.00036000   \n",
      "10  29819.70000000  29819.71000000  3.66217000  0.14181000  0.00074000   \n",
      "11  29819.70000000  29819.71000000  3.79434000  0.14181000  0.00074000   \n",
      "12  29816.29000000  29816.30000000  2.06426000  0.01855000  0.25145000   \n",
      "13  29816.29000000  29816.30000000  6.65887000  0.25145000  0.00450000   \n",
      "14  29815.44000000  29815.70000000  5.98766000  0.01196000  0.01195000   \n",
      "15  29815.70000000  29816.05000000  5.98088000  0.01196000  0.25145000   \n",
      "16  29815.44000000  29815.70000000  5.38666000  0.01196000  0.05010000   \n",
      "17  29815.44000000  29815.70000000  5.28294000  0.00082000  0.05010000   \n",
      "18  29808.71000000  29809.49000000  2.62421000  0.69401000  0.54868000   \n",
      "19  29808.11000000  29808.12000000  2.82728000  0.61108000  0.02004000   \n",
      "\n",
      "           as4         as5  \n",
      "0          NaN         NaN  \n",
      "1   0.00222000  0.08000000  \n",
      "2   0.08000000  0.00108000  \n",
      "3   0.00036000  0.08293000  \n",
      "4   0.08293000  1.00447000  \n",
      "5   0.00036000  1.11033000  \n",
      "6   0.00036000  1.11033000  \n",
      "7   1.08021000  0.07605000  \n",
      "8   0.08293000  0.49787000  \n",
      "9   0.08293000  0.49787000  \n",
      "10  0.00036000  0.08293000  \n",
      "11  0.00036000  0.08293000  \n",
      "12  0.00067000  0.54868000  \n",
      "13  0.00067000  0.54868000  \n",
      "14  0.25145000  0.40300000  \n",
      "15  0.40300000  0.00450000  \n",
      "16  0.25139000  0.40300000  \n",
      "17  0.25139000  0.40300000  \n",
      "18  0.08293000  0.25144000  \n",
      "19  0.40300000  0.00623000  \n",
      "\n",
      "[20 rows x 21 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/91/6wbfy1kd3c54vx64tq8sck_00000gn/T/ipykernel_6976/3022916258.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.df_0 = self.df_0.append(df, ignore_index = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    last_update_id             bp1             bp2             bp3  \\\n",
      "0              NaN             NaN             NaN             NaN   \n",
      "1     1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "2     1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "3     1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "4     1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "5     1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "6     1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "7     1.950054e+10  29819.58000000  29819.57000000  29819.32000000   \n",
      "8     1.950054e+10  29819.58000000  29819.57000000  29819.10000000   \n",
      "9     1.950054e+10  29819.58000000  29819.57000000  29819.10000000   \n",
      "10    1.950054e+10  29819.57000000  29819.10000000  29818.14000000   \n",
      "11    1.950054e+10  29819.57000000  29819.10000000  29818.14000000   \n",
      "12    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "13    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "14    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "15    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "16    1.950054e+10  29814.54000000  29814.53000000  29814.48000000   \n",
      "17    1.950054e+10  29814.54000000  29814.53000000  29814.48000000   \n",
      "18    1.950054e+10  29808.50000000  29808.45000000  29808.38000000   \n",
      "19    1.950054e+10  29806.89000000  29806.70000000  29806.37000000   \n",
      "\n",
      "               bp4             bp5         bs1         bs2         bs3  \\\n",
      "0              NaN             NaN         NaN         NaN         NaN   \n",
      "1   29819.48000000  29819.39000000  0.60625000  0.24868000  0.23807000   \n",
      "2   29819.39000000  29819.32000000  0.68641000  0.24868000  0.23807000   \n",
      "3   29819.32000000  29819.10000000  0.30421000  0.23807000  0.00373000   \n",
      "4   29819.32000000  29819.10000000  0.91948000  0.23807000  0.00373000   \n",
      "5   29819.32000000  29819.10000000  0.39849000  0.23807000  0.01755000   \n",
      "6   29819.32000000  29819.10000000  0.40640000  0.23807000  0.01755000   \n",
      "7   29819.10000000  29816.96000000  0.55670000  0.23807000  0.00042000   \n",
      "8   29817.67000000  29816.77000000  0.17616000  0.23807000  0.01000000   \n",
      "9   29818.14000000  29817.67000000  0.34906000  0.23807000  0.01000000   \n",
      "10  29817.67000000  29816.76000000  0.40690000  0.01000000  0.00450000   \n",
      "11  29817.67000000  29816.76000000  0.40690000  0.01000000  0.00450000   \n",
      "12  29812.74000000  29810.94000000  0.36085000  0.01665000  0.00720000   \n",
      "13  29813.04000000  29811.17000000  0.22782000  0.01665000  0.00720000   \n",
      "14  29813.04000000  29811.17000000  0.21910000  0.01665000  0.00720000   \n",
      "15  29813.04000000  29811.17000000  0.11981000  0.01665000  0.00720000   \n",
      "16  29814.45000000  29813.04000000  0.16352000  0.00114000  0.01665000   \n",
      "17  29814.45000000  29814.33000000  0.34986000  0.00114000  0.01665000   \n",
      "18  29808.16000000  29808.02000000  0.24903000  0.00864000  0.01574000   \n",
      "19  29805.88000000  29805.69000000  0.93639000  0.00252000  0.00450000   \n",
      "\n",
      "           bs4  ...             ap1             ap2             ap3  \\\n",
      "0          NaN  ...             NaN             NaN             NaN   \n",
      "1   0.02032000  ...  29820.00000000  29820.02000000  29820.04000000   \n",
      "2   0.00373000  ...  29820.00000000  29820.02000000  29820.09000000   \n",
      "3   0.00545000  ...  29819.59000000  29819.64000000  29819.65000000   \n",
      "4   0.00042000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "5   0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "6   0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "7   0.01000000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "8   0.00450000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "9   0.00450000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "10  0.00450000  ...  29819.58000000  29819.59000000  29819.65000000   \n",
      "11  0.00450000  ...  29819.58000000  29819.59000000  29819.65000000   \n",
      "12  0.00450000  ...  29814.55000000  29815.20000000  29815.44000000   \n",
      "13  0.00450000  ...  29814.55000000  29815.44000000  29816.05000000   \n",
      "14  0.00450000  ...  29814.55000000  29814.57000000  29814.59000000   \n",
      "15  0.00450000  ...  29814.55000000  29814.57000000  29815.44000000   \n",
      "16  0.00720000  ...  29814.55000000  29814.57000000  29814.94000000   \n",
      "17  0.00720000  ...  29814.55000000  29814.59000000  29814.94000000   \n",
      "18  0.00450000  ...  29808.51000000  29808.52000000  29808.53000000   \n",
      "19  0.00450000  ...  29806.90000000  29807.59000000  29808.02000000   \n",
      "\n",
      "               ap4             ap5         as1         as2         as3  \\\n",
      "0              NaN             NaN         NaN         NaN         NaN   \n",
      "1   29820.09000000  29820.11000000  1.92227000  0.02688000  0.02689000   \n",
      "2   29820.11000000  29820.20000000  2.48119000  0.02688000  0.00222000   \n",
      "3   29819.70000000  29819.75000000  3.90382000  0.03046000  0.00074000   \n",
      "4   29819.75000000  29820.00000000  1.98067000  0.00074000  0.00036000   \n",
      "5   29819.70000000  29820.00000000  1.90625000  0.01450000  0.00074000   \n",
      "6   29819.70000000  29820.00000000  1.90545000  0.01450000  0.00074000   \n",
      "7   29820.00000000  29820.09000000  1.88693000  0.00074000  0.00036000   \n",
      "8   29819.71000000  29819.99000000  2.15159000  0.00074000  0.00036000   \n",
      "9   29819.71000000  29819.99000000  2.15159000  0.00074000  0.00036000   \n",
      "10  29819.70000000  29819.71000000  3.66217000  0.14181000  0.00074000   \n",
      "11  29819.70000000  29819.71000000  3.79434000  0.14181000  0.00074000   \n",
      "12  29816.29000000  29816.30000000  2.06426000  0.01855000  0.25145000   \n",
      "13  29816.29000000  29816.30000000  6.65887000  0.25145000  0.00450000   \n",
      "14  29815.44000000  29815.70000000  5.98766000  0.01196000  0.01195000   \n",
      "15  29815.70000000  29816.05000000  5.98088000  0.01196000  0.25145000   \n",
      "16  29815.44000000  29815.70000000  5.38666000  0.01196000  0.05010000   \n",
      "17  29815.44000000  29815.70000000  5.28294000  0.00082000  0.05010000   \n",
      "18  29808.71000000  29809.49000000  2.62421000  0.69401000  0.54868000   \n",
      "19  29808.11000000  29808.12000000  2.82728000  0.61108000  0.02004000   \n",
      "\n",
      "           as4         as5  \n",
      "0          NaN         NaN  \n",
      "1   0.00222000  0.08000000  \n",
      "2   0.08000000  0.00108000  \n",
      "3   0.00036000  0.08293000  \n",
      "4   0.08293000  1.00447000  \n",
      "5   0.00036000  1.11033000  \n",
      "6   0.00036000  1.11033000  \n",
      "7   1.08021000  0.07605000  \n",
      "8   0.08293000  0.49787000  \n",
      "9   0.08293000  0.49787000  \n",
      "10  0.00036000  0.08293000  \n",
      "11  0.00036000  0.08293000  \n",
      "12  0.00067000  0.54868000  \n",
      "13  0.00067000  0.54868000  \n",
      "14  0.25145000  0.40300000  \n",
      "15  0.40300000  0.00450000  \n",
      "16  0.25139000  0.40300000  \n",
      "17  0.25139000  0.40300000  \n",
      "18  0.08293000  0.25144000  \n",
      "19  0.40300000  0.00623000  \n",
      "\n",
      "[20 rows x 21 columns]\n",
      "    last_update_id             bp1             bp2             bp3  \\\n",
      "0              NaN             NaN             NaN             NaN   \n",
      "1     1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "2     1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "3     1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "4     1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "5     1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "6     1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "7     1.950054e+10  29819.58000000  29819.57000000  29819.32000000   \n",
      "8     1.950054e+10  29819.58000000  29819.57000000  29819.10000000   \n",
      "9     1.950054e+10  29819.58000000  29819.57000000  29819.10000000   \n",
      "10    1.950054e+10  29819.57000000  29819.10000000  29818.14000000   \n",
      "11    1.950054e+10  29819.57000000  29819.10000000  29818.14000000   \n",
      "12    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "13    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "14    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "15    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "16    1.950054e+10  29814.54000000  29814.53000000  29814.48000000   \n",
      "17    1.950054e+10  29814.54000000  29814.53000000  29814.48000000   \n",
      "18    1.950054e+10  29808.50000000  29808.45000000  29808.38000000   \n",
      "19    1.950054e+10  29806.89000000  29806.70000000  29806.37000000   \n",
      "20    1.950054e+10  29804.77000000  29804.76000000  29804.70000000   \n",
      "\n",
      "               bp4             bp5         bs1         bs2         bs3  \\\n",
      "0              NaN             NaN         NaN         NaN         NaN   \n",
      "1   29819.48000000  29819.39000000  0.60625000  0.24868000  0.23807000   \n",
      "2   29819.39000000  29819.32000000  0.68641000  0.24868000  0.23807000   \n",
      "3   29819.32000000  29819.10000000  0.30421000  0.23807000  0.00373000   \n",
      "4   29819.32000000  29819.10000000  0.91948000  0.23807000  0.00373000   \n",
      "5   29819.32000000  29819.10000000  0.39849000  0.23807000  0.01755000   \n",
      "6   29819.32000000  29819.10000000  0.40640000  0.23807000  0.01755000   \n",
      "7   29819.10000000  29816.96000000  0.55670000  0.23807000  0.00042000   \n",
      "8   29817.67000000  29816.77000000  0.17616000  0.23807000  0.01000000   \n",
      "9   29818.14000000  29817.67000000  0.34906000  0.23807000  0.01000000   \n",
      "10  29817.67000000  29816.76000000  0.40690000  0.01000000  0.00450000   \n",
      "11  29817.67000000  29816.76000000  0.40690000  0.01000000  0.00450000   \n",
      "12  29812.74000000  29810.94000000  0.36085000  0.01665000  0.00720000   \n",
      "13  29813.04000000  29811.17000000  0.22782000  0.01665000  0.00720000   \n",
      "14  29813.04000000  29811.17000000  0.21910000  0.01665000  0.00720000   \n",
      "15  29813.04000000  29811.17000000  0.11981000  0.01665000  0.00720000   \n",
      "16  29814.45000000  29813.04000000  0.16352000  0.00114000  0.01665000   \n",
      "17  29814.45000000  29814.33000000  0.34986000  0.00114000  0.01665000   \n",
      "18  29808.16000000  29808.02000000  0.24903000  0.00864000  0.01574000   \n",
      "19  29805.88000000  29805.69000000  0.93639000  0.00252000  0.00450000   \n",
      "20  29804.69000000  29804.24000000  0.40477000  0.00134000  0.00288000   \n",
      "\n",
      "           bs4  ...             ap1             ap2             ap3  \\\n",
      "0          NaN  ...             NaN             NaN             NaN   \n",
      "1   0.02032000  ...  29820.00000000  29820.02000000  29820.04000000   \n",
      "2   0.00373000  ...  29820.00000000  29820.02000000  29820.09000000   \n",
      "3   0.00545000  ...  29819.59000000  29819.64000000  29819.65000000   \n",
      "4   0.00042000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "5   0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "6   0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "7   0.01000000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "8   0.00450000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "9   0.00450000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "10  0.00450000  ...  29819.58000000  29819.59000000  29819.65000000   \n",
      "11  0.00450000  ...  29819.58000000  29819.59000000  29819.65000000   \n",
      "12  0.00450000  ...  29814.55000000  29815.20000000  29815.44000000   \n",
      "13  0.00450000  ...  29814.55000000  29815.44000000  29816.05000000   \n",
      "14  0.00450000  ...  29814.55000000  29814.57000000  29814.59000000   \n",
      "15  0.00450000  ...  29814.55000000  29814.57000000  29815.44000000   \n",
      "16  0.00720000  ...  29814.55000000  29814.57000000  29814.94000000   \n",
      "17  0.00720000  ...  29814.55000000  29814.59000000  29814.94000000   \n",
      "18  0.00450000  ...  29808.51000000  29808.52000000  29808.53000000   \n",
      "19  0.00450000  ...  29806.90000000  29807.59000000  29808.02000000   \n",
      "20  0.00740000  ...  29804.78000000  29804.93000000  29805.46000000   \n",
      "\n",
      "               ap4             ap5         as1         as2         as3  \\\n",
      "0              NaN             NaN         NaN         NaN         NaN   \n",
      "1   29820.09000000  29820.11000000  1.92227000  0.02688000  0.02689000   \n",
      "2   29820.11000000  29820.20000000  2.48119000  0.02688000  0.00222000   \n",
      "3   29819.70000000  29819.75000000  3.90382000  0.03046000  0.00074000   \n",
      "4   29819.75000000  29820.00000000  1.98067000  0.00074000  0.00036000   \n",
      "5   29819.70000000  29820.00000000  1.90625000  0.01450000  0.00074000   \n",
      "6   29819.70000000  29820.00000000  1.90545000  0.01450000  0.00074000   \n",
      "7   29820.00000000  29820.09000000  1.88693000  0.00074000  0.00036000   \n",
      "8   29819.71000000  29819.99000000  2.15159000  0.00074000  0.00036000   \n",
      "9   29819.71000000  29819.99000000  2.15159000  0.00074000  0.00036000   \n",
      "10  29819.70000000  29819.71000000  3.66217000  0.14181000  0.00074000   \n",
      "11  29819.70000000  29819.71000000  3.79434000  0.14181000  0.00074000   \n",
      "12  29816.29000000  29816.30000000  2.06426000  0.01855000  0.25145000   \n",
      "13  29816.29000000  29816.30000000  6.65887000  0.25145000  0.00450000   \n",
      "14  29815.44000000  29815.70000000  5.98766000  0.01196000  0.01195000   \n",
      "15  29815.70000000  29816.05000000  5.98088000  0.01196000  0.25145000   \n",
      "16  29815.44000000  29815.70000000  5.38666000  0.01196000  0.05010000   \n",
      "17  29815.44000000  29815.70000000  5.28294000  0.00082000  0.05010000   \n",
      "18  29808.71000000  29809.49000000  2.62421000  0.69401000  0.54868000   \n",
      "19  29808.11000000  29808.12000000  2.82728000  0.61108000  0.02004000   \n",
      "20  29805.67000000  29805.70000000  2.08961000  0.01772000  0.02004000   \n",
      "\n",
      "           as4         as5  \n",
      "0          NaN         NaN  \n",
      "1   0.00222000  0.08000000  \n",
      "2   0.08000000  0.00108000  \n",
      "3   0.00036000  0.08293000  \n",
      "4   0.08293000  1.00447000  \n",
      "5   0.00036000  1.11033000  \n",
      "6   0.00036000  1.11033000  \n",
      "7   1.08021000  0.07605000  \n",
      "8   0.08293000  0.49787000  \n",
      "9   0.08293000  0.49787000  \n",
      "10  0.00036000  0.08293000  \n",
      "11  0.00036000  0.08293000  \n",
      "12  0.00067000  0.54868000  \n",
      "13  0.00067000  0.54868000  \n",
      "14  0.25145000  0.40300000  \n",
      "15  0.40300000  0.00450000  \n",
      "16  0.25139000  0.40300000  \n",
      "17  0.25139000  0.40300000  \n",
      "18  0.08293000  0.25144000  \n",
      "19  0.40300000  0.00623000  \n",
      "20  0.25147000  0.30000000  \n",
      "\n",
      "[21 rows x 21 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/91/6wbfy1kd3c54vx64tq8sck_00000gn/T/ipykernel_6976/3022916258.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.df_0 = self.df_0.append(df, ignore_index = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    last_update_id             bp1             bp2             bp3  \\\n",
      "0              NaN             NaN             NaN             NaN   \n",
      "1     1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "2     1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "3     1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "4     1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "5     1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "6     1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "7     1.950054e+10  29819.58000000  29819.57000000  29819.32000000   \n",
      "8     1.950054e+10  29819.58000000  29819.57000000  29819.10000000   \n",
      "9     1.950054e+10  29819.58000000  29819.57000000  29819.10000000   \n",
      "10    1.950054e+10  29819.57000000  29819.10000000  29818.14000000   \n",
      "11    1.950054e+10  29819.57000000  29819.10000000  29818.14000000   \n",
      "12    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "13    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "14    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "15    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "16    1.950054e+10  29814.54000000  29814.53000000  29814.48000000   \n",
      "17    1.950054e+10  29814.54000000  29814.53000000  29814.48000000   \n",
      "18    1.950054e+10  29808.50000000  29808.45000000  29808.38000000   \n",
      "19    1.950054e+10  29806.89000000  29806.70000000  29806.37000000   \n",
      "20    1.950054e+10  29804.77000000  29804.76000000  29804.70000000   \n",
      "\n",
      "               bp4             bp5         bs1         bs2         bs3  \\\n",
      "0              NaN             NaN         NaN         NaN         NaN   \n",
      "1   29819.48000000  29819.39000000  0.60625000  0.24868000  0.23807000   \n",
      "2   29819.39000000  29819.32000000  0.68641000  0.24868000  0.23807000   \n",
      "3   29819.32000000  29819.10000000  0.30421000  0.23807000  0.00373000   \n",
      "4   29819.32000000  29819.10000000  0.91948000  0.23807000  0.00373000   \n",
      "5   29819.32000000  29819.10000000  0.39849000  0.23807000  0.01755000   \n",
      "6   29819.32000000  29819.10000000  0.40640000  0.23807000  0.01755000   \n",
      "7   29819.10000000  29816.96000000  0.55670000  0.23807000  0.00042000   \n",
      "8   29817.67000000  29816.77000000  0.17616000  0.23807000  0.01000000   \n",
      "9   29818.14000000  29817.67000000  0.34906000  0.23807000  0.01000000   \n",
      "10  29817.67000000  29816.76000000  0.40690000  0.01000000  0.00450000   \n",
      "11  29817.67000000  29816.76000000  0.40690000  0.01000000  0.00450000   \n",
      "12  29812.74000000  29810.94000000  0.36085000  0.01665000  0.00720000   \n",
      "13  29813.04000000  29811.17000000  0.22782000  0.01665000  0.00720000   \n",
      "14  29813.04000000  29811.17000000  0.21910000  0.01665000  0.00720000   \n",
      "15  29813.04000000  29811.17000000  0.11981000  0.01665000  0.00720000   \n",
      "16  29814.45000000  29813.04000000  0.16352000  0.00114000  0.01665000   \n",
      "17  29814.45000000  29814.33000000  0.34986000  0.00114000  0.01665000   \n",
      "18  29808.16000000  29808.02000000  0.24903000  0.00864000  0.01574000   \n",
      "19  29805.88000000  29805.69000000  0.93639000  0.00252000  0.00450000   \n",
      "20  29804.69000000  29804.24000000  0.40477000  0.00134000  0.00288000   \n",
      "\n",
      "           bs4  ...             ap1             ap2             ap3  \\\n",
      "0          NaN  ...             NaN             NaN             NaN   \n",
      "1   0.02032000  ...  29820.00000000  29820.02000000  29820.04000000   \n",
      "2   0.00373000  ...  29820.00000000  29820.02000000  29820.09000000   \n",
      "3   0.00545000  ...  29819.59000000  29819.64000000  29819.65000000   \n",
      "4   0.00042000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "5   0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "6   0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "7   0.01000000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "8   0.00450000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "9   0.00450000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "10  0.00450000  ...  29819.58000000  29819.59000000  29819.65000000   \n",
      "11  0.00450000  ...  29819.58000000  29819.59000000  29819.65000000   \n",
      "12  0.00450000  ...  29814.55000000  29815.20000000  29815.44000000   \n",
      "13  0.00450000  ...  29814.55000000  29815.44000000  29816.05000000   \n",
      "14  0.00450000  ...  29814.55000000  29814.57000000  29814.59000000   \n",
      "15  0.00450000  ...  29814.55000000  29814.57000000  29815.44000000   \n",
      "16  0.00720000  ...  29814.55000000  29814.57000000  29814.94000000   \n",
      "17  0.00720000  ...  29814.55000000  29814.59000000  29814.94000000   \n",
      "18  0.00450000  ...  29808.51000000  29808.52000000  29808.53000000   \n",
      "19  0.00450000  ...  29806.90000000  29807.59000000  29808.02000000   \n",
      "20  0.00740000  ...  29804.78000000  29804.93000000  29805.46000000   \n",
      "\n",
      "               ap4             ap5         as1         as2         as3  \\\n",
      "0              NaN             NaN         NaN         NaN         NaN   \n",
      "1   29820.09000000  29820.11000000  1.92227000  0.02688000  0.02689000   \n",
      "2   29820.11000000  29820.20000000  2.48119000  0.02688000  0.00222000   \n",
      "3   29819.70000000  29819.75000000  3.90382000  0.03046000  0.00074000   \n",
      "4   29819.75000000  29820.00000000  1.98067000  0.00074000  0.00036000   \n",
      "5   29819.70000000  29820.00000000  1.90625000  0.01450000  0.00074000   \n",
      "6   29819.70000000  29820.00000000  1.90545000  0.01450000  0.00074000   \n",
      "7   29820.00000000  29820.09000000  1.88693000  0.00074000  0.00036000   \n",
      "8   29819.71000000  29819.99000000  2.15159000  0.00074000  0.00036000   \n",
      "9   29819.71000000  29819.99000000  2.15159000  0.00074000  0.00036000   \n",
      "10  29819.70000000  29819.71000000  3.66217000  0.14181000  0.00074000   \n",
      "11  29819.70000000  29819.71000000  3.79434000  0.14181000  0.00074000   \n",
      "12  29816.29000000  29816.30000000  2.06426000  0.01855000  0.25145000   \n",
      "13  29816.29000000  29816.30000000  6.65887000  0.25145000  0.00450000   \n",
      "14  29815.44000000  29815.70000000  5.98766000  0.01196000  0.01195000   \n",
      "15  29815.70000000  29816.05000000  5.98088000  0.01196000  0.25145000   \n",
      "16  29815.44000000  29815.70000000  5.38666000  0.01196000  0.05010000   \n",
      "17  29815.44000000  29815.70000000  5.28294000  0.00082000  0.05010000   \n",
      "18  29808.71000000  29809.49000000  2.62421000  0.69401000  0.54868000   \n",
      "19  29808.11000000  29808.12000000  2.82728000  0.61108000  0.02004000   \n",
      "20  29805.67000000  29805.70000000  2.08961000  0.01772000  0.02004000   \n",
      "\n",
      "           as4         as5  \n",
      "0          NaN         NaN  \n",
      "1   0.00222000  0.08000000  \n",
      "2   0.08000000  0.00108000  \n",
      "3   0.00036000  0.08293000  \n",
      "4   0.08293000  1.00447000  \n",
      "5   0.00036000  1.11033000  \n",
      "6   0.00036000  1.11033000  \n",
      "7   1.08021000  0.07605000  \n",
      "8   0.08293000  0.49787000  \n",
      "9   0.08293000  0.49787000  \n",
      "10  0.00036000  0.08293000  \n",
      "11  0.00036000  0.08293000  \n",
      "12  0.00067000  0.54868000  \n",
      "13  0.00067000  0.54868000  \n",
      "14  0.25145000  0.40300000  \n",
      "15  0.40300000  0.00450000  \n",
      "16  0.25139000  0.40300000  \n",
      "17  0.25139000  0.40300000  \n",
      "18  0.08293000  0.25144000  \n",
      "19  0.40300000  0.00623000  \n",
      "20  0.25147000  0.30000000  \n",
      "\n",
      "[21 rows x 21 columns]\n",
      "    last_update_id             bp1             bp2             bp3  \\\n",
      "0              NaN             NaN             NaN             NaN   \n",
      "1     1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "2     1.950054e+10  29819.99000000  29819.89000000  29819.57000000   \n",
      "3     1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "4     1.950054e+10  29819.58000000  29819.57000000  29819.39000000   \n",
      "5     1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "6     1.950054e+10  29819.58000000  29819.57000000  29819.56000000   \n",
      "7     1.950054e+10  29819.58000000  29819.57000000  29819.32000000   \n",
      "8     1.950054e+10  29819.58000000  29819.57000000  29819.10000000   \n",
      "9     1.950054e+10  29819.58000000  29819.57000000  29819.10000000   \n",
      "10    1.950054e+10  29819.57000000  29819.10000000  29818.14000000   \n",
      "11    1.950054e+10  29819.57000000  29819.10000000  29818.14000000   \n",
      "12    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "13    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "14    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "15    1.950054e+10  29814.54000000  29814.48000000  29814.45000000   \n",
      "16    1.950054e+10  29814.54000000  29814.53000000  29814.48000000   \n",
      "17    1.950054e+10  29814.54000000  29814.53000000  29814.48000000   \n",
      "18    1.950054e+10  29808.50000000  29808.45000000  29808.38000000   \n",
      "19    1.950054e+10  29806.89000000  29806.70000000  29806.37000000   \n",
      "20    1.950054e+10  29804.77000000  29804.76000000  29804.70000000   \n",
      "21    1.950054e+10  29804.77000000  29804.76000000  29804.70000000   \n",
      "\n",
      "               bp4             bp5         bs1         bs2         bs3  \\\n",
      "0              NaN             NaN         NaN         NaN         NaN   \n",
      "1   29819.48000000  29819.39000000  0.60625000  0.24868000  0.23807000   \n",
      "2   29819.39000000  29819.32000000  0.68641000  0.24868000  0.23807000   \n",
      "3   29819.32000000  29819.10000000  0.30421000  0.23807000  0.00373000   \n",
      "4   29819.32000000  29819.10000000  0.91948000  0.23807000  0.00373000   \n",
      "5   29819.32000000  29819.10000000  0.39849000  0.23807000  0.01755000   \n",
      "6   29819.32000000  29819.10000000  0.40640000  0.23807000  0.01755000   \n",
      "7   29819.10000000  29816.96000000  0.55670000  0.23807000  0.00042000   \n",
      "8   29817.67000000  29816.77000000  0.17616000  0.23807000  0.01000000   \n",
      "9   29818.14000000  29817.67000000  0.34906000  0.23807000  0.01000000   \n",
      "10  29817.67000000  29816.76000000  0.40690000  0.01000000  0.00450000   \n",
      "11  29817.67000000  29816.76000000  0.40690000  0.01000000  0.00450000   \n",
      "12  29812.74000000  29810.94000000  0.36085000  0.01665000  0.00720000   \n",
      "13  29813.04000000  29811.17000000  0.22782000  0.01665000  0.00720000   \n",
      "14  29813.04000000  29811.17000000  0.21910000  0.01665000  0.00720000   \n",
      "15  29813.04000000  29811.17000000  0.11981000  0.01665000  0.00720000   \n",
      "16  29814.45000000  29813.04000000  0.16352000  0.00114000  0.01665000   \n",
      "17  29814.45000000  29814.33000000  0.34986000  0.00114000  0.01665000   \n",
      "18  29808.16000000  29808.02000000  0.24903000  0.00864000  0.01574000   \n",
      "19  29805.88000000  29805.69000000  0.93639000  0.00252000  0.00450000   \n",
      "20  29804.69000000  29804.24000000  0.40477000  0.00134000  0.00288000   \n",
      "21  29804.69000000  29804.24000000  0.21269000  0.00134000  0.00288000   \n",
      "\n",
      "           bs4  ...             ap1             ap2             ap3  \\\n",
      "0          NaN  ...             NaN             NaN             NaN   \n",
      "1   0.02032000  ...  29820.00000000  29820.02000000  29820.04000000   \n",
      "2   0.00373000  ...  29820.00000000  29820.02000000  29820.09000000   \n",
      "3   0.00545000  ...  29819.59000000  29819.64000000  29819.65000000   \n",
      "4   0.00042000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "5   0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "6   0.00042000  ...  29819.59000000  29819.61000000  29819.65000000   \n",
      "7   0.01000000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "8   0.00450000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "9   0.00450000  ...  29819.59000000  29819.65000000  29819.70000000   \n",
      "10  0.00450000  ...  29819.58000000  29819.59000000  29819.65000000   \n",
      "11  0.00450000  ...  29819.58000000  29819.59000000  29819.65000000   \n",
      "12  0.00450000  ...  29814.55000000  29815.20000000  29815.44000000   \n",
      "13  0.00450000  ...  29814.55000000  29815.44000000  29816.05000000   \n",
      "14  0.00450000  ...  29814.55000000  29814.57000000  29814.59000000   \n",
      "15  0.00450000  ...  29814.55000000  29814.57000000  29815.44000000   \n",
      "16  0.00720000  ...  29814.55000000  29814.57000000  29814.94000000   \n",
      "17  0.00720000  ...  29814.55000000  29814.59000000  29814.94000000   \n",
      "18  0.00450000  ...  29808.51000000  29808.52000000  29808.53000000   \n",
      "19  0.00450000  ...  29806.90000000  29807.59000000  29808.02000000   \n",
      "20  0.00740000  ...  29804.78000000  29804.93000000  29805.46000000   \n",
      "21  0.00740000  ...  29804.78000000  29804.82000000  29804.93000000   \n",
      "\n",
      "               ap4             ap5         as1         as2         as3  \\\n",
      "0              NaN             NaN         NaN         NaN         NaN   \n",
      "1   29820.09000000  29820.11000000  1.92227000  0.02688000  0.02689000   \n",
      "2   29820.11000000  29820.20000000  2.48119000  0.02688000  0.00222000   \n",
      "3   29819.70000000  29819.75000000  3.90382000  0.03046000  0.00074000   \n",
      "4   29819.75000000  29820.00000000  1.98067000  0.00074000  0.00036000   \n",
      "5   29819.70000000  29820.00000000  1.90625000  0.01450000  0.00074000   \n",
      "6   29819.70000000  29820.00000000  1.90545000  0.01450000  0.00074000   \n",
      "7   29820.00000000  29820.09000000  1.88693000  0.00074000  0.00036000   \n",
      "8   29819.71000000  29819.99000000  2.15159000  0.00074000  0.00036000   \n",
      "9   29819.71000000  29819.99000000  2.15159000  0.00074000  0.00036000   \n",
      "10  29819.70000000  29819.71000000  3.66217000  0.14181000  0.00074000   \n",
      "11  29819.70000000  29819.71000000  3.79434000  0.14181000  0.00074000   \n",
      "12  29816.29000000  29816.30000000  2.06426000  0.01855000  0.25145000   \n",
      "13  29816.29000000  29816.30000000  6.65887000  0.25145000  0.00450000   \n",
      "14  29815.44000000  29815.70000000  5.98766000  0.01196000  0.01195000   \n",
      "15  29815.70000000  29816.05000000  5.98088000  0.01196000  0.25145000   \n",
      "16  29815.44000000  29815.70000000  5.38666000  0.01196000  0.05010000   \n",
      "17  29815.44000000  29815.70000000  5.28294000  0.00082000  0.05010000   \n",
      "18  29808.71000000  29809.49000000  2.62421000  0.69401000  0.54868000   \n",
      "19  29808.11000000  29808.12000000  2.82728000  0.61108000  0.02004000   \n",
      "20  29805.67000000  29805.70000000  2.08961000  0.01772000  0.02004000   \n",
      "21  29805.25000000  29805.67000000  2.65248000  0.00337000  0.01772000   \n",
      "\n",
      "           as4         as5  \n",
      "0          NaN         NaN  \n",
      "1   0.00222000  0.08000000  \n",
      "2   0.08000000  0.00108000  \n",
      "3   0.00036000  0.08293000  \n",
      "4   0.08293000  1.00447000  \n",
      "5   0.00036000  1.11033000  \n",
      "6   0.00036000  1.11033000  \n",
      "7   1.08021000  0.07605000  \n",
      "8   0.08293000  0.49787000  \n",
      "9   0.08293000  0.49787000  \n",
      "10  0.00036000  0.08293000  \n",
      "11  0.00036000  0.08293000  \n",
      "12  0.00067000  0.54868000  \n",
      "13  0.00067000  0.54868000  \n",
      "14  0.25145000  0.40300000  \n",
      "15  0.40300000  0.00450000  \n",
      "16  0.25139000  0.40300000  \n",
      "17  0.25139000  0.40300000  \n",
      "18  0.08293000  0.25144000  \n",
      "19  0.40300000  0.00623000  \n",
      "20  0.25147000  0.30000000  \n",
      "21  0.05000000  0.25143000  \n",
      "\n",
      "[22 rows x 21 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/91/6wbfy1kd3c54vx64tq8sck_00000gn/T/ipykernel_6976/3022916258.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.df_0 = self.df_0.append(df, ignore_index = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_0 = pd.DataFrame.from_dict(my_json_0(5))\n",
    "w = StreamingData(df_0)\n",
    "w.start()\n",
    "\n",
    "w.my_return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local variable 'df_0' referenced before assignment\n",
      "local variable 'df_0' referenced before assignment\n",
      "local variable 'df_0' referenced before assignment\n",
      "local variable 'df_0' referenced before assignment\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ws_trades(df_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nikhil': 1, 'akash': 7, 'manjeet': 10, 'akshat': 5, 'm': 15}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  \n",
    "# initialising dictionaries\n",
    "ini_dictionary1 = {'nikhil': 1, 'akash' : 5,\n",
    "                     'manjeet' : 10, 'akshat' : 15}\n",
    "ini_dictionary2 = {'akash' : 7, 'akshat' : 5,\n",
    "                                          'm' : 15}\n",
    "\n",
    "ini_dictionary1.update(ini_dictionary2)\n",
    "ini_dictionary1  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bp0': '29724.70000000',\n",
       " 'bp1': '29747.650000',\n",
       " 'bp2': '29724.62000000',\n",
       " 'bp3': '29724.61000000',\n",
       " 'bp4': '29724.57000000'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_message ={'lastUpdateId': 19493390097, \n",
    "               'bids': [['29724.70000000', '8.90412000'], ['29747.650000', '0.00429000'], ['29724.62000000', '0.08293000'], ['29724.61000000', '0.01998000'], ['29724.57000000', '0.16835000']], \n",
    "               'asks': [['29724.71000000', '0.00001000'], ['29724.72000000', '0.00075000'], ['29724.73000000', '0.01237000'], ['29724.75000000', '0.01237000'], ['29724.77000000', '0.01000000']]}\n",
    "\n",
    "\n",
    "{'bp'+str(key):value for key,value in zip(np.arange(0,5),np.array(json_message['bids'])[:,0]) }\n",
    "{'bs'+str(key):value for key,value in zip(np.arange(0,5),np.array(json_message['bids'])[:,1]) }\n",
    "{'bp'+str(key):value for key,value in zip(np.arange(0,5),np.array(json_message['bids'])[:,0]) }\n",
    "{'bp'+str(key):value for key,value in zip(np.arange(0,5),np.array(json_message['bids'])[:,0]) }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_message ={'lastUpdateId': 19493390097, \n",
    "               'bids': [['29724.70000000', '8.90412000'], ['nan', '0.00429000'], ['29724.62000000', '0.08293000'], ['29724.61000000', '0.01998000'], ['29724.57000000', '0.16835000']], \n",
    "               'asks': [['29724.71000000', '0.00001000'], ['29724.72000000', '0.00075000'], ['29724.73000000', '0.01237000'], ['29724.75000000', '0.01237000'], ['29724.77000000', '0.01000000']]}\n",
    "aaa(bp1) bid price 1 = 29724.70000000\n",
    "(bs1) bid size 1 = 8.90412000\n",
    "\n",
    "(ap1) asd price 1 = 29724.71000000\n",
    "(as1) ask size 1 = 0000100\n",
    "\n",
    "{'ts':json_message['lastUpdateId'],\n",
    "  'bp1':json_message['bids'][0][0],\n",
    "  'bp1':json_message['bids'][0][0],\n",
    "  'bp1':json_message['bids'][0][0],\n",
    "  'bp1':json_message['bids'][0][0],\n",
    "  'bp1':json_message['bids'][0][0],\n",
    "  'bp1':json_message['bids'][0][0],\n",
    "  'bp1':json_message['bids'][0][0],\n",
    "  'bp1':json_message['bids'][0][0],\n",
    "  'bp1':json_message['bids'][0][0],\n",
    "  'bp1':json_message['bids'][0][0],  \n",
    "  'bp1':json_message['bids'][0][0],\n",
    "  }\n",
    "\n",
    "symbol,ts,last_update_id,bp1,bs1,bp2,bs2,bp3,bs3,bp4,bs4,bp5,bs5,bp6,bs6,bp7,bs7,bp8,bs8,bp9,bs9,bp10,bs10,bp11,bs11,bp12,bs12,bp13,bs13,bp14,bs14,bp15,bs15,bp16,bs16,bp17,bs17,bp18,bs18,bp19,bs19,bp20,bs20,ap1,as1,ap2,as2,ap3,as3,ap4,as4,ap5,as5,ap6,as6,ap7,as7,ap8,as8,ap9,as9,ap10,as10,ap11,as11,ap12,as12,ap13,as13,ap14,as14,ap15,as15,ap16,as16,ap17,as17,ap18,as18,ap19,as19,ap20,as20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.streaming import StreamingContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment the next line to run the code block on jupyter. Keep it commented if copy-pasting into the pyspark shell\n",
    "sc = pyspark.SparkContext()\n",
    "\n",
    "# This tells Spark Streaming to bacth-up the contents of a data stream and \"ingest\" them every 10 seconds.\n",
    "ssc = StreamingContext(sc,10)\n",
    "\n",
    "# Tell spark to listen on port 9999 of our localhost.\n",
    "lines = ssc.socketTextStream('wss://stream.binance.com/ws/BTCUSDT@depth5', 9443)\n",
    "lines = ssc.socketTextStream('localhost', 9999)    \n",
    "\n",
    "words = lines.flatMap(lambda line : line.split(\" \"))\n",
    "\n",
    "pairs = words.map(lambda word: (word, 1))\n",
    "wordCount = pairs.reduceByKey(lambda a, b: a + b)\n",
    "\n",
    "wordCount.pprint()\n",
    "\n",
    "ssc.start()\n",
    "ssc.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/25 13:09:12 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:12 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:12 ERROR Executor: Exception in task 0.0 in stage 0.0 (TID 0)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:12 WARN TaskSetManager: Lost task 0.0 in stage 0.0 (TID 0) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:12 ERROR TaskSetManager: Task 0 in stage 0.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:12 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:12 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:12 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:12 ERROR Executor: Exception in task 0.0 in stage 1.0 (TID 1)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:12 WARN TaskSetManager: Lost task 0.0 in stage 1.0 (TID 1) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:12 ERROR TaskSetManager: Task 0 in stage 1.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:12 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1.0 (TID 1) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:12 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:13 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:13 ERROR Executor: Exception in task 0.0 in stage 2.0 (TID 2)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:13 WARN TaskSetManager: Lost task 0.0 in stage 2.0 (TID 2) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:13 ERROR TaskSetManager: Task 0 in stage 2.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:13 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 2.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2.0 (TID 2) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:13 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:13 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:13 ERROR Executor: Exception in task 0.0 in stage 3.0 (TID 3)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:13 WARN TaskSetManager: Lost task 0.0 in stage 3.0 (TID 3) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:13 ERROR TaskSetManager: Task 0 in stage 3.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:13 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 3.0 failed 1 times, most recent failure: Lost task 0.0 in stage 3.0 (TID 3) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:13 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:14 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:14 ERROR Executor: Exception in task 0.0 in stage 4.0 (TID 4)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:14 WARN TaskSetManager: Lost task 0.0 in stage 4.0 (TID 4) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:14 ERROR TaskSetManager: Task 0 in stage 4.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:14 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 4.0 failed 1 times, most recent failure: Lost task 0.0 in stage 4.0 (TID 4) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:14 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:14 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:14 ERROR Executor: Exception in task 0.0 in stage 5.0 (TID 5)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:14 WARN TaskSetManager: Lost task 0.0 in stage 5.0 (TID 5) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:14 ERROR TaskSetManager: Task 0 in stage 5.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:14 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 5.0 failed 1 times, most recent failure: Lost task 0.0 in stage 5.0 (TID 5) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:14 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:14 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:14 ERROR Executor: Exception in task 0.0 in stage 6.0 (TID 6)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:14 WARN TaskSetManager: Lost task 0.0 in stage 6.0 (TID 6) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:14 ERROR TaskSetManager: Task 0 in stage 6.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:14 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 6.0 failed 1 times, most recent failure: Lost task 0.0 in stage 6.0 (TID 6) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:14 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:15 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:15 ERROR Executor: Exception in task 0.0 in stage 7.0 (TID 7)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:15 WARN TaskSetManager: Lost task 0.0 in stage 7.0 (TID 7) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:15 ERROR TaskSetManager: Task 0 in stage 7.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:15 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 7.0 failed 1 times, most recent failure: Lost task 0.0 in stage 7.0 (TID 7) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:15 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:15 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:15 ERROR Executor: Exception in task 0.0 in stage 8.0 (TID 8)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:15 WARN TaskSetManager: Lost task 0.0 in stage 8.0 (TID 8) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:15 ERROR TaskSetManager: Task 0 in stage 8.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:15 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 8.0 failed 1 times, most recent failure: Lost task 0.0 in stage 8.0 (TID 8) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:15 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:16 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:16 ERROR Executor: Exception in task 0.0 in stage 9.0 (TID 9)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:16 WARN TaskSetManager: Lost task 0.0 in stage 9.0 (TID 9) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:16 ERROR TaskSetManager: Task 0 in stage 9.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:16 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 9.0 failed 1 times, most recent failure: Lost task 0.0 in stage 9.0 (TID 9) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:16 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:16 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:16 ERROR Executor: Exception in task 0.0 in stage 10.0 (TID 10)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:16 WARN TaskSetManager: Lost task 0.0 in stage 10.0 (TID 10) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:16 ERROR TaskSetManager: Task 0 in stage 10.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:16 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 10.0 failed 1 times, most recent failure: Lost task 0.0 in stage 10.0 (TID 10) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:16 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:16 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:16 ERROR Executor: Exception in task 0.0 in stage 11.0 (TID 11)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:16 WARN TaskSetManager: Lost task 0.0 in stage 11.0 (TID 11) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:16 ERROR TaskSetManager: Task 0 in stage 11.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:16 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 11.0 failed 1 times, most recent failure: Lost task 0.0 in stage 11.0 (TID 11) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:16 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:17 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:17 ERROR Executor: Exception in task 0.0 in stage 12.0 (TID 12)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:17 WARN TaskSetManager: Lost task 0.0 in stage 12.0 (TID 12) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:17 ERROR TaskSetManager: Task 0 in stage 12.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:17 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 12.0 failed 1 times, most recent failure: Lost task 0.0 in stage 12.0 (TID 12) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:17 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:17 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:17 ERROR Executor: Exception in task 0.0 in stage 13.0 (TID 13)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:17 WARN TaskSetManager: Lost task 0.0 in stage 13.0 (TID 13) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:17 ERROR TaskSetManager: Task 0 in stage 13.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:17 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 13.0 failed 1 times, most recent failure: Lost task 0.0 in stage 13.0 (TID 13) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:17 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:18 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:18 ERROR Executor: Exception in task 0.0 in stage 14.0 (TID 14)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:18 WARN TaskSetManager: Lost task 0.0 in stage 14.0 (TID 14) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:18 ERROR TaskSetManager: Task 0 in stage 14.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:18 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 14.0 failed 1 times, most recent failure: Lost task 0.0 in stage 14.0 (TID 14) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:18 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:18 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:18 ERROR Executor: Exception in task 0.0 in stage 15.0 (TID 15)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:18 WARN TaskSetManager: Lost task 0.0 in stage 15.0 (TID 15) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:18 ERROR TaskSetManager: Task 0 in stage 15.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:18 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 15.0 failed 1 times, most recent failure: Lost task 0.0 in stage 15.0 (TID 15) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:18 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:18 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:18 ERROR Executor: Exception in task 0.0 in stage 16.0 (TID 16)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:18 WARN TaskSetManager: Lost task 0.0 in stage 16.0 (TID 16) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:18 ERROR TaskSetManager: Task 0 in stage 16.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:18 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 16.0 failed 1 times, most recent failure: Lost task 0.0 in stage 16.0 (TID 16) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:18 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:19 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:19 ERROR Executor: Exception in task 0.0 in stage 17.0 (TID 17)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:19 WARN TaskSetManager: Lost task 0.0 in stage 17.0 (TID 17) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:19 ERROR TaskSetManager: Task 0 in stage 17.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:19 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 17.0 failed 1 times, most recent failure: Lost task 0.0 in stage 17.0 (TID 17) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:19 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:19 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:19 ERROR Executor: Exception in task 0.0 in stage 18.0 (TID 18)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:19 WARN TaskSetManager: Lost task 0.0 in stage 18.0 (TID 18) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:19 ERROR TaskSetManager: Task 0 in stage 18.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:19 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 18.0 failed 1 times, most recent failure: Lost task 0.0 in stage 18.0 (TID 18) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:19 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2022-05-25 13:09:20\n",
      "-------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/25 13:09:20 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:20 ERROR Executor: Exception in task 0.0 in stage 19.0 (TID 19)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:20 WARN TaskSetManager: Lost task 0.0 in stage 19.0 (TID 19) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:20 ERROR TaskSetManager: Task 0 in stage 19.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:20 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 19.0 failed 1 times, most recent failure: Lost task 0.0 in stage 19.0 (TID 19) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:20 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:20 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:20 ERROR Executor: Exception in task 0.0 in stage 20.0 (TID 20)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:20 WARN TaskSetManager: Lost task 0.0 in stage 20.0 (TID 20) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:20 ERROR TaskSetManager: Task 0 in stage 20.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:20 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 20.0 failed 1 times, most recent failure: Lost task 0.0 in stage 20.0 (TID 20) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:20 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:20 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:20 ERROR Executor: Exception in task 0.0 in stage 21.0 (TID 21)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:20 WARN TaskSetManager: Lost task 0.0 in stage 21.0 (TID 21) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:20 ERROR TaskSetManager: Task 0 in stage 21.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:20 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 21.0 failed 1 times, most recent failure: Lost task 0.0 in stage 21.0 (TID 21) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:20 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:21 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:21 ERROR Executor: Exception in task 0.0 in stage 22.0 (TID 22)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:21 WARN TaskSetManager: Lost task 0.0 in stage 22.0 (TID 22) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:21 ERROR TaskSetManager: Task 0 in stage 22.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:21 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 22.0 failed 1 times, most recent failure: Lost task 0.0 in stage 22.0 (TID 22) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:21 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:21 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:21 ERROR Executor: Exception in task 0.0 in stage 23.0 (TID 23)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:21 WARN TaskSetManager: Lost task 0.0 in stage 23.0 (TID 23) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:21 ERROR TaskSetManager: Task 0 in stage 23.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:21 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 23.0 failed 1 times, most recent failure: Lost task 0.0 in stage 23.0 (TID 23) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:21 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:22 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:22 ERROR Executor: Exception in task 0.0 in stage 24.0 (TID 24)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:22 WARN TaskSetManager: Lost task 0.0 in stage 24.0 (TID 24) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:22 ERROR TaskSetManager: Task 0 in stage 24.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:22 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 24.0 failed 1 times, most recent failure: Lost task 0.0 in stage 24.0 (TID 24) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:22 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:22 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:22 ERROR Executor: Exception in task 0.0 in stage 25.0 (TID 25)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:22 WARN TaskSetManager: Lost task 0.0 in stage 25.0 (TID 25) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:22 ERROR TaskSetManager: Task 0 in stage 25.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:22 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 25.0 failed 1 times, most recent failure: Lost task 0.0 in stage 25.0 (TID 25) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:22 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:22 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:22 ERROR Executor: Exception in task 0.0 in stage 26.0 (TID 26)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:22 WARN TaskSetManager: Lost task 0.0 in stage 26.0 (TID 26) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:22 ERROR TaskSetManager: Task 0 in stage 26.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:22 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 26.0 failed 1 times, most recent failure: Lost task 0.0 in stage 26.0 (TID 26) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:22 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:23 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:23 ERROR Executor: Exception in task 0.0 in stage 27.0 (TID 27)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:23 WARN TaskSetManager: Lost task 0.0 in stage 27.0 (TID 27) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:23 ERROR TaskSetManager: Task 0 in stage 27.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:23 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 27.0 failed 1 times, most recent failure: Lost task 0.0 in stage 27.0 (TID 27) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:23 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:23 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:23 ERROR Executor: Exception in task 0.0 in stage 28.0 (TID 28)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:23 WARN TaskSetManager: Lost task 0.0 in stage 28.0 (TID 28) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:23 ERROR TaskSetManager: Task 0 in stage 28.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:23 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 28.0 failed 1 times, most recent failure: Lost task 0.0 in stage 28.0 (TID 28) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:23 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:24 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:24 ERROR Executor: Exception in task 0.0 in stage 29.0 (TID 29)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:24 WARN TaskSetManager: Lost task 0.0 in stage 29.0 (TID 29) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:24 ERROR TaskSetManager: Task 0 in stage 29.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:24 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 29.0 failed 1 times, most recent failure: Lost task 0.0 in stage 29.0 (TID 29) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:24 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:24 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:24 ERROR Executor: Exception in task 0.0 in stage 30.0 (TID 30)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:24 WARN TaskSetManager: Lost task 0.0 in stage 30.0 (TID 30) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:24 ERROR TaskSetManager: Task 0 in stage 30.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:24 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 30.0 failed 1 times, most recent failure: Lost task 0.0 in stage 30.0 (TID 30) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:24 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:24 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:24 ERROR Executor: Exception in task 0.0 in stage 31.0 (TID 31)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:24 WARN TaskSetManager: Lost task 0.0 in stage 31.0 (TID 31) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:24 ERROR TaskSetManager: Task 0 in stage 31.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:24 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 31.0 failed 1 times, most recent failure: Lost task 0.0 in stage 31.0 (TID 31) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:24 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:25 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:25 ERROR Executor: Exception in task 0.0 in stage 32.0 (TID 32)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:25 WARN TaskSetManager: Lost task 0.0 in stage 32.0 (TID 32) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:25 ERROR TaskSetManager: Task 0 in stage 32.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:25 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 32.0 failed 1 times, most recent failure: Lost task 0.0 in stage 32.0 (TID 32) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:25 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:25 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:25 ERROR Executor: Exception in task 0.0 in stage 33.0 (TID 33)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:25 WARN TaskSetManager: Lost task 0.0 in stage 33.0 (TID 33) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:25 ERROR TaskSetManager: Task 0 in stage 33.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:25 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 33.0 failed 1 times, most recent failure: Lost task 0.0 in stage 33.0 (TID 33) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:25 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:26 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:26 ERROR Executor: Exception in task 0.0 in stage 34.0 (TID 34)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:26 WARN TaskSetManager: Lost task 0.0 in stage 34.0 (TID 34) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:26 ERROR TaskSetManager: Task 0 in stage 34.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:26 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 34.0 failed 1 times, most recent failure: Lost task 0.0 in stage 34.0 (TID 34) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:26 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:26 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:26 ERROR Executor: Exception in task 0.0 in stage 35.0 (TID 35)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:26 WARN TaskSetManager: Lost task 0.0 in stage 35.0 (TID 35) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:26 ERROR TaskSetManager: Task 0 in stage 35.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:26 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 35.0 failed 1 times, most recent failure: Lost task 0.0 in stage 35.0 (TID 35) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:26 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:26 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:26 ERROR Executor: Exception in task 0.0 in stage 36.0 (TID 36)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:26 WARN TaskSetManager: Lost task 0.0 in stage 36.0 (TID 36) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:26 ERROR TaskSetManager: Task 0 in stage 36.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:26 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 36.0 failed 1 times, most recent failure: Lost task 0.0 in stage 36.0 (TID 36) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:26 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:27 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:27 ERROR Executor: Exception in task 0.0 in stage 37.0 (TID 37)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:27 WARN TaskSetManager: Lost task 0.0 in stage 37.0 (TID 37) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:27 ERROR TaskSetManager: Task 0 in stage 37.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:27 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 37.0 failed 1 times, most recent failure: Lost task 0.0 in stage 37.0 (TID 37) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:27 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:27 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:27 ERROR Executor: Exception in task 0.0 in stage 38.0 (TID 38)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:27 WARN TaskSetManager: Lost task 0.0 in stage 38.0 (TID 38) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:27 ERROR TaskSetManager: Task 0 in stage 38.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:27 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 38.0 failed 1 times, most recent failure: Lost task 0.0 in stage 38.0 (TID 38) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:27 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:28 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:28 ERROR Executor: Exception in task 0.0 in stage 39.0 (TID 39)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:28 WARN TaskSetManager: Lost task 0.0 in stage 39.0 (TID 39) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:28 ERROR TaskSetManager: Task 0 in stage 39.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:28 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 39.0 failed 1 times, most recent failure: Lost task 0.0 in stage 39.0 (TID 39) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:28 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:28 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:28 ERROR Executor: Exception in task 0.0 in stage 40.0 (TID 40)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:28 WARN TaskSetManager: Lost task 0.0 in stage 40.0 (TID 40) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:28 ERROR TaskSetManager: Task 0 in stage 40.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:28 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 40.0 failed 1 times, most recent failure: Lost task 0.0 in stage 40.0 (TID 40) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/py4j/clientserver.py\", line 475, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "RuntimeError: reentrant call inside <_io.BufferedReader name=75>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/py4j/clientserver.py\", line 503, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n",
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/py4j/clientserver.py\", line 475, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/Users/fipm/.pyenv/versions/3.8.12/lib/python3.8/socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/pyspark/context.py\", line 292, in signal_handler\n",
      "    self.cancelAllJobs()\n",
      "  File \"/Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/pyspark/context.py\", line 1195, in cancelAllJobs\n",
      "    self._jsc.sc().cancelAllJobs()\n",
      "  File \"/Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1321, in __call__\n",
      "    return_value = get_return_value(\n",
      "  File \"/Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/py4j/protocol.py\", line 334, in get_return_value\n",
      "    raise Py4JError(\n",
      "py4j.protocol.Py4JError: An error occurred while calling o412.sc\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/py4j/clientserver.py\", line 503, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n",
      "22/05/25 13:09:28 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n"
     ]
    },
    {
     "ename": "Py4JError",
     "evalue": "An error occurred while calling o421.awaitTermination",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/fipm/code/abefarkas/Thalassa_Regime_Classifier/notebooks/FIPM_understanding_stream_data.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fipm/code/abefarkas/Thalassa_Regime_Classifier/notebooks/FIPM_understanding_stream_data.ipynb#ch0000006?line=11'>12</a>\u001b[0m lines\u001b[39m.\u001b[39mpprint()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fipm/code/abefarkas/Thalassa_Regime_Classifier/notebooks/FIPM_understanding_stream_data.ipynb#ch0000006?line=13'>14</a>\u001b[0m ssc\u001b[39m.\u001b[39mstart()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/fipm/code/abefarkas/Thalassa_Regime_Classifier/notebooks/FIPM_understanding_stream_data.ipynb#ch0000006?line=14'>15</a>\u001b[0m ssc\u001b[39m.\u001b[39;49mawaitTermination()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/pyspark/streaming/context.py:200\u001b[0m, in \u001b[0;36mStreamingContext.awaitTermination\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/pyspark/streaming/context.py?line=190'>191</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/pyspark/streaming/context.py?line=191'>192</a>\u001b[0m \u001b[39mWait for the execution to stop.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/pyspark/streaming/context.py?line=192'>193</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/pyspark/streaming/context.py?line=196'>197</a>\u001b[0m \u001b[39m    time to wait in seconds\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/pyspark/streaming/context.py?line=197'>198</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/pyspark/streaming/context.py?line=198'>199</a>\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/pyspark/streaming/context.py?line=199'>200</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jssc\u001b[39m.\u001b[39;49mawaitTermination()\n\u001b[1;32m    <a href='file:///Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/pyspark/streaming/context.py?line=200'>201</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/pyspark/streaming/context.py?line=201'>202</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jssc\u001b[39m.\u001b[39mawaitTerminationOrTimeout(\u001b[39mint\u001b[39m(timeout \u001b[39m*\u001b[39m \u001b[39m1000\u001b[39m))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/py4j/java_gateway.py?line=1314'>1315</a>\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   <a href='file:///Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/py4j/java_gateway.py?line=1315'>1316</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   <a href='file:///Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/py4j/java_gateway.py?line=1316'>1317</a>\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   <a href='file:///Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/py4j/java_gateway.py?line=1317'>1318</a>\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   <a href='file:///Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/py4j/java_gateway.py?line=1319'>1320</a>\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[0;32m-> <a href='file:///Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/py4j/java_gateway.py?line=1320'>1321</a>\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   <a href='file:///Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/py4j/java_gateway.py?line=1321'>1322</a>\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[1;32m   <a href='file:///Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/py4j/java_gateway.py?line=1323'>1324</a>\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[1;32m   <a href='file:///Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/py4j/java_gateway.py?line=1324'>1325</a>\u001b[0m     temp_arg\u001b[39m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/py4j/protocol.py:334\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/py4j/protocol.py?line=329'>330</a>\u001b[0m             \u001b[39mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    <a href='file:///Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/py4j/protocol.py?line=330'>331</a>\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m{1}\u001b[39;00m\u001b[39m{2}\u001b[39;00m\u001b[39m. Trace:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{3}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\n\u001b[1;32m    <a href='file:///Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/py4j/protocol.py?line=331'>332</a>\u001b[0m                 \u001b[39mformat\u001b[39m(target_id, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, name, value))\n\u001b[1;32m    <a href='file:///Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/py4j/protocol.py?line=332'>333</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/py4j/protocol.py?line=333'>334</a>\u001b[0m         \u001b[39mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    <a href='file:///Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/py4j/protocol.py?line=334'>335</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m{1}\u001b[39;00m\u001b[39m{2}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\n\u001b[1;32m    <a href='file:///Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/py4j/protocol.py?line=335'>336</a>\u001b[0m             \u001b[39mformat\u001b[39m(target_id, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, name))\n\u001b[1;32m    <a href='file:///Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/py4j/protocol.py?line=336'>337</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/py4j/protocol.py?line=337'>338</a>\u001b[0m     \u001b[39mtype\u001b[39m \u001b[39m=\u001b[39m answer[\u001b[39m1\u001b[39m]\n",
      "\u001b[0;31mPy4JError\u001b[0m: An error occurred while calling o421.awaitTermination"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/25 13:09:28 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:28 ERROR Executor: Exception in task 0.0 in stage 41.0 (TID 41)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:28 WARN TaskSetManager: Lost task 0.0 in stage 41.0 (TID 41) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:28 ERROR TaskSetManager: Task 0 in stage 41.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:28 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 41.0 failed 1 times, most recent failure: Lost task 0.0 in stage 41.0 (TID 41) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:28 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:29 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:29 ERROR Executor: Exception in task 0.0 in stage 42.0 (TID 42)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:29 WARN TaskSetManager: Lost task 0.0 in stage 42.0 (TID 42) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:29 ERROR TaskSetManager: Task 0 in stage 42.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:29 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 42.0 failed 1 times, most recent failure: Lost task 0.0 in stage 42.0 (TID 42) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:29 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:29 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:29 ERROR Executor: Exception in task 0.0 in stage 43.0 (TID 43)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:29 WARN TaskSetManager: Lost task 0.0 in stage 43.0 (TID 43) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:29 ERROR TaskSetManager: Task 0 in stage 43.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:29 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 43.0 failed 1 times, most recent failure: Lost task 0.0 in stage 43.0 (TID 43) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:29 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2022-05-25 13:09:30\n",
      "-------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/25 13:09:30 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:30 ERROR Executor: Exception in task 0.0 in stage 44.0 (TID 44)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:30 WARN TaskSetManager: Lost task 0.0 in stage 44.0 (TID 44) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:30 ERROR TaskSetManager: Task 0 in stage 44.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:30 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 44.0 failed 1 times, most recent failure: Lost task 0.0 in stage 44.0 (TID 44) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:30 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:30 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:30 ERROR Executor: Exception in task 0.0 in stage 45.0 (TID 45)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:30 WARN TaskSetManager: Lost task 0.0 in stage 45.0 (TID 45) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:30 ERROR TaskSetManager: Task 0 in stage 45.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:30 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 45.0 failed 1 times, most recent failure: Lost task 0.0 in stage 45.0 (TID 45) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:30 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:30 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:30 ERROR Executor: Exception in task 0.0 in stage 46.0 (TID 46)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:30 WARN TaskSetManager: Lost task 0.0 in stage 46.0 (TID 46) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:30 ERROR TaskSetManager: Task 0 in stage 46.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:30 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 46.0 failed 1 times, most recent failure: Lost task 0.0 in stage 46.0 (TID 46) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:30 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:31 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:31 ERROR Executor: Exception in task 0.0 in stage 47.0 (TID 47)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:31 WARN TaskSetManager: Lost task 0.0 in stage 47.0 (TID 47) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:31 ERROR TaskSetManager: Task 0 in stage 47.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:31 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 47.0 failed 1 times, most recent failure: Lost task 0.0 in stage 47.0 (TID 47) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:31 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:31 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:31 ERROR Executor: Exception in task 0.0 in stage 48.0 (TID 48)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:31 WARN TaskSetManager: Lost task 0.0 in stage 48.0 (TID 48) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:31 ERROR TaskSetManager: Task 0 in stage 48.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:31 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 48.0 failed 1 times, most recent failure: Lost task 0.0 in stage 48.0 (TID 48) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:31 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:32 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:32 ERROR Executor: Exception in task 0.0 in stage 49.0 (TID 49)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:32 WARN TaskSetManager: Lost task 0.0 in stage 49.0 (TID 49) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:32 ERROR TaskSetManager: Task 0 in stage 49.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:32 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 49.0 failed 1 times, most recent failure: Lost task 0.0 in stage 49.0 (TID 49) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:32 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:32 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:32 ERROR Executor: Exception in task 0.0 in stage 50.0 (TID 50)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:32 WARN TaskSetManager: Lost task 0.0 in stage 50.0 (TID 50) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:32 ERROR TaskSetManager: Task 0 in stage 50.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:32 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 50.0 failed 1 times, most recent failure: Lost task 0.0 in stage 50.0 (TID 50) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:32 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:32 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:32 ERROR Executor: Exception in task 0.0 in stage 51.0 (TID 51)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:32 WARN TaskSetManager: Lost task 0.0 in stage 51.0 (TID 51) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:32 ERROR TaskSetManager: Task 0 in stage 51.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:32 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 51.0 failed 1 times, most recent failure: Lost task 0.0 in stage 51.0 (TID 51) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:32 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:33 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:33 ERROR Executor: Exception in task 0.0 in stage 52.0 (TID 52)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:33 WARN TaskSetManager: Lost task 0.0 in stage 52.0 (TID 52) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:33 ERROR TaskSetManager: Task 0 in stage 52.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:33 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 52.0 failed 1 times, most recent failure: Lost task 0.0 in stage 52.0 (TID 52) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:33 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:33 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:33 ERROR Executor: Exception in task 0.0 in stage 53.0 (TID 53)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:33 WARN TaskSetManager: Lost task 0.0 in stage 53.0 (TID 53) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:33 ERROR TaskSetManager: Task 0 in stage 53.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:33 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 53.0 failed 1 times, most recent failure: Lost task 0.0 in stage 53.0 (TID 53) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:33 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:34 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:34 ERROR Executor: Exception in task 0.0 in stage 54.0 (TID 54)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:34 WARN TaskSetManager: Lost task 0.0 in stage 54.0 (TID 54) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:34 ERROR TaskSetManager: Task 0 in stage 54.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:34 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 54.0 failed 1 times, most recent failure: Lost task 0.0 in stage 54.0 (TID 54) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:34 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:34 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:34 ERROR Executor: Exception in task 0.0 in stage 55.0 (TID 55)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:34 WARN TaskSetManager: Lost task 0.0 in stage 55.0 (TID 55) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:34 ERROR TaskSetManager: Task 0 in stage 55.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:34 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 55.0 failed 1 times, most recent failure: Lost task 0.0 in stage 55.0 (TID 55) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:34 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:34 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:34 ERROR Executor: Exception in task 0.0 in stage 56.0 (TID 56)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:34 WARN TaskSetManager: Lost task 0.0 in stage 56.0 (TID 56) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:34 ERROR TaskSetManager: Task 0 in stage 56.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:34 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 56.0 failed 1 times, most recent failure: Lost task 0.0 in stage 56.0 (TID 56) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:34 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:35 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:35 ERROR Executor: Exception in task 0.0 in stage 57.0 (TID 57)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:35 WARN TaskSetManager: Lost task 0.0 in stage 57.0 (TID 57) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:35 ERROR TaskSetManager: Task 0 in stage 57.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:35 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 57.0 failed 1 times, most recent failure: Lost task 0.0 in stage 57.0 (TID 57) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:35 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:35 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:35 ERROR Executor: Exception in task 0.0 in stage 58.0 (TID 58)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:35 WARN TaskSetManager: Lost task 0.0 in stage 58.0 (TID 58) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:35 ERROR TaskSetManager: Task 0 in stage 58.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:35 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 58.0 failed 1 times, most recent failure: Lost task 0.0 in stage 58.0 (TID 58) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:35 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:36 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:36 ERROR Executor: Exception in task 0.0 in stage 59.0 (TID 59)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:36 WARN TaskSetManager: Lost task 0.0 in stage 59.0 (TID 59) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:36 ERROR TaskSetManager: Task 0 in stage 59.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:36 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 59.0 failed 1 times, most recent failure: Lost task 0.0 in stage 59.0 (TID 59) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:36 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:36 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:36 ERROR Executor: Exception in task 0.0 in stage 60.0 (TID 60)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:36 WARN TaskSetManager: Lost task 0.0 in stage 60.0 (TID 60) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:36 ERROR TaskSetManager: Task 0 in stage 60.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:36 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 60.0 failed 1 times, most recent failure: Lost task 0.0 in stage 60.0 (TID 60) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:36 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:36 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:36 ERROR Executor: Exception in task 0.0 in stage 61.0 (TID 61)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:36 WARN TaskSetManager: Lost task 0.0 in stage 61.0 (TID 61) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:36 ERROR TaskSetManager: Task 0 in stage 61.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:36 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 61.0 failed 1 times, most recent failure: Lost task 0.0 in stage 61.0 (TID 61) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:36 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:37 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:37 ERROR Executor: Exception in task 0.0 in stage 62.0 (TID 62)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:37 WARN TaskSetManager: Lost task 0.0 in stage 62.0 (TID 62) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:37 ERROR TaskSetManager: Task 0 in stage 62.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:37 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 62.0 failed 1 times, most recent failure: Lost task 0.0 in stage 62.0 (TID 62) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:37 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:37 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:37 ERROR Executor: Exception in task 0.0 in stage 63.0 (TID 63)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:37 WARN TaskSetManager: Lost task 0.0 in stage 63.0 (TID 63) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:37 ERROR TaskSetManager: Task 0 in stage 63.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:37 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 63.0 failed 1 times, most recent failure: Lost task 0.0 in stage 63.0 (TID 63) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:37 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:38 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:38 ERROR Executor: Exception in task 0.0 in stage 64.0 (TID 64)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:38 WARN TaskSetManager: Lost task 0.0 in stage 64.0 (TID 64) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:38 ERROR TaskSetManager: Task 0 in stage 64.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:38 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 64.0 failed 1 times, most recent failure: Lost task 0.0 in stage 64.0 (TID 64) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:38 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:38 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:38 ERROR Executor: Exception in task 0.0 in stage 65.0 (TID 65)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:38 WARN TaskSetManager: Lost task 0.0 in stage 65.0 (TID 65) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:38 ERROR TaskSetManager: Task 0 in stage 65.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:38 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 65.0 failed 1 times, most recent failure: Lost task 0.0 in stage 65.0 (TID 65) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:38 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:38 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:38 ERROR Executor: Exception in task 0.0 in stage 66.0 (TID 66)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:38 WARN TaskSetManager: Lost task 0.0 in stage 66.0 (TID 66) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:38 ERROR TaskSetManager: Task 0 in stage 66.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:38 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 66.0 failed 1 times, most recent failure: Lost task 0.0 in stage 66.0 (TID 66) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:38 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:39 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:39 ERROR Executor: Exception in task 0.0 in stage 67.0 (TID 67)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:39 WARN TaskSetManager: Lost task 0.0 in stage 67.0 (TID 67) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:39 ERROR TaskSetManager: Task 0 in stage 67.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:39 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 67.0 failed 1 times, most recent failure: Lost task 0.0 in stage 67.0 (TID 67) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:39 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:39 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:39 ERROR Executor: Exception in task 0.0 in stage 68.0 (TID 68)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:39 WARN TaskSetManager: Lost task 0.0 in stage 68.0 (TID 68) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:39 ERROR TaskSetManager: Task 0 in stage 68.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:39 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 68.0 failed 1 times, most recent failure: Lost task 0.0 in stage 68.0 (TID 68) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:39 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Uncomment the next line to run the code block on jupyter. Keep it commented if copy-pasting into the pyspark shell\n",
    "sc = pyspark.SparkContext()\n",
    "\n",
    "# This tells Spark Streaming to bacth-up the contents of a data stream and \"ingest\" them every 10 seconds.\n",
    "ssc = StreamingContext(sc,10)\n",
    "\n",
    "# Tell spark to listen on port 9999 of our localhost.\n",
    "lines = ssc.socketTextStream('wss://stream.binance.com/ws/BTCUSDT@depth5', 9443)\n",
    "\n",
    "\n",
    "\n",
    "lines.pprint()\n",
    "\n",
    "ssc.start()\n",
    "ssc.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/25 13:09:40 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:40 ERROR Executor: Exception in task 0.0 in stage 69.0 (TID 69)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:40 WARN TaskSetManager: Lost task 0.0 in stage 69.0 (TID 69) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:40 ERROR TaskSetManager: Task 0 in stage 69.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:40 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 69.0 failed 1 times, most recent failure: Lost task 0.0 in stage 69.0 (TID 69) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:40 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Could not find Receiver-0-1653505779672.\n",
      "\tat org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:178)\n",
      "\tat org.apache.spark.rpc.netty.Dispatcher.postOneWayMessage(Dispatcher.scala:150)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.send(NettyRpcEnv.scala:193)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEndpointRef.send(NettyRpcEnv.scala:564)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$stopReceivers$2(ReceiverTracker.scala:657)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$stopReceivers$2$adapted(ReceiverTracker.scala:657)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.org$apache$spark$streaming$scheduler$ReceiverTracker$ReceiverTrackerEndpoint$$stopReceivers(ReceiverTracker.scala:657)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$receiveAndReply$1.applyOrElse(ReceiverTracker.scala:538)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:40 ERROR Utils: Uncaught exception in thread Thread-173\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker.stop(ReceiverTracker.scala:172)\n",
      "\tat org.apache.spark.streaming.scheduler.JobScheduler.stop(JobScheduler.scala:113)\n",
      "\tat org.apache.spark.streaming.StreamingContext.$anonfun$stop$3(StreamingContext.scala:688)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1442)\n",
      "\tat org.apache.spark.streaming.StreamingContext.stop(StreamingContext.scala:688)\n",
      "\tat org.apache.spark.streaming.api.java.JavaStreamingContext.stop(JavaStreamingContext.scala:602)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Could not find Receiver-0-1653505779672.\n",
      "\tat org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:178)\n",
      "\tat org.apache.spark.rpc.netty.Dispatcher.postOneWayMessage(Dispatcher.scala:150)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.send(NettyRpcEnv.scala:193)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEndpointRef.send(NettyRpcEnv.scala:564)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$stopReceivers$2(ReceiverTracker.scala:657)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$stopReceivers$2$adapted(ReceiverTracker.scala:657)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.org$apache$spark$streaming$scheduler$ReceiverTracker$ReceiverTrackerEndpoint$$stopReceivers(ReceiverTracker.scala:657)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$receiveAndReply$1.applyOrElse(ReceiverTracker.scala:538)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\t... 1 more\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2022-05-25 13:09:40\n",
      "-------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/25 13:09:50 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:10:00 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:10:10 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:10:20 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:10:30 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:10:40 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:10:50 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:11:00 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:11:10 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:11:20 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:11:30 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:11:40 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:11:50 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:12:00 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:12:10 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:12:20 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:12:30 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:12:40 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:12:50 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:13:00 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:13:10 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:13:20 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:13:30 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:13:40 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:13:50 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:14:00 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:14:10 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:14:20 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:14:30 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:14:40 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:14:50 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:15:00 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:15:10 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:15:20 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:15:30 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:15:40 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:15:50 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:16:00 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:16:10 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:16:20 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:16:30 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:16:40 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:16:50 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:17:00 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:17:10 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:17:20 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:17:30 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:17:40 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:17:50 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:18:00 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:18:10 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:18:20 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:18:30 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:18:40 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:18:50 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:19:00 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:19:10 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:19:20 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:19:30 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:19:40 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:19:50 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:20:00 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:20:10 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:20:20 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:20:30 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:20:40 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:20:50 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:21:00 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:21:10 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:21:20 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:21:30 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:21:40 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:21:50 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:22:00 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:22:10 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:22:20 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:22:30 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:22:40 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:22:50 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:23:00 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:23:10 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:23:20 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:23:30 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:23:40 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:23:50 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:24:00 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:24:10 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:24:20 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:24:30 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:24:40 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:24:50 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:25:00 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:25:10 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:25:20 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:25:30 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:25:40 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:25:50 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:26:00 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:26:10 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:26:20 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:26:30 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:26:40 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:26:50 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:27:00 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:27:10 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:27:20 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:27:30 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:27:40 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:27:50 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:28:00 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:28:10 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:28:20 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:28:30 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:28:40 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:28:50 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:29:00 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:29:10 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:29:20 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:29:30 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:29:40 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:29:50 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:30:00 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:30:10 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:30:20 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:30:30 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:30:40 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:30:50 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:31:00 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:31:10 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:31:20 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:31:30 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:31:40 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:31:50 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:32:00 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:32:10 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:32:20 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:32:30 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:32:40 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:32:50 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:33:00 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n"
     ]
    }
   ],
   "source": [
    "ssc.stop()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1f53de40d125f7884f636dff8497593e6e6ea391da6f1e4c596278056577faa2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('thalassa')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
