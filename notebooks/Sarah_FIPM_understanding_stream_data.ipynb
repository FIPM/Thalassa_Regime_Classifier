{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Thalassa_Regime_Classifier'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/sarah/code/abefarkas/Thalassa_Regime_Classifier/notebooks/Sarah_understanding_stream_data.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/sarah/code/abefarkas/Thalassa_Regime_Classifier/notebooks/Sarah_understanding_stream_data.ipynb#ch0000000vscode-remote?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatetime\u001b[39;00m \u001b[39mimport\u001b[39;00m datetime, timezone\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/sarah/code/abefarkas/Thalassa_Regime_Classifier/notebooks/Sarah_understanding_stream_data.ipynb#ch0000000vscode-remote?line=6'>7</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtime\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/sarah/code/abefarkas/Thalassa_Regime_Classifier/notebooks/Sarah_understanding_stream_data.ipynb#ch0000000vscode-remote?line=7'>8</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mThalassa_Regime_Classifier\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing_streamed_data\u001b[39;00m \u001b[39mimport\u001b[39;00m preprocessing_streamed_data\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Thalassa_Regime_Classifier'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import websocket\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone\n",
    "import time\n",
    "from Thalassa_Regime_Classifier.preprocessing_streamed_data import preprocessing_streamed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1653586152.0\n",
      "1653586152\n"
     ]
    }
   ],
   "source": [
    "print(time.mktime(datetime.now().timetuple()))\n",
    "print(int(time.mktime(datetime.now().timetuple())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_json(json_message):\n",
    "    size = len(np.array(json_message['bids'])[:,0])    \n",
    "    return {\n",
    "        **{'ts':[int(time.mktime(datetime.now().timetuple()))]},\n",
    "        **{'bp'+str(key):[float(value)] for key,value in zip(np.arange(0,size)+1,np.array(json_message['bids'])[:,0])},\n",
    "        **{'bs'+str(key):[float(value)] for key,value in zip(np.arange(0,size)+1,np.array(json_message['bids'])[:,1])},\n",
    "        **{'ap'+str(key):[float(value)] for key,value in zip(np.arange(0,size)+1,np.array(json_message['asks'])[:,0])},\n",
    "        **{'as'+str(key):[float(value)] for key,value in zip(np.arange(0,size)+1,np.array(json_message['asks'])[:,1])}}\n",
    "    \n",
    "def my_json_0(size):    \n",
    "    return {\n",
    "        **{'ts':[int(time.mktime(datetime.now().timetuple()))]},\n",
    "        **{'bp'+str(key):[value] for key,value in zip(np.arange(0,size)+1,(np.arange(0,size)+1)*np.nan)},\n",
    "        **{'bs'+str(key):[value] for key,value in zip(np.arange(0,size)+1,(np.arange(0,size)+1)*np.nan)},\n",
    "        **{'ap'+str(key):[value] for key,value in zip(np.arange(0,size)+1,(np.arange(0,size)+1)*np.nan)},\n",
    "        **{'as'+str(key):[value] for key,value in zip(np.arange(0,size)+1,(np.arange(0,size)+1)*np.nan)}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_0 = pd.DataFrame.from_dict(my_json_0(5))\n",
    "\n",
    "def ws_trades(df_0): \n",
    "    symbol = 'BTCUSDT'\n",
    "    depth = 5\n",
    "    socket = 'wss://stream.binance.com:9443/ws/{}@depth{}'.format(symbol.lower(),\n",
    "                                                                depth)\n",
    "    \n",
    "    \n",
    "    def on_message(wsapp,message):  \n",
    "        json_message = json.loads(message)\n",
    "        handle_trades(json_message)\n",
    "\n",
    "    def on_error(wsapp,error):\n",
    "        print(error)\n",
    "\n",
    "    wsapp = websocket.WebSocketApp(socket, on_message=on_message, on_error=on_error)\n",
    "    wsapp.run_forever()\n",
    "    \n",
    "def handle_trades(json_message):    \n",
    "    df = pd.DataFrame.from_dict(my_json(json_message))\n",
    "    df_0 = df_0.append(df, ignore_index = True)\n",
    "    \n",
    "    print(df_0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StreamingData():\n",
    "    def __init__(self,df_0):\n",
    "        self.df_0=df_0\n",
    "        self.symbol = 'BTCUSDT'\n",
    "        self.depth = 5        \n",
    "        self.socket = 'wss://stream.binance.com:9443/ws/{}@depth{}'.format(self.symbol.lower(),self.depth)\n",
    "        \n",
    "    def handle_trades(self,json_message):    \n",
    "        df = pd.DataFrame.from_dict(my_json(json_message))\n",
    "        self.df_0 = self.df_0.append(df, ignore_index = True)       \n",
    "        print(self.df_0)\n",
    "        print(self.preprocessing_streamed_data(self.df_0, rolling_window=2))\n",
    "                \n",
    "    def my_return(self):\n",
    "        return self.df_0\n",
    "\n",
    "    def on_message(self,wsapp,message):  \n",
    "        json_message = json.loads(message)\n",
    "        self.handle_trades(json_message)\n",
    "\n",
    "    def on_error(self,wsapp,error):\n",
    "        print(error)\n",
    "\n",
    "    def start(self):\n",
    "        wsapp = websocket.WebSocketApp(self.socket, on_message=self.on_message, on_error=self.on_error)\n",
    "        wsapp.run_forever()\n",
    "        \n",
    "    def preprocessing_streamed_data(self,df_ob, rolling_window=2):\n",
    "        '''preprocessing of data for streamed data'''\n",
    "        \n",
    "        print('hola1')\n",
    "        # from unix timestamp to human date\n",
    "        unix_timestamp = lambda x: datetime.fromtimestamp(x/1000.0, tz=timezone.utc).strftime('%Y-%m-%d %H:%M:%S')\n",
    "        str2date = lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "        print('hola2')\n",
    "        df_ob['ts']=df_ob['ts'].apply(unix_timestamp).apply(str2date)\n",
    "        \n",
    "        # aggregating by seconds     \n",
    "        df_agg = df_ob.groupby(pd.Grouper(key='ts', axis=0, freq='S')).mean()\n",
    "        # applying rolling window of rolling_window lenght\n",
    "        df_agg = df_agg.rolling(str(rolling_window)+'S').mean()\n",
    "        df_agg.reset_index(inplace=True)\n",
    "        print(df_agg.head())\n",
    "        # dropping useless columns\n",
    "        #df_agg.drop(columns=['ts'], inplace=True)\n",
    "\n",
    "        return df_agg\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18158/1311226267.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.df_0 = self.df_0.append(df, ignore_index = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ts       bp1       bp2       bp3       bp4       bp5      bs1  \\\n",
      "0  1653586676       NaN       NaN       NaN       NaN       NaN      NaN   \n",
      "1  1653586677  29609.99  29609.97  29608.44  29607.14  29607.13  0.05081   \n",
      "\n",
      "       bs2      bs3      bs4  ...      ap1       ap2       ap3       ap4  \\\n",
      "0      NaN      NaN      NaN  ...      NaN       NaN       NaN       NaN   \n",
      "1  0.01581  0.00067  0.07483  ...  29610.0  29610.01  29610.02  29610.04   \n",
      "\n",
      "       ap5       as1      as2      as3      as4      as5  \n",
      "0      NaN       NaN      NaN      NaN      NaN      NaN  \n",
      "1  29610.1  14.63605  0.01295  0.01465  0.00846  0.02025  \n",
      "\n",
      "[2 rows x 21 columns]\n",
      "hola1\n",
      "hola2\n",
      "                   ts       bp1       bp2       bp3       bp4       bp5  \\\n",
      "0 1970-01-20 03:19:46  29609.99  29609.97  29608.44  29607.14  29607.13   \n",
      "\n",
      "       bs1      bs2      bs3      bs4  ...      ap1       ap2       ap3  \\\n",
      "0  0.05081  0.01581  0.00067  0.07483  ...  29610.0  29610.01  29610.02   \n",
      "\n",
      "        ap4      ap5       as1      as2      as3      as4      as5  \n",
      "0  29610.04  29610.1  14.63605  0.01295  0.01465  0.00846  0.02025  \n",
      "\n",
      "[1 rows x 21 columns]\n",
      "                   ts       bp1       bp2       bp3       bp4       bp5  \\\n",
      "0 1970-01-20 03:19:46  29609.99  29609.97  29608.44  29607.14  29607.13   \n",
      "\n",
      "       bs1      bs2      bs3      bs4  ...      ap1       ap2       ap3  \\\n",
      "0  0.05081  0.01581  0.00067  0.07483  ...  29610.0  29610.01  29610.02   \n",
      "\n",
      "        ap4      ap5       as1      as2      as3      as4      as5  \n",
      "0  29610.04  29610.1  14.63605  0.01295  0.01465  0.00846  0.02025  \n",
      "\n",
      "[1 rows x 21 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18158/1311226267.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.df_0 = self.df_0.append(df, ignore_index = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    ts       bp1       bp2       bp3       bp4       bp5  \\\n",
      "0  1970-01-20 03:19:46       NaN       NaN       NaN       NaN       NaN   \n",
      "1  1970-01-20 03:19:46  29609.99  29609.97  29608.44  29607.14  29607.13   \n",
      "2           1653586678  29607.13  29607.12  29606.96  29606.95  29606.89   \n",
      "\n",
      "       bs1      bs2      bs3      bs4  ...       ap1       ap2       ap3  \\\n",
      "0      NaN      NaN      NaN      NaN  ...       NaN       NaN       NaN   \n",
      "1  0.05081  0.01581  0.00067  0.07483  ...  29610.00  29610.01  29610.02   \n",
      "2  1.77227  0.00311  0.02395  0.00036  ...  29607.14  29607.24  29607.49   \n",
      "\n",
      "        ap4       ap5       as1      as2      as3      as4      as5  \n",
      "0       NaN       NaN       NaN      NaN      NaN      NaN      NaN  \n",
      "1  29610.04  29610.10  14.63605  0.01295  0.01465  0.00846  0.02025  \n",
      "2  29607.63  29608.45   2.32136  0.00075  0.90000  0.25000  0.30000  \n",
      "\n",
      "[3 rows x 21 columns]\n",
      "hola1\n",
      "hola2\n",
      "unsupported operand type(s) for /: 'Timestamp' and 'float'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18158/1311226267.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.df_0 = self.df_0.append(df, ignore_index = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    ts       bp1       bp2       bp3       bp4       bp5  \\\n",
      "0  1970-01-20 03:19:46       NaN       NaN       NaN       NaN       NaN   \n",
      "1  1970-01-20 03:19:46  29609.99  29609.97  29608.44  29607.14  29607.13   \n",
      "2           1653586678  29607.13  29607.12  29606.96  29606.95  29606.89   \n",
      "3           1653586679  29607.13  29607.12  29607.06  29606.96  29606.95   \n",
      "\n",
      "       bs1      bs2      bs3      bs4  ...       ap1       ap2       ap3  \\\n",
      "0      NaN      NaN      NaN      NaN  ...       NaN       NaN       NaN   \n",
      "1  0.05081  0.01581  0.00067  0.07483  ...  29610.00  29610.01  29610.02   \n",
      "2  1.77227  0.00311  0.02395  0.00036  ...  29607.14  29607.24  29607.49   \n",
      "3  2.11487  0.00311  0.08092  0.02395  ...  29607.14  29607.18  29607.24   \n",
      "\n",
      "        ap4       ap5       as1      as2      as3      as4      as5  \n",
      "0       NaN       NaN       NaN      NaN      NaN      NaN      NaN  \n",
      "1  29610.04  29610.10  14.63605  0.01295  0.01465  0.00846  0.02025  \n",
      "2  29607.63  29608.45   2.32136  0.00075  0.90000  0.25000  0.30000  \n",
      "3  29607.49  29607.63   2.64476  0.01000  0.00075  0.90000  0.25000  \n",
      "\n",
      "[4 rows x 21 columns]\n",
      "hola1\n",
      "hola2\n",
      "unsupported operand type(s) for /: 'Timestamp' and 'float'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_0 = pd.DataFrame.from_dict(my_json_0(5))\n",
    "w = StreamingData(df_0)\n",
    "w.start()\n",
    "\n",
    "# w.my_return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local variable 'df_0' referenced before assignment\n",
      "local variable 'df_0' referenced before assignment\n",
      "local variable 'df_0' referenced before assignment\n",
      "local variable 'df_0' referenced before assignment\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ws_trades(df_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nikhil': 1, 'akash': 7, 'manjeet': 10, 'akshat': 5, 'm': 15}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  \n",
    "# initialising dictionaries\n",
    "ini_dictionary1 = {'nikhil': 1, 'akash' : 5,\n",
    "                     'manjeet' : 10, 'akshat' : 15}\n",
    "ini_dictionary2 = {'akash' : 7, 'akshat' : 5,\n",
    "                                          'm' : 15}\n",
    "\n",
    "ini_dictionary1.update(ini_dictionary2)\n",
    "ini_dictionary1  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bp0': '29724.70000000',\n",
       " 'bp1': '29747.650000',\n",
       " 'bp2': '29724.62000000',\n",
       " 'bp3': '29724.61000000',\n",
       " 'bp4': '29724.57000000'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_message ={'lastUpdateId': 19493390097, \n",
    "               'bids': [['29724.70000000', '8.90412000'], ['29747.650000', '0.00429000'], ['29724.62000000', '0.08293000'], ['29724.61000000', '0.01998000'], ['29724.57000000', '0.16835000']], \n",
    "               'asks': [['29724.71000000', '0.00001000'], ['29724.72000000', '0.00075000'], ['29724.73000000', '0.01237000'], ['29724.75000000', '0.01237000'], ['29724.77000000', '0.01000000']]}\n",
    "\n",
    "\n",
    "{'bp'+str(key):value for key,value in zip(np.arange(0,5),np.array(json_message['bids'])[:,0]) }\n",
    "{'bs'+str(key):value for key,value in zip(np.arange(0,5),np.array(json_message['bids'])[:,1]) }\n",
    "{'bp'+str(key):value for key,value in zip(np.arange(0,5),np.array(json_message['bids'])[:,0]) }\n",
    "{'bp'+str(key):value for key,value in zip(np.arange(0,5),np.array(json_message['bids'])[:,0]) }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_message ={'lastUpdateId': 19493390097, \n",
    "               'bids': [['29724.70000000', '8.90412000'], ['nan', '0.00429000'], ['29724.62000000', '0.08293000'], ['29724.61000000', '0.01998000'], ['29724.57000000', '0.16835000']], \n",
    "               'asks': [['29724.71000000', '0.00001000'], ['29724.72000000', '0.00075000'], ['29724.73000000', '0.01237000'], ['29724.75000000', '0.01237000'], ['29724.77000000', '0.01000000']]}\n",
    "aaa(bp1) bid price 1 = 29724.70000000\n",
    "(bs1) bid size 1 = 8.90412000\n",
    "\n",
    "(ap1) asd price 1 = 29724.71000000\n",
    "(as1) ask size 1 = 0000100\n",
    "\n",
    "{'ts':json_message['lastUpdateId'],\n",
    "  'bp1':json_message['bids'][0][0],\n",
    "  'bp1':json_message['bids'][0][0],\n",
    "  'bp1':json_message['bids'][0][0],\n",
    "  'bp1':json_message['bids'][0][0],\n",
    "  'bp1':json_message['bids'][0][0],\n",
    "  'bp1':json_message['bids'][0][0],\n",
    "  'bp1':json_message['bids'][0][0],\n",
    "  'bp1':json_message['bids'][0][0],\n",
    "  'bp1':json_message['bids'][0][0],\n",
    "  'bp1':json_message['bids'][0][0],  \n",
    "  'bp1':json_message['bids'][0][0],\n",
    "  }\n",
    "\n",
    "symbol,ts,last_update_id,bp1,bs1,bp2,bs2,bp3,bs3,bp4,bs4,bp5,bs5,bp6,bs6,bp7,bs7,bp8,bs8,bp9,bs9,bp10,bs10,bp11,bs11,bp12,bs12,bp13,bs13,bp14,bs14,bp15,bs15,bp16,bs16,bp17,bs17,bp18,bs18,bp19,bs19,bp20,bs20,ap1,as1,ap2,as2,ap3,as3,ap4,as4,ap5,as5,ap6,as6,ap7,as7,ap8,as8,ap9,as9,ap10,as10,ap11,as11,ap12,as12,ap13,as13,ap14,as14,ap15,as15,ap16,as16,ap17,as17,ap18,as18,ap19,as19,ap20,as20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.streaming import StreamingContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment the next line to run the code block on jupyter. Keep it commented if copy-pasting into the pyspark shell\n",
    "sc = pyspark.SparkContext()\n",
    "\n",
    "# This tells Spark Streaming to bacth-up the contents of a data stream and \"ingest\" them every 10 seconds.\n",
    "ssc = StreamingContext(sc,10)\n",
    "\n",
    "# Tell spark to listen on port 9999 of our localhost.\n",
    "lines = ssc.socketTextStream('wss://stream.binance.com/ws/BTCUSDT@depth5', 9443)\n",
    "lines = ssc.socketTextStream('localhost', 9999)    \n",
    "\n",
    "words = lines.flatMap(lambda line : line.split(\" \"))\n",
    "\n",
    "pairs = words.map(lambda word: (word, 1))\n",
    "wordCount = pairs.reduceByKey(lambda a, b: a + b)\n",
    "\n",
    "wordCount.pprint()\n",
    "\n",
    "ssc.start()\n",
    "ssc.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/25 13:09:12 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:12 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:12 ERROR Executor: Exception in task 0.0 in stage 0.0 (TID 0)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:12 WARN TaskSetManager: Lost task 0.0 in stage 0.0 (TID 0) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:12 ERROR TaskSetManager: Task 0 in stage 0.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:12 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:12 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:12 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:12 ERROR Executor: Exception in task 0.0 in stage 1.0 (TID 1)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:12 WARN TaskSetManager: Lost task 0.0 in stage 1.0 (TID 1) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:12 ERROR TaskSetManager: Task 0 in stage 1.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:12 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1.0 (TID 1) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:12 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:13 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:13 ERROR Executor: Exception in task 0.0 in stage 2.0 (TID 2)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:13 WARN TaskSetManager: Lost task 0.0 in stage 2.0 (TID 2) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:13 ERROR TaskSetManager: Task 0 in stage 2.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:13 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 2.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2.0 (TID 2) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:13 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:13 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:13 ERROR Executor: Exception in task 0.0 in stage 3.0 (TID 3)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:13 WARN TaskSetManager: Lost task 0.0 in stage 3.0 (TID 3) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:13 ERROR TaskSetManager: Task 0 in stage 3.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:13 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 3.0 failed 1 times, most recent failure: Lost task 0.0 in stage 3.0 (TID 3) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:13 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:14 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:14 ERROR Executor: Exception in task 0.0 in stage 4.0 (TID 4)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:14 WARN TaskSetManager: Lost task 0.0 in stage 4.0 (TID 4) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:14 ERROR TaskSetManager: Task 0 in stage 4.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:14 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 4.0 failed 1 times, most recent failure: Lost task 0.0 in stage 4.0 (TID 4) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:14 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:14 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:14 ERROR Executor: Exception in task 0.0 in stage 5.0 (TID 5)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:14 WARN TaskSetManager: Lost task 0.0 in stage 5.0 (TID 5) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:14 ERROR TaskSetManager: Task 0 in stage 5.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:14 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 5.0 failed 1 times, most recent failure: Lost task 0.0 in stage 5.0 (TID 5) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:14 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:14 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:14 ERROR Executor: Exception in task 0.0 in stage 6.0 (TID 6)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:14 WARN TaskSetManager: Lost task 0.0 in stage 6.0 (TID 6) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:14 ERROR TaskSetManager: Task 0 in stage 6.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:14 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 6.0 failed 1 times, most recent failure: Lost task 0.0 in stage 6.0 (TID 6) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:14 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:15 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:15 ERROR Executor: Exception in task 0.0 in stage 7.0 (TID 7)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:15 WARN TaskSetManager: Lost task 0.0 in stage 7.0 (TID 7) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:15 ERROR TaskSetManager: Task 0 in stage 7.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:15 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 7.0 failed 1 times, most recent failure: Lost task 0.0 in stage 7.0 (TID 7) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:15 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:15 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:15 ERROR Executor: Exception in task 0.0 in stage 8.0 (TID 8)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:15 WARN TaskSetManager: Lost task 0.0 in stage 8.0 (TID 8) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:15 ERROR TaskSetManager: Task 0 in stage 8.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:15 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 8.0 failed 1 times, most recent failure: Lost task 0.0 in stage 8.0 (TID 8) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:15 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:16 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:16 ERROR Executor: Exception in task 0.0 in stage 9.0 (TID 9)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:16 WARN TaskSetManager: Lost task 0.0 in stage 9.0 (TID 9) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:16 ERROR TaskSetManager: Task 0 in stage 9.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:16 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 9.0 failed 1 times, most recent failure: Lost task 0.0 in stage 9.0 (TID 9) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:16 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:16 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:16 ERROR Executor: Exception in task 0.0 in stage 10.0 (TID 10)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:16 WARN TaskSetManager: Lost task 0.0 in stage 10.0 (TID 10) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:16 ERROR TaskSetManager: Task 0 in stage 10.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:16 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 10.0 failed 1 times, most recent failure: Lost task 0.0 in stage 10.0 (TID 10) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:16 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:16 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:16 ERROR Executor: Exception in task 0.0 in stage 11.0 (TID 11)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:16 WARN TaskSetManager: Lost task 0.0 in stage 11.0 (TID 11) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:16 ERROR TaskSetManager: Task 0 in stage 11.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:16 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 11.0 failed 1 times, most recent failure: Lost task 0.0 in stage 11.0 (TID 11) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:16 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:17 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:17 ERROR Executor: Exception in task 0.0 in stage 12.0 (TID 12)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:17 WARN TaskSetManager: Lost task 0.0 in stage 12.0 (TID 12) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:17 ERROR TaskSetManager: Task 0 in stage 12.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:17 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 12.0 failed 1 times, most recent failure: Lost task 0.0 in stage 12.0 (TID 12) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:17 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:17 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:17 ERROR Executor: Exception in task 0.0 in stage 13.0 (TID 13)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:17 WARN TaskSetManager: Lost task 0.0 in stage 13.0 (TID 13) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:17 ERROR TaskSetManager: Task 0 in stage 13.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:17 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 13.0 failed 1 times, most recent failure: Lost task 0.0 in stage 13.0 (TID 13) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:17 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:18 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:18 ERROR Executor: Exception in task 0.0 in stage 14.0 (TID 14)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:18 WARN TaskSetManager: Lost task 0.0 in stage 14.0 (TID 14) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:18 ERROR TaskSetManager: Task 0 in stage 14.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:18 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 14.0 failed 1 times, most recent failure: Lost task 0.0 in stage 14.0 (TID 14) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:18 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:18 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:18 ERROR Executor: Exception in task 0.0 in stage 15.0 (TID 15)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:18 WARN TaskSetManager: Lost task 0.0 in stage 15.0 (TID 15) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:18 ERROR TaskSetManager: Task 0 in stage 15.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:18 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 15.0 failed 1 times, most recent failure: Lost task 0.0 in stage 15.0 (TID 15) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:18 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:18 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:18 ERROR Executor: Exception in task 0.0 in stage 16.0 (TID 16)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:18 WARN TaskSetManager: Lost task 0.0 in stage 16.0 (TID 16) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:18 ERROR TaskSetManager: Task 0 in stage 16.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:18 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 16.0 failed 1 times, most recent failure: Lost task 0.0 in stage 16.0 (TID 16) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:18 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:19 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:19 ERROR Executor: Exception in task 0.0 in stage 17.0 (TID 17)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:19 WARN TaskSetManager: Lost task 0.0 in stage 17.0 (TID 17) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:19 ERROR TaskSetManager: Task 0 in stage 17.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:19 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 17.0 failed 1 times, most recent failure: Lost task 0.0 in stage 17.0 (TID 17) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:19 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:19 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:19 ERROR Executor: Exception in task 0.0 in stage 18.0 (TID 18)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:19 WARN TaskSetManager: Lost task 0.0 in stage 18.0 (TID 18) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:19 ERROR TaskSetManager: Task 0 in stage 18.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:19 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 18.0 failed 1 times, most recent failure: Lost task 0.0 in stage 18.0 (TID 18) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:19 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2022-05-25 13:09:20\n",
      "-------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/25 13:09:20 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:20 ERROR Executor: Exception in task 0.0 in stage 19.0 (TID 19)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:20 WARN TaskSetManager: Lost task 0.0 in stage 19.0 (TID 19) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:20 ERROR TaskSetManager: Task 0 in stage 19.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:20 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 19.0 failed 1 times, most recent failure: Lost task 0.0 in stage 19.0 (TID 19) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:20 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:20 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:20 ERROR Executor: Exception in task 0.0 in stage 20.0 (TID 20)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:20 WARN TaskSetManager: Lost task 0.0 in stage 20.0 (TID 20) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:20 ERROR TaskSetManager: Task 0 in stage 20.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:20 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 20.0 failed 1 times, most recent failure: Lost task 0.0 in stage 20.0 (TID 20) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:20 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:20 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:20 ERROR Executor: Exception in task 0.0 in stage 21.0 (TID 21)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:20 WARN TaskSetManager: Lost task 0.0 in stage 21.0 (TID 21) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:20 ERROR TaskSetManager: Task 0 in stage 21.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:20 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 21.0 failed 1 times, most recent failure: Lost task 0.0 in stage 21.0 (TID 21) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:20 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:21 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:21 ERROR Executor: Exception in task 0.0 in stage 22.0 (TID 22)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:21 WARN TaskSetManager: Lost task 0.0 in stage 22.0 (TID 22) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:21 ERROR TaskSetManager: Task 0 in stage 22.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:21 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 22.0 failed 1 times, most recent failure: Lost task 0.0 in stage 22.0 (TID 22) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:21 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:21 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:21 ERROR Executor: Exception in task 0.0 in stage 23.0 (TID 23)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:21 WARN TaskSetManager: Lost task 0.0 in stage 23.0 (TID 23) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:21 ERROR TaskSetManager: Task 0 in stage 23.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:21 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 23.0 failed 1 times, most recent failure: Lost task 0.0 in stage 23.0 (TID 23) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:21 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:22 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:22 ERROR Executor: Exception in task 0.0 in stage 24.0 (TID 24)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:22 WARN TaskSetManager: Lost task 0.0 in stage 24.0 (TID 24) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:22 ERROR TaskSetManager: Task 0 in stage 24.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:22 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 24.0 failed 1 times, most recent failure: Lost task 0.0 in stage 24.0 (TID 24) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:22 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:22 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:22 ERROR Executor: Exception in task 0.0 in stage 25.0 (TID 25)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:22 WARN TaskSetManager: Lost task 0.0 in stage 25.0 (TID 25) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:22 ERROR TaskSetManager: Task 0 in stage 25.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:22 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 25.0 failed 1 times, most recent failure: Lost task 0.0 in stage 25.0 (TID 25) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:22 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:22 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:22 ERROR Executor: Exception in task 0.0 in stage 26.0 (TID 26)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:22 WARN TaskSetManager: Lost task 0.0 in stage 26.0 (TID 26) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:22 ERROR TaskSetManager: Task 0 in stage 26.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:22 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 26.0 failed 1 times, most recent failure: Lost task 0.0 in stage 26.0 (TID 26) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:22 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:23 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:23 ERROR Executor: Exception in task 0.0 in stage 27.0 (TID 27)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:23 WARN TaskSetManager: Lost task 0.0 in stage 27.0 (TID 27) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:23 ERROR TaskSetManager: Task 0 in stage 27.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:23 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 27.0 failed 1 times, most recent failure: Lost task 0.0 in stage 27.0 (TID 27) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:23 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:23 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:23 ERROR Executor: Exception in task 0.0 in stage 28.0 (TID 28)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:23 WARN TaskSetManager: Lost task 0.0 in stage 28.0 (TID 28) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:23 ERROR TaskSetManager: Task 0 in stage 28.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:23 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 28.0 failed 1 times, most recent failure: Lost task 0.0 in stage 28.0 (TID 28) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:23 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:24 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:24 ERROR Executor: Exception in task 0.0 in stage 29.0 (TID 29)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:24 WARN TaskSetManager: Lost task 0.0 in stage 29.0 (TID 29) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:24 ERROR TaskSetManager: Task 0 in stage 29.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:24 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 29.0 failed 1 times, most recent failure: Lost task 0.0 in stage 29.0 (TID 29) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:24 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:24 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:24 ERROR Executor: Exception in task 0.0 in stage 30.0 (TID 30)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:24 WARN TaskSetManager: Lost task 0.0 in stage 30.0 (TID 30) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:24 ERROR TaskSetManager: Task 0 in stage 30.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:24 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 30.0 failed 1 times, most recent failure: Lost task 0.0 in stage 30.0 (TID 30) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:24 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:24 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:24 ERROR Executor: Exception in task 0.0 in stage 31.0 (TID 31)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:24 WARN TaskSetManager: Lost task 0.0 in stage 31.0 (TID 31) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:24 ERROR TaskSetManager: Task 0 in stage 31.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:24 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 31.0 failed 1 times, most recent failure: Lost task 0.0 in stage 31.0 (TID 31) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:24 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:25 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:25 ERROR Executor: Exception in task 0.0 in stage 32.0 (TID 32)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:25 WARN TaskSetManager: Lost task 0.0 in stage 32.0 (TID 32) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:25 ERROR TaskSetManager: Task 0 in stage 32.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:25 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 32.0 failed 1 times, most recent failure: Lost task 0.0 in stage 32.0 (TID 32) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:25 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:25 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:25 ERROR Executor: Exception in task 0.0 in stage 33.0 (TID 33)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:25 WARN TaskSetManager: Lost task 0.0 in stage 33.0 (TID 33) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:25 ERROR TaskSetManager: Task 0 in stage 33.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:25 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 33.0 failed 1 times, most recent failure: Lost task 0.0 in stage 33.0 (TID 33) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:25 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:26 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:26 ERROR Executor: Exception in task 0.0 in stage 34.0 (TID 34)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:26 WARN TaskSetManager: Lost task 0.0 in stage 34.0 (TID 34) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:26 ERROR TaskSetManager: Task 0 in stage 34.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:26 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 34.0 failed 1 times, most recent failure: Lost task 0.0 in stage 34.0 (TID 34) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:26 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:26 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:26 ERROR Executor: Exception in task 0.0 in stage 35.0 (TID 35)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:26 WARN TaskSetManager: Lost task 0.0 in stage 35.0 (TID 35) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:26 ERROR TaskSetManager: Task 0 in stage 35.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:26 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 35.0 failed 1 times, most recent failure: Lost task 0.0 in stage 35.0 (TID 35) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:26 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:26 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:26 ERROR Executor: Exception in task 0.0 in stage 36.0 (TID 36)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:26 WARN TaskSetManager: Lost task 0.0 in stage 36.0 (TID 36) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:26 ERROR TaskSetManager: Task 0 in stage 36.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:26 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 36.0 failed 1 times, most recent failure: Lost task 0.0 in stage 36.0 (TID 36) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:26 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:27 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:27 ERROR Executor: Exception in task 0.0 in stage 37.0 (TID 37)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:27 WARN TaskSetManager: Lost task 0.0 in stage 37.0 (TID 37) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:27 ERROR TaskSetManager: Task 0 in stage 37.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:27 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 37.0 failed 1 times, most recent failure: Lost task 0.0 in stage 37.0 (TID 37) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:27 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:27 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:27 ERROR Executor: Exception in task 0.0 in stage 38.0 (TID 38)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:27 WARN TaskSetManager: Lost task 0.0 in stage 38.0 (TID 38) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:27 ERROR TaskSetManager: Task 0 in stage 38.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:27 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 38.0 failed 1 times, most recent failure: Lost task 0.0 in stage 38.0 (TID 38) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:27 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:28 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:28 ERROR Executor: Exception in task 0.0 in stage 39.0 (TID 39)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:28 WARN TaskSetManager: Lost task 0.0 in stage 39.0 (TID 39) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:28 ERROR TaskSetManager: Task 0 in stage 39.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:28 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 39.0 failed 1 times, most recent failure: Lost task 0.0 in stage 39.0 (TID 39) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:28 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:28 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:28 ERROR Executor: Exception in task 0.0 in stage 40.0 (TID 40)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:28 WARN TaskSetManager: Lost task 0.0 in stage 40.0 (TID 40) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:28 ERROR TaskSetManager: Task 0 in stage 40.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:28 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 40.0 failed 1 times, most recent failure: Lost task 0.0 in stage 40.0 (TID 40) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/py4j/clientserver.py\", line 475, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "RuntimeError: reentrant call inside <_io.BufferedReader name=75>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/py4j/clientserver.py\", line 503, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n",
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/py4j/clientserver.py\", line 475, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/Users/fipm/.pyenv/versions/3.8.12/lib/python3.8/socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/pyspark/context.py\", line 292, in signal_handler\n",
      "    self.cancelAllJobs()\n",
      "  File \"/Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/pyspark/context.py\", line 1195, in cancelAllJobs\n",
      "    self._jsc.sc().cancelAllJobs()\n",
      "  File \"/Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1321, in __call__\n",
      "    return_value = get_return_value(\n",
      "  File \"/Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/py4j/protocol.py\", line 334, in get_return_value\n",
      "    raise Py4JError(\n",
      "py4j.protocol.Py4JError: An error occurred while calling o412.sc\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/py4j/clientserver.py\", line 503, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n",
      "22/05/25 13:09:28 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n"
     ]
    },
    {
     "ename": "Py4JError",
     "evalue": "An error occurred while calling o421.awaitTermination",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/fipm/code/abefarkas/Thalassa_Regime_Classifier/notebooks/FIPM_understanding_stream_data.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fipm/code/abefarkas/Thalassa_Regime_Classifier/notebooks/FIPM_understanding_stream_data.ipynb#ch0000006?line=11'>12</a>\u001b[0m lines\u001b[39m.\u001b[39mpprint()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fipm/code/abefarkas/Thalassa_Regime_Classifier/notebooks/FIPM_understanding_stream_data.ipynb#ch0000006?line=13'>14</a>\u001b[0m ssc\u001b[39m.\u001b[39mstart()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/fipm/code/abefarkas/Thalassa_Regime_Classifier/notebooks/FIPM_understanding_stream_data.ipynb#ch0000006?line=14'>15</a>\u001b[0m ssc\u001b[39m.\u001b[39;49mawaitTermination()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/pyspark/streaming/context.py:200\u001b[0m, in \u001b[0;36mStreamingContext.awaitTermination\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/pyspark/streaming/context.py?line=190'>191</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/pyspark/streaming/context.py?line=191'>192</a>\u001b[0m \u001b[39mWait for the execution to stop.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/pyspark/streaming/context.py?line=192'>193</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/pyspark/streaming/context.py?line=196'>197</a>\u001b[0m \u001b[39m    time to wait in seconds\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/pyspark/streaming/context.py?line=197'>198</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/pyspark/streaming/context.py?line=198'>199</a>\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/pyspark/streaming/context.py?line=199'>200</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jssc\u001b[39m.\u001b[39;49mawaitTermination()\n\u001b[1;32m    <a href='file:///Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/pyspark/streaming/context.py?line=200'>201</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/pyspark/streaming/context.py?line=201'>202</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jssc\u001b[39m.\u001b[39mawaitTerminationOrTimeout(\u001b[39mint\u001b[39m(timeout \u001b[39m*\u001b[39m \u001b[39m1000\u001b[39m))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/py4j/java_gateway.py?line=1314'>1315</a>\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   <a href='file:///Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/py4j/java_gateway.py?line=1315'>1316</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   <a href='file:///Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/py4j/java_gateway.py?line=1316'>1317</a>\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   <a href='file:///Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/py4j/java_gateway.py?line=1317'>1318</a>\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   <a href='file:///Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/py4j/java_gateway.py?line=1319'>1320</a>\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[0;32m-> <a href='file:///Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/py4j/java_gateway.py?line=1320'>1321</a>\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   <a href='file:///Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/py4j/java_gateway.py?line=1321'>1322</a>\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[1;32m   <a href='file:///Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/py4j/java_gateway.py?line=1323'>1324</a>\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[1;32m   <a href='file:///Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/py4j/java_gateway.py?line=1324'>1325</a>\u001b[0m     temp_arg\u001b[39m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/py4j/protocol.py:334\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/py4j/protocol.py?line=329'>330</a>\u001b[0m             \u001b[39mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    <a href='file:///Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/py4j/protocol.py?line=330'>331</a>\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m{1}\u001b[39;00m\u001b[39m{2}\u001b[39;00m\u001b[39m. Trace:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{3}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\n\u001b[1;32m    <a href='file:///Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/py4j/protocol.py?line=331'>332</a>\u001b[0m                 \u001b[39mformat\u001b[39m(target_id, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, name, value))\n\u001b[1;32m    <a href='file:///Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/py4j/protocol.py?line=332'>333</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/py4j/protocol.py?line=333'>334</a>\u001b[0m         \u001b[39mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    <a href='file:///Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/py4j/protocol.py?line=334'>335</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m{1}\u001b[39;00m\u001b[39m{2}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\n\u001b[1;32m    <a href='file:///Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/py4j/protocol.py?line=335'>336</a>\u001b[0m             \u001b[39mformat\u001b[39m(target_id, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, name))\n\u001b[1;32m    <a href='file:///Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/py4j/protocol.py?line=336'>337</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/fipm/.pyenv/versions/3.8.12/envs/thalassa/lib/python3.8/site-packages/py4j/protocol.py?line=337'>338</a>\u001b[0m     \u001b[39mtype\u001b[39m \u001b[39m=\u001b[39m answer[\u001b[39m1\u001b[39m]\n",
      "\u001b[0;31mPy4JError\u001b[0m: An error occurred while calling o421.awaitTermination"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/25 13:09:28 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:28 ERROR Executor: Exception in task 0.0 in stage 41.0 (TID 41)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:28 WARN TaskSetManager: Lost task 0.0 in stage 41.0 (TID 41) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:28 ERROR TaskSetManager: Task 0 in stage 41.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:28 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 41.0 failed 1 times, most recent failure: Lost task 0.0 in stage 41.0 (TID 41) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:28 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:29 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:29 ERROR Executor: Exception in task 0.0 in stage 42.0 (TID 42)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:29 WARN TaskSetManager: Lost task 0.0 in stage 42.0 (TID 42) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:29 ERROR TaskSetManager: Task 0 in stage 42.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:29 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 42.0 failed 1 times, most recent failure: Lost task 0.0 in stage 42.0 (TID 42) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:29 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:29 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:29 ERROR Executor: Exception in task 0.0 in stage 43.0 (TID 43)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:29 WARN TaskSetManager: Lost task 0.0 in stage 43.0 (TID 43) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:29 ERROR TaskSetManager: Task 0 in stage 43.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:29 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 43.0 failed 1 times, most recent failure: Lost task 0.0 in stage 43.0 (TID 43) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:29 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2022-05-25 13:09:30\n",
      "-------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/25 13:09:30 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:30 ERROR Executor: Exception in task 0.0 in stage 44.0 (TID 44)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:30 WARN TaskSetManager: Lost task 0.0 in stage 44.0 (TID 44) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:30 ERROR TaskSetManager: Task 0 in stage 44.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:30 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 44.0 failed 1 times, most recent failure: Lost task 0.0 in stage 44.0 (TID 44) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:30 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:30 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:30 ERROR Executor: Exception in task 0.0 in stage 45.0 (TID 45)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:30 WARN TaskSetManager: Lost task 0.0 in stage 45.0 (TID 45) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:30 ERROR TaskSetManager: Task 0 in stage 45.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:30 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 45.0 failed 1 times, most recent failure: Lost task 0.0 in stage 45.0 (TID 45) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:30 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:30 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:30 ERROR Executor: Exception in task 0.0 in stage 46.0 (TID 46)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:30 WARN TaskSetManager: Lost task 0.0 in stage 46.0 (TID 46) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:30 ERROR TaskSetManager: Task 0 in stage 46.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:30 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 46.0 failed 1 times, most recent failure: Lost task 0.0 in stage 46.0 (TID 46) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:30 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:31 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:31 ERROR Executor: Exception in task 0.0 in stage 47.0 (TID 47)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:31 WARN TaskSetManager: Lost task 0.0 in stage 47.0 (TID 47) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:31 ERROR TaskSetManager: Task 0 in stage 47.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:31 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 47.0 failed 1 times, most recent failure: Lost task 0.0 in stage 47.0 (TID 47) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:31 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:31 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:31 ERROR Executor: Exception in task 0.0 in stage 48.0 (TID 48)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:31 WARN TaskSetManager: Lost task 0.0 in stage 48.0 (TID 48) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:31 ERROR TaskSetManager: Task 0 in stage 48.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:31 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 48.0 failed 1 times, most recent failure: Lost task 0.0 in stage 48.0 (TID 48) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:31 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:32 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:32 ERROR Executor: Exception in task 0.0 in stage 49.0 (TID 49)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:32 WARN TaskSetManager: Lost task 0.0 in stage 49.0 (TID 49) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:32 ERROR TaskSetManager: Task 0 in stage 49.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:32 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 49.0 failed 1 times, most recent failure: Lost task 0.0 in stage 49.0 (TID 49) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:32 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:32 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:32 ERROR Executor: Exception in task 0.0 in stage 50.0 (TID 50)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:32 WARN TaskSetManager: Lost task 0.0 in stage 50.0 (TID 50) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:32 ERROR TaskSetManager: Task 0 in stage 50.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:32 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 50.0 failed 1 times, most recent failure: Lost task 0.0 in stage 50.0 (TID 50) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:32 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:32 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:32 ERROR Executor: Exception in task 0.0 in stage 51.0 (TID 51)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:32 WARN TaskSetManager: Lost task 0.0 in stage 51.0 (TID 51) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:32 ERROR TaskSetManager: Task 0 in stage 51.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:32 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 51.0 failed 1 times, most recent failure: Lost task 0.0 in stage 51.0 (TID 51) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:32 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:33 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:33 ERROR Executor: Exception in task 0.0 in stage 52.0 (TID 52)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:33 WARN TaskSetManager: Lost task 0.0 in stage 52.0 (TID 52) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:33 ERROR TaskSetManager: Task 0 in stage 52.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:33 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 52.0 failed 1 times, most recent failure: Lost task 0.0 in stage 52.0 (TID 52) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:33 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:33 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:33 ERROR Executor: Exception in task 0.0 in stage 53.0 (TID 53)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:33 WARN TaskSetManager: Lost task 0.0 in stage 53.0 (TID 53) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:33 ERROR TaskSetManager: Task 0 in stage 53.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:33 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 53.0 failed 1 times, most recent failure: Lost task 0.0 in stage 53.0 (TID 53) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:33 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:34 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:34 ERROR Executor: Exception in task 0.0 in stage 54.0 (TID 54)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:34 WARN TaskSetManager: Lost task 0.0 in stage 54.0 (TID 54) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:34 ERROR TaskSetManager: Task 0 in stage 54.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:34 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 54.0 failed 1 times, most recent failure: Lost task 0.0 in stage 54.0 (TID 54) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:34 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:34 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:34 ERROR Executor: Exception in task 0.0 in stage 55.0 (TID 55)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:34 WARN TaskSetManager: Lost task 0.0 in stage 55.0 (TID 55) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:34 ERROR TaskSetManager: Task 0 in stage 55.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:34 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 55.0 failed 1 times, most recent failure: Lost task 0.0 in stage 55.0 (TID 55) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:34 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:34 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:34 ERROR Executor: Exception in task 0.0 in stage 56.0 (TID 56)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:34 WARN TaskSetManager: Lost task 0.0 in stage 56.0 (TID 56) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:34 ERROR TaskSetManager: Task 0 in stage 56.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:34 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 56.0 failed 1 times, most recent failure: Lost task 0.0 in stage 56.0 (TID 56) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:34 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:35 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:35 ERROR Executor: Exception in task 0.0 in stage 57.0 (TID 57)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:35 WARN TaskSetManager: Lost task 0.0 in stage 57.0 (TID 57) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:35 ERROR TaskSetManager: Task 0 in stage 57.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:35 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 57.0 failed 1 times, most recent failure: Lost task 0.0 in stage 57.0 (TID 57) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:35 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:35 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:35 ERROR Executor: Exception in task 0.0 in stage 58.0 (TID 58)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:35 WARN TaskSetManager: Lost task 0.0 in stage 58.0 (TID 58) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:35 ERROR TaskSetManager: Task 0 in stage 58.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:35 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 58.0 failed 1 times, most recent failure: Lost task 0.0 in stage 58.0 (TID 58) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:35 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:36 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:36 ERROR Executor: Exception in task 0.0 in stage 59.0 (TID 59)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:36 WARN TaskSetManager: Lost task 0.0 in stage 59.0 (TID 59) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:36 ERROR TaskSetManager: Task 0 in stage 59.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:36 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 59.0 failed 1 times, most recent failure: Lost task 0.0 in stage 59.0 (TID 59) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:36 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:36 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:36 ERROR Executor: Exception in task 0.0 in stage 60.0 (TID 60)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:36 WARN TaskSetManager: Lost task 0.0 in stage 60.0 (TID 60) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:36 ERROR TaskSetManager: Task 0 in stage 60.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:36 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 60.0 failed 1 times, most recent failure: Lost task 0.0 in stage 60.0 (TID 60) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:36 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:36 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:36 ERROR Executor: Exception in task 0.0 in stage 61.0 (TID 61)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:36 WARN TaskSetManager: Lost task 0.0 in stage 61.0 (TID 61) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:36 ERROR TaskSetManager: Task 0 in stage 61.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:36 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 61.0 failed 1 times, most recent failure: Lost task 0.0 in stage 61.0 (TID 61) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:36 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:37 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:37 ERROR Executor: Exception in task 0.0 in stage 62.0 (TID 62)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:37 WARN TaskSetManager: Lost task 0.0 in stage 62.0 (TID 62) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:37 ERROR TaskSetManager: Task 0 in stage 62.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:37 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 62.0 failed 1 times, most recent failure: Lost task 0.0 in stage 62.0 (TID 62) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:37 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:37 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:37 ERROR Executor: Exception in task 0.0 in stage 63.0 (TID 63)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:37 WARN TaskSetManager: Lost task 0.0 in stage 63.0 (TID 63) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:37 ERROR TaskSetManager: Task 0 in stage 63.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:37 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 63.0 failed 1 times, most recent failure: Lost task 0.0 in stage 63.0 (TID 63) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:37 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:38 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:38 ERROR Executor: Exception in task 0.0 in stage 64.0 (TID 64)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:38 WARN TaskSetManager: Lost task 0.0 in stage 64.0 (TID 64) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:38 ERROR TaskSetManager: Task 0 in stage 64.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:38 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 64.0 failed 1 times, most recent failure: Lost task 0.0 in stage 64.0 (TID 64) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:38 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:38 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:38 ERROR Executor: Exception in task 0.0 in stage 65.0 (TID 65)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:38 WARN TaskSetManager: Lost task 0.0 in stage 65.0 (TID 65) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:38 ERROR TaskSetManager: Task 0 in stage 65.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:38 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 65.0 failed 1 times, most recent failure: Lost task 0.0 in stage 65.0 (TID 65) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:38 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:38 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:38 ERROR Executor: Exception in task 0.0 in stage 66.0 (TID 66)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:38 WARN TaskSetManager: Lost task 0.0 in stage 66.0 (TID 66) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:38 ERROR TaskSetManager: Task 0 in stage 66.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:38 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 66.0 failed 1 times, most recent failure: Lost task 0.0 in stage 66.0 (TID 66) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:38 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:39 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:39 ERROR Executor: Exception in task 0.0 in stage 67.0 (TID 67)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:39 WARN TaskSetManager: Lost task 0.0 in stage 67.0 (TID 67) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:39 ERROR TaskSetManager: Task 0 in stage 67.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:39 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 67.0 failed 1 times, most recent failure: Lost task 0.0 in stage 67.0 (TID 67) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:39 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:39 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:39 ERROR Executor: Exception in task 0.0 in stage 68.0 (TID 68)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:39 WARN TaskSetManager: Lost task 0.0 in stage 68.0 (TID 68) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:39 ERROR TaskSetManager: Task 0 in stage 68.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:39 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 68.0 failed 1 times, most recent failure: Lost task 0.0 in stage 68.0 (TID 68) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:39 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Uncomment the next line to run the code block on jupyter. Keep it commented if copy-pasting into the pyspark shell\n",
    "sc = pyspark.SparkContext()\n",
    "\n",
    "# This tells Spark Streaming to bacth-up the contents of a data stream and \"ingest\" them every 10 seconds.\n",
    "ssc = StreamingContext(sc,10)\n",
    "\n",
    "# Tell spark to listen on port 9999 of our localhost.\n",
    "lines = ssc.socketTextStream('wss://stream.binance.com/ws/BTCUSDT@depth5', 9443)\n",
    "\n",
    "\n",
    "\n",
    "lines.pprint()\n",
    "\n",
    "ssc.start()\n",
    "ssc.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/25 13:09:40 ERROR ReceiverSupervisorImpl: Stopped receiver with error: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "22/05/25 13:09:40 ERROR Executor: Exception in task 0.0 in stage 69.0 (TID 69)\n",
      "java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:40 WARN TaskSetManager: Lost task 0.0 in stage 69.0 (TID 69) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/05/25 13:09:40 ERROR TaskSetManager: Task 0 in stage 69.0 failed 1 times; aborting job\n",
      "22/05/25 13:09:40 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 69.0 failed 1 times, most recent failure: Lost task 0.0 in stage 69.0 (TID 69) (192.168.2.23 executor driver): java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.net.UnknownHostException: wss://stream.binance.com/ws/BTCUSDT@depth5\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1(ReceiverTracker.scala:596)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$startReceiver$1$adapted(ReceiverTracker.scala:586)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$submitJob$1(SparkContext.scala:2363)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:40 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Could not find Receiver-0-1653505779672.\n",
      "\tat org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:178)\n",
      "\tat org.apache.spark.rpc.netty.Dispatcher.postOneWayMessage(Dispatcher.scala:150)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.send(NettyRpcEnv.scala:193)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEndpointRef.send(NettyRpcEnv.scala:564)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$stopReceivers$2(ReceiverTracker.scala:657)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$stopReceivers$2$adapted(ReceiverTracker.scala:657)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.org$apache$spark$streaming$scheduler$ReceiverTracker$ReceiverTrackerEndpoint$$stopReceivers(ReceiverTracker.scala:657)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$receiveAndReply$1.applyOrElse(ReceiverTracker.scala:538)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/05/25 13:09:40 ERROR Utils: Uncaught exception in thread Thread-173\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker.stop(ReceiverTracker.scala:172)\n",
      "\tat org.apache.spark.streaming.scheduler.JobScheduler.stop(JobScheduler.scala:113)\n",
      "\tat org.apache.spark.streaming.StreamingContext.$anonfun$stop$3(StreamingContext.scala:688)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1442)\n",
      "\tat org.apache.spark.streaming.StreamingContext.stop(StreamingContext.scala:688)\n",
      "\tat org.apache.spark.streaming.api.java.JavaStreamingContext.stop(JavaStreamingContext.scala:602)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Could not find Receiver-0-1653505779672.\n",
      "\tat org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:178)\n",
      "\tat org.apache.spark.rpc.netty.Dispatcher.postOneWayMessage(Dispatcher.scala:150)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.send(NettyRpcEnv.scala:193)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEndpointRef.send(NettyRpcEnv.scala:564)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$stopReceivers$2(ReceiverTracker.scala:657)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.$anonfun$stopReceivers$2$adapted(ReceiverTracker.scala:657)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.org$apache$spark$streaming$scheduler$ReceiverTracker$ReceiverTrackerEndpoint$$stopReceivers(ReceiverTracker.scala:657)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$receiveAndReply$1.applyOrElse(ReceiverTracker.scala:538)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\t... 1 more\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2022-05-25 13:09:40\n",
      "-------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/25 13:09:50 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:10:00 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:10:10 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:10:20 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:10:30 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:10:40 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:10:50 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:11:00 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:11:10 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:11:20 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:11:30 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:11:40 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:11:50 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:12:00 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:12:10 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:12:20 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:12:30 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:12:40 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:12:50 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:13:00 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:13:10 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:13:20 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:13:30 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:13:40 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:13:50 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:14:00 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:14:10 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:14:20 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:14:30 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:14:40 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:14:50 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:15:00 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:15:10 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:15:20 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:15:30 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:15:40 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:15:50 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:16:00 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:16:10 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:16:20 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:16:30 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:16:40 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:16:50 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:17:00 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:17:10 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:17:20 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:17:30 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:17:40 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:17:50 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:18:00 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:18:10 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:18:20 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:18:30 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:18:40 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:18:50 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:19:00 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:19:10 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:19:20 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:19:30 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:19:40 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:19:50 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:20:00 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:20:10 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:20:20 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:20:30 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:20:40 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:20:50 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:21:00 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:21:10 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:21:20 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:21:30 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:21:40 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:21:50 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:22:00 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:22:10 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:22:20 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:22:30 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:22:40 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:22:50 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:23:00 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:23:10 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:23:20 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:23:30 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:23:40 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:23:50 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:24:00 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:24:10 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:24:20 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:24:30 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:24:40 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:24:50 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:25:00 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:25:10 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:25:20 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:25:30 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:25:40 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:25:50 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:26:00 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:26:10 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:26:20 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:26:30 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:26:40 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:26:50 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:27:00 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:27:10 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:27:20 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:27:30 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:27:40 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:27:50 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:28:00 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:28:10 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:28:20 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:28:30 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:28:40 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:28:50 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:29:00 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:29:10 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:29:20 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:29:30 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:29:40 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:29:50 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:30:00 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:30:10 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:30:20 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:30:30 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:30:40 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:30:50 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:31:00 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:31:10 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:31:20 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:31:30 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:31:40 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:31:50 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:32:00 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:32:10 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:32:20 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:32:30 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:32:40 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:32:50 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "22/05/25 13:33:00 ERROR JobScheduler: Error in job generator\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:162)\n",
      "\tat org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1912)\n",
      "\tat org.apache.spark.rdd.RDD.unpersist(RDD.scala:222)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6(DStream.scala:459)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$6$adapted(DStream.scala:458)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.$anonfun$foreach$3(HashMap.scala:158)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry(HashTable.scala:237)\n",
      "\tat scala.collection.mutable.HashTable.foreachEntry$(HashTable.scala:230)\n",
      "\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:44)\n",
      "\tat scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:158)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:458)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.$anonfun$clearMetadata$9$adapted(DStream.scala:471)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.clearMetadata(DStream.scala:471)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.$anonfun$clearMetadata$2$adapted(DStreamGraph.scala:135)\n",
      "\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\n",
      "\tat org.apache.spark.streaming.DStreamGraph.clearMetadata(DStreamGraph.scala:135)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.clearMetadata(JobGenerator.scala:266)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:187)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\n",
      "\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n"
     ]
    }
   ],
   "source": [
    "ssc.stop()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7f324bf0f3a4c27c0f343afbdf6a85547be48a38cd4f6138b408483976222ba8"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
